{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.tsa.stattools as ts\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from fbprophet import Prophet\n",
    "\n",
    "import math\n",
    "\n",
    "# import pyflux as pf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM\n",
    "#from keras.layers import Concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(2019)\n",
    "set_random_seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_pickle('./processed_data/df_combined.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>vix</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-08 00:00:00</td>\n",
       "      <td>1054.03</td>\n",
       "      <td>18.879</td>\n",
       "      <td>2732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-08 01:00:00</td>\n",
       "      <td>1060.48</td>\n",
       "      <td>18.915</td>\n",
       "      <td>2693.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds        y     vix    gold\n",
       "0 2017-02-08 00:00:00  1054.03  18.879  2732.0\n",
       "1 2017-02-08 01:00:00  1060.48  18.915  2693.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlations = df_combined.corr()\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(correlations, square=True, cmap=\"RdBu_r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_chronological(df, ratio = 0.9, use_ratio = True, index = 1000):\n",
    "    \n",
    "    '''\n",
    "    Input is a dataframe, and a ratio. Splits dataframe into 2 dataframes chronologically.\n",
    "    Returns first dataframe up to the index of the length of the input dataframe times the input ratio, \n",
    "    and returns second dataframe of remaining elements.\n",
    "    use_ratio is a flag, wether ratio should be used or indicies instead.\n",
    "    \n",
    "    df = input dataframe\n",
    "    ratio = ratio to be used for splitting\n",
    "    use_ratio = if True, use ratio, \n",
    "    index = index to split input dataframe on\n",
    "    \n",
    "    '''\n",
    "    if use_ratio:\n",
    "        size = len(df) * ratio\n",
    "        size_round = round(size)\n",
    "\n",
    "        df_train = df[0:(size_round)]\n",
    "        df_test = df[size_round:]\n",
    "    else:\n",
    "        df_train = df[0:(index)]\n",
    "        df_test = df[index:]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variables(df, lags, look_back, predict_window):\n",
    "    \n",
    "    '''\n",
    "    In order to use keras LSTM, we need to convert the input into a keras-friendly input.\n",
    "    \n",
    "    df = input dataframe\n",
    "    lags = number of lags\n",
    "    look_back = number of preceding elements to be considered\n",
    "    predict_window = size of window for predictions\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features = lags + 1\n",
    "    start = look_back\n",
    "    stop = len(df) - lags - predict_window\n",
    "\n",
    "    lstm_in_X = np.zeros(shape=(stop-start, look_back+1, features))\n",
    "    lstm_in_Y = np.zeros(shape=(stop-start, look_back+1))\n",
    "\n",
    "    iter_list = [num for num in range(look_back+1)][::-1]\n",
    "    for i in range(start, stop):\n",
    "        for index, j in enumerate(iter_list):\n",
    "            X = df[i - j : i - j + lags + 1, -1]\n",
    "            lstm_in_X[i - start, index] = np.ravel(X)\n",
    "            Y = df[i - j + lags + 1, -1]\n",
    "            lstm_in_Y[i-start, index] = Y\n",
    "            \n",
    "    return lstm_in_X, lstm_in_Y, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(train_X, train_Y, lags, look_back, predict_window, lstm_nodes,\n",
    "               dense_layers, dropout = 0.1, loss_type = 'hinge', optimizer_type = 'adam',\n",
    "               number_epochs = 300, batch_size = 24, ):\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_nodes, input_shape=(look_back+1, features)))\n",
    "    model.add(Dropout(dropout))\n",
    "    for nodes in dense_layers:\n",
    "        model.add(Dense(nodes))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(look_back + 1))\n",
    "    model.compile(loss=loss_type, optimizer= optimizer_type)\n",
    "    model.fit(train_X, train_Y, epochs=number_epochs, batch_size = batch_size, verbose = 1)\n",
    "    \n",
    "    pred_Y_train = model.predict(train_X)\n",
    "    predictions = pred_Y_train[:,-1]\n",
    "    actuals = train_Y[:,-1]\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model, dataset, train_X, train_Y, predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rolling_window(model, train_x, train_y, test_x, test_y, batch_size = 32, epochs = 2):\n",
    "    predictions_test = []\n",
    "    actuals_test = []\n",
    "    yhats = []\n",
    "    ys = []\n",
    "    \n",
    "    for i in range(0, len(test_y) - 1):\n",
    "        model.fit(train_x, train_y, \n",
    "                    epochs= epochs, \n",
    "                    batch_size = batch_size, \n",
    "                    validation_data=(test_x[i].reshape(1,1,23), (test_y[i].reshape(1 ,))),\n",
    "                    verbose=2,\n",
    "#                     callbacks=[earlystopper],\n",
    "                    shuffle=False)\n",
    "        pred_Y_test = model.predict(test_x[i].reshape(1,1,23))\n",
    "        train_x = np.concatenate((train_x, (test_x[i].reshape(1 , 1 , 23))))\n",
    "\n",
    "        train_y = np.concatenate((train_y, (test_y[i].reshape(1 ,))))\n",
    "        predict_test = pred_Y_test[-1,-1]\n",
    "        actual_test = train_y[-1]\n",
    "        predictions_test.append(predict_test)\n",
    "        actuals_test.append(actual_test)\n",
    "        yhats.append(pred_Y_test)\n",
    "        ys.append(test_y[i])\n",
    "        \n",
    "    return predictions_test, actuals_test, yhats, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Val, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_train_test_chronological(df_combined, ratio = .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = split_train_test_chronological(df_combined, ratio = .95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-7)</th>\n",
       "      <th>var2(t-7)</th>\n",
       "      <th>var3(t-7)</th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var2(t-6)</th>\n",
       "      <th>var3(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var2(t-5)</th>\n",
       "      <th>var3(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1054.030029</td>\n",
       "      <td>18.879000</td>\n",
       "      <td>2732.000000</td>\n",
       "      <td>1060.479980</td>\n",
       "      <td>18.915001</td>\n",
       "      <td>2693.000000</td>\n",
       "      <td>1062.939941</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>2712.120117</td>\n",
       "      <td>1065.819946</td>\n",
       "      <td>...</td>\n",
       "      <td>2742.100098</td>\n",
       "      <td>1066.310059</td>\n",
       "      <td>18.878000</td>\n",
       "      <td>2735.270020</td>\n",
       "      <td>1066.060059</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.120117</td>\n",
       "      <td>1066.260010</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2731.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1060.479980</td>\n",
       "      <td>18.915001</td>\n",
       "      <td>2693.000000</td>\n",
       "      <td>1062.939941</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>2712.120117</td>\n",
       "      <td>1065.819946</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2743.989990</td>\n",
       "      <td>1068.150024</td>\n",
       "      <td>...</td>\n",
       "      <td>2735.270020</td>\n",
       "      <td>1066.060059</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.120117</td>\n",
       "      <td>1066.260010</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2731.959961</td>\n",
       "      <td>1033.900024</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2710.209961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1062.939941</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>2712.120117</td>\n",
       "      <td>1065.819946</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2743.989990</td>\n",
       "      <td>1068.150024</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2742.100098</td>\n",
       "      <td>1066.310059</td>\n",
       "      <td>...</td>\n",
       "      <td>2732.120117</td>\n",
       "      <td>1066.260010</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2731.959961</td>\n",
       "      <td>1033.900024</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2710.209961</td>\n",
       "      <td>1032.180054</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2719.310059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1065.819946</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2743.989990</td>\n",
       "      <td>1068.150024</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2742.100098</td>\n",
       "      <td>1066.310059</td>\n",
       "      <td>18.878000</td>\n",
       "      <td>2735.270020</td>\n",
       "      <td>1066.060059</td>\n",
       "      <td>...</td>\n",
       "      <td>2731.959961</td>\n",
       "      <td>1033.900024</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2710.209961</td>\n",
       "      <td>1032.180054</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2719.310059</td>\n",
       "      <td>1037.780029</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.989990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1068.150024</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2742.100098</td>\n",
       "      <td>1066.310059</td>\n",
       "      <td>18.878000</td>\n",
       "      <td>2735.270020</td>\n",
       "      <td>1066.060059</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.120117</td>\n",
       "      <td>1066.260010</td>\n",
       "      <td>...</td>\n",
       "      <td>2710.209961</td>\n",
       "      <td>1032.180054</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2719.310059</td>\n",
       "      <td>1037.780029</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.989990</td>\n",
       "      <td>1045.300049</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2719.979980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-7)  var2(t-7)    var3(t-7)    var1(t-6)  var2(t-6)    var3(t-6)  \\\n",
       "7   1054.030029  18.879000  2732.000000  1060.479980  18.915001  2693.000000   \n",
       "8   1060.479980  18.915001  2693.000000  1062.939941  18.860001  2712.120117   \n",
       "9   1062.939941  18.860001  2712.120117  1065.819946  18.770000  2743.989990   \n",
       "10  1065.819946  18.770000  2743.989990  1068.150024  18.770000  2742.100098   \n",
       "11  1068.150024  18.770000  2742.100098  1066.310059  18.878000  2735.270020   \n",
       "\n",
       "      var1(t-5)  var2(t-5)    var3(t-5)    var1(t-4)  ...    var3(t-3)  \\\n",
       "7   1062.939941  18.860001  2712.120117  1065.819946  ...  2742.100098   \n",
       "8   1065.819946  18.770000  2743.989990  1068.150024  ...  2735.270020   \n",
       "9   1068.150024  18.770000  2742.100098  1066.310059  ...  2732.120117   \n",
       "10  1066.310059  18.878000  2735.270020  1066.060059  ...  2731.959961   \n",
       "11  1066.060059  18.886999  2732.120117  1066.260010  ...  2710.209961   \n",
       "\n",
       "      var1(t-2)  var2(t-2)    var3(t-2)    var1(t-1)  var2(t-1)    var3(t-1)  \\\n",
       "7   1066.310059  18.878000  2735.270020  1066.060059  18.886999  2732.120117   \n",
       "8   1066.060059  18.886999  2732.120117  1066.260010  18.886999  2731.959961   \n",
       "9   1066.260010  18.886999  2731.959961  1033.900024  18.886999  2710.209961   \n",
       "10  1033.900024  18.886999  2710.209961  1032.180054  18.886999  2719.310059   \n",
       "11  1032.180054  18.886999  2719.310059  1037.780029  18.886999  2732.989990   \n",
       "\n",
       "        var1(t)    var2(t)      var3(t)  \n",
       "7   1066.260010  18.886999  2731.959961  \n",
       "8   1033.900024  18.886999  2710.209961  \n",
       "9   1032.180054  18.886999  2719.310059  \n",
       "10  1037.780029  18.886999  2732.989990  \n",
       "11  1045.300049  18.886999  2719.979980  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "values = df_combined.drop('ds', axis = 1).values\n",
    "# integer encode direction\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 7, 1)\n",
    "\n",
    "reframed_2 = series_to_supervised(values, 7, 1)\n",
    "reframed_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 1, 23) (12000,) (341, 1, 23) (341,) (320, 1, 23) (320,)\n"
     ]
    }
   ],
   "source": [
    "# drop columns we don't want to predict\n",
    "y = reframed.iloc[:,-12].values\n",
    "X = reframed.drop('var1(t)', axis =1).values\n",
    "# split into train and test sets\n",
    "\n",
    "n_train_hours = 12000\n",
    "n_test_hours = 320\n",
    "train_X = X[:n_train_hours,:]\n",
    "train_y = y[:n_train_hours]\n",
    "\n",
    "val_X= X[n_train_hours:-n_test_hours,]\n",
    "val_y= y[n_train_hours:-n_test_hours]\n",
    "\n",
    "\n",
    "test_X = X[-n_test_hours:,:]\n",
    "test_y = y[-n_test_hours:]\n",
    "\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape,val_X.shape, val_y.shape ,test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12661, 23)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8421831 , -1.8427463 , -1.8428228 , ...,  0.4367851 ,\n",
       "        0.43582702,  0.44757515], dtype=float32)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unscaled data for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 1, 23) (12000,) (341, 1, 23) (341,) (320, 1, 23) (320,)\n"
     ]
    }
   ],
   "source": [
    "# # drop columns we don't want to predict\n",
    "# y = reframed_2.iloc[:,-12].values\n",
    "# X = reframed_2.drop('var1(t)', axis =1).values\n",
    "# # split into train and test sets\n",
    "\n",
    "# n_train_hours = 12000\n",
    "# n_test_hours = 320\n",
    "# train_X = X[:n_train_hours,:]\n",
    "# train_y = y[:n_train_hours]\n",
    "\n",
    "# val_X= X[n_train_hours:-n_test_hours,]\n",
    "# val_y= y[n_train_hours:-n_test_hours]\n",
    "\n",
    "# test_X = X[-n_test_hours:,:]\n",
    "# test_y = y[-n_test_hours:]\n",
    "\n",
    "\n",
    "\n",
    "# # reshape input to be 3D [samples, timesteps, features]\n",
    "# train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "# val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "# print(train_X.shape, train_y.shape,val_X.shape, val_y.shape ,test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1068.15, 1066.31, 1066.06, ..., 8513.3 , 8510.17, 8548.55],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_4 = Sequential()\n",
    "LSTM_model_4.add(LSTM(64, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]), dropout=0.20,recurrent_dropout=0.20))\n",
    "# LSTM_model_4.add(LSTM(128))\n",
    "LSTM_model_4.add(Dense(32))\n",
    "LSTM_model_4.add(Dense(32))\n",
    "# LSTM_model_4.add(LSTM(16, activation='relu'))\n",
    "LSTM_model_4.add(Dense(1))\n",
    "LSTM_model_4.compile(optimizer='adam', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 341 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.1489 - val_loss: 0.0025\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0357 - val_loss: 0.0039\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0301 - val_loss: 0.0108\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0271 - val_loss: 0.0034\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0263 - val_loss: 0.0018\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0273 - val_loss: 0.0023\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0246 - val_loss: 0.0023\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0223 - val_loss: 0.0015\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0248 - val_loss: 0.0023\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0226 - val_loss: 0.0023\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0194 - val_loss: 0.0017\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.0199 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0192 - val_loss: 0.0033\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.0186 - val_loss: 0.0034\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.0175 - val_loss: 0.0047\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0163 - val_loss: 0.0066\n",
      "Epoch 17/100\n",
      " - 6s - loss: 0.0157 - val_loss: 0.0046\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.0146 - val_loss: 0.0033\n",
      "Epoch 19/100\n",
      " - 6s - loss: 0.0148 - val_loss: 0.0039\n",
      "Epoch 20/100\n",
      " - 6s - loss: 0.0145 - val_loss: 0.0036\n",
      "Epoch 21/100\n",
      " - 6s - loss: 0.0350 - val_loss: 0.0026\n",
      "Epoch 22/100\n",
      " - 6s - loss: 0.0339 - val_loss: 0.0021\n",
      "Epoch 23/100\n",
      " - 6s - loss: 0.0274 - val_loss: 0.0013\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.0229 - val_loss: 9.5581e-04\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.0171 - val_loss: 0.0015\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.0165 - val_loss: 0.0024\n",
      "Epoch 27/100\n",
      " - 6s - loss: 0.0165 - val_loss: 0.0026\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.0165 - val_loss: 0.0033\n",
      "Epoch 29/100\n",
      " - 6s - loss: 0.0145 - val_loss: 0.0029\n",
      "Epoch 30/100\n",
      " - 6s - loss: 0.0154 - val_loss: 0.0027\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.0150 - val_loss: 0.0023\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.0139 - val_loss: 0.0019\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.0119 - val_loss: 0.0020\n",
      "Epoch 34/100\n",
      " - 6s - loss: 0.0123 - val_loss: 0.0027\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.0128 - val_loss: 0.0032\n",
      "Epoch 36/100\n",
      " - 6s - loss: 0.0133 - val_loss: 0.0016\n",
      "Epoch 37/100\n",
      " - 6s - loss: 0.0128 - val_loss: 0.0023\n",
      "Epoch 38/100\n",
      " - 6s - loss: 0.0115 - val_loss: 0.0035\n",
      "Epoch 39/100\n",
      " - 6s - loss: 0.0101 - val_loss: 0.0023\n",
      "Epoch 40/100\n",
      " - 6s - loss: 0.0100 - val_loss: 0.0024\n",
      "Epoch 41/100\n",
      " - 6s - loss: 0.0104 - val_loss: 0.0030\n",
      "Epoch 42/100\n",
      " - 6s - loss: 0.0110 - val_loss: 0.0021\n",
      "Epoch 43/100\n",
      " - 6s - loss: 0.0101 - val_loss: 0.0019\n",
      "Epoch 44/100\n",
      " - 6s - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 45/100\n",
      " - 6s - loss: 0.0092 - val_loss: 0.0033\n",
      "Epoch 46/100\n",
      " - 6s - loss: 0.0091 - val_loss: 0.0029\n",
      "Epoch 47/100\n",
      " - 6s - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 48/100\n",
      " - 6s - loss: 0.0096 - val_loss: 0.0017\n",
      "Epoch 49/100\n",
      " - 6s - loss: 0.0087 - val_loss: 0.0036\n",
      "Epoch 50/100\n",
      " - 6s - loss: 0.0086 - val_loss: 0.0022\n",
      "Epoch 51/100\n",
      " - 6s - loss: 0.0086 - val_loss: 0.0018\n",
      "Epoch 52/100\n",
      " - 6s - loss: 0.0087 - val_loss: 0.0017\n",
      "Epoch 53/100\n",
      " - 6s - loss: 0.0077 - val_loss: 0.0028\n",
      "Epoch 54/100\n",
      " - 6s - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 55/100\n",
      " - 6s - loss: 0.0081 - val_loss: 0.0029\n",
      "Epoch 56/100\n",
      " - 6s - loss: 0.0073 - val_loss: 0.0030\n",
      "Epoch 57/100\n",
      " - 6s - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 58/100\n",
      " - 7s - loss: 0.0075 - val_loss: 0.0031\n",
      "Epoch 59/100\n",
      " - 7s - loss: 0.0071 - val_loss: 0.0033\n",
      "Epoch 60/100\n",
      " - 7s - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 61/100\n",
      " - 6s - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 62/100\n",
      " - 6s - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 63/100\n",
      " - 6s - loss: 0.0075 - val_loss: 0.0034\n",
      "Epoch 64/100\n",
      " - 6s - loss: 0.0068 - val_loss: 0.0025\n",
      "Epoch 65/100\n",
      " - 6s - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 66/100\n",
      " - 6s - loss: 0.0063 - val_loss: 0.0030\n",
      "Epoch 67/100\n",
      " - 6s - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 68/100\n",
      " - 6s - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 69/100\n",
      " - 6s - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 70/100\n",
      " - 6s - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 71/100\n",
      " - 6s - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 72/100\n",
      " - 6s - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 73/100\n",
      " - 6s - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 74/100\n",
      " - 6s - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 75/100\n",
      " - 6s - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 76/100\n",
      " - 6s - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 77/100\n",
      " - 6s - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 78/100\n",
      " - 6s - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 79/100\n",
      " - 7s - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 80/100\n",
      " - 6s - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 81/100\n",
      " - 6s - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 82/100\n",
      " - 6s - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 83/100\n",
      " - 6s - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 84/100\n",
      " - 6s - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 85/100\n",
      " - 6s - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 86/100\n",
      " - 6s - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 87/100\n",
      " - 6s - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 88/100\n",
      " - 6s - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 89/100\n",
      " - 6s - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 90/100\n",
      " - 6s - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 91/100\n",
      " - 6s - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 92/100\n",
      " - 6s - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 93/100\n",
      " - 6s - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 94/100\n",
      " - 6s - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 95/100\n",
      " - 6s - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 96/100\n",
      " - 6s - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 97/100\n",
      " - 6s - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 98/100\n",
      " - 6s - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 99/100\n",
      " - 6s - loss: 0.0033 - val_loss: 0.0079\n",
      "Epoch 100/100\n",
      " - 6s - loss: 0.0032 - val_loss: 0.0055\n"
     ]
    }
   ],
   "source": [
    "history_4 = LSTM_model_4.fit(train_X, train_y, \n",
    "                    epochs= 100, \n",
    "                    batch_size = 32, \n",
    "                    validation_data=(val_X, val_y),\n",
    "                    verbose=2,\n",
    "#                     callbacks=[earlystopper],\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0038 - val_loss: 0.0207\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0033 - val_loss: 0.0207\n",
      "Train on 12001 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 0.0031 - val_loss: 0.0203\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0032 - val_loss: 0.0291\n",
      "Train on 12002 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0027 - val_loss: 0.0172\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0028 - val_loss: 0.0189\n",
      "Train on 12003 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0029 - val_loss: 0.0158\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0027 - val_loss: 0.0230\n",
      "Train on 12004 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0029 - val_loss: 0.0151\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0031 - val_loss: 0.0125\n",
      "Train on 12005 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0027 - val_loss: 0.0078\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0026 - val_loss: 0.0090\n",
      "Train on 12006 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0028 - val_loss: 0.0173\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0027 - val_loss: 0.0112\n",
      "Train on 12007 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0027 - val_loss: 0.0233\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0031 - val_loss: 0.0188\n",
      "Train on 12008 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0025 - val_loss: 0.0181\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0023 - val_loss: 0.0193\n",
      "Train on 12009 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0030 - val_loss: 0.0204\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0025 - val_loss: 0.0178\n",
      "Train on 12010 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0027 - val_loss: 0.0155\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0029 - val_loss: 0.0163\n",
      "Train on 12011 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0030 - val_loss: 0.0107\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0028 - val_loss: 0.0154\n",
      "Train on 12012 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0023 - val_loss: 0.0188\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0029 - val_loss: 0.0221\n",
      "Train on 12013 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0021 - val_loss: 0.0235\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0024 - val_loss: 0.0285\n",
      "Train on 12014 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0024 - val_loss: 0.0236\n",
      "Epoch 2/2\n",
      " - 6s - loss: 0.0023 - val_loss: 0.0219\n",
      "Train on 12015 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0027 - val_loss: 0.0171\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0022 - val_loss: 0.0158\n",
      "Train on 12016 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0022 - val_loss: 0.0149\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0023 - val_loss: 0.0168\n",
      "Train on 12017 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0026 - val_loss: 0.0096\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0024 - val_loss: 0.0107\n",
      "Train on 12018 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0025 - val_loss: 0.0097\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0019 - val_loss: 0.0084\n",
      "Train on 12019 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0020 - val_loss: 0.0093\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0023 - val_loss: 0.0095\n",
      "Train on 12020 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 0.0018 - val_loss: 0.0075\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0020 - val_loss: 0.0118\n",
      "Train on 12021 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0020 - val_loss: 0.0081\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0022 - val_loss: 0.0102\n",
      "Train on 12022 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0020 - val_loss: 0.0125\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0021 - val_loss: 0.0120\n",
      "Train on 12023 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 0.0019 - val_loss: 0.0144\n",
      "Epoch 2/2\n",
      " - 9s - loss: 0.0021 - val_loss: 0.0140\n",
      "Train on 12024 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0022 - val_loss: 0.0046\n",
      "Train on 12025 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 0.0025 - val_loss: 4.1833e-04\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0026 - val_loss: 0.0024\n",
      "Train on 12026 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0024 - val_loss: 0.0018\n",
      "Train on 12027 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0017 - val_loss: 9.1892e-04\n",
      "Train on 12028 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 12029 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0022 - val_loss: 0.0063\n",
      "Train on 12030 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0021 - val_loss: 0.0067\n",
      "Train on 12031 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0016 - val_loss: 0.0037\n",
      "Train on 12032 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0019 - val_loss: 0.0027\n",
      "Train on 12033 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0017 - val_loss: 0.0078\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0019 - val_loss: 0.0093\n",
      "Train on 12034 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0017 - val_loss: 0.0104\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0016 - val_loss: 0.0080\n",
      "Train on 12035 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0021 - val_loss: 0.0092\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0018 - val_loss: 0.0086\n",
      "Train on 12036 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0016 - val_loss: 0.0156\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0017 - val_loss: 0.0174\n",
      "Train on 12037 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0016 - val_loss: 0.0192\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0015 - val_loss: 0.0192\n",
      "Train on 12038 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0013 - val_loss: 0.0105\n",
      "Epoch 2/2\n",
      " - 9s - loss: 0.0019 - val_loss: 0.0080\n",
      "Train on 12039 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0017 - val_loss: 0.0078\n",
      "Train on 12040 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0015 - val_loss: 0.0079\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0016 - val_loss: 0.0062\n",
      "Train on 12041 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0049\n",
      "Train on 12042 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0014 - val_loss: 0.0088\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0076\n",
      "Train on 12043 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0103\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0016 - val_loss: 0.0108\n",
      "Train on 12044 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0091\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0115\n",
      "Train on 12045 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0162\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0195\n",
      "Train on 12046 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0154\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0018 - val_loss: 0.0134\n",
      "Train on 12047 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0127\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0015 - val_loss: 0.0136\n",
      "Train on 12048 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0104\n",
      "Train on 12049 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0177\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0150\n",
      "Train on 12050 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0011 - val_loss: 0.0186\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0188\n",
      "Train on 12051 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0151\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0196\n",
      "Train on 12052 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0177\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0141\n",
      "Train on 12053 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0150\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0080\n",
      "Train on 12054 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0091\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0015 - val_loss: 0.0119\n",
      "Train on 12055 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0017 - val_loss: 0.0173\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0020 - val_loss: 0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12056 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0015 - val_loss: 0.0257\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0015 - val_loss: 0.0238\n",
      "Train on 12057 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0215\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0015 - val_loss: 0.0207\n",
      "Train on 12058 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0212\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0202\n",
      "Train on 12059 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0016 - val_loss: 0.0252\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0240\n",
      "Train on 12060 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0272\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0291\n",
      "Train on 12061 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0242\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0249\n",
      "Train on 12062 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0015 - val_loss: 0.0230\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0215\n",
      "Train on 12063 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0198\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0205\n",
      "Train on 12064 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.9686e-04 - val_loss: 0.0213\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0274\n",
      "Train on 12065 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0363\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0284\n",
      "Train on 12066 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0310\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0271\n",
      "Train on 12067 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0219\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.4698e-04 - val_loss: 0.0216\n",
      "Train on 12068 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0292\n",
      "Epoch 2/2\n",
      " - 9s - loss: 0.0012 - val_loss: 0.0269\n",
      "Train on 12069 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0011 - val_loss: 0.0282\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0270\n",
      "Train on 12070 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0230\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0266\n",
      "Train on 12071 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9.6009e-04 - val_loss: 0.0268\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0013 - val_loss: 0.0253\n",
      "Train on 12072 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0269\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.0829e-04 - val_loss: 0.0304\n",
      "Train on 12073 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.6641e-04 - val_loss: 0.0218\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.3193e-04 - val_loss: 0.0238\n",
      "Train on 12074 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0234\n",
      "Epoch 2/2\n",
      " - 9s - loss: 0.0017 - val_loss: 0.0255\n",
      "Train on 12075 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0236\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0191\n",
      "Train on 12076 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0198\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0245\n",
      "Train on 12077 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0254\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0013 - val_loss: 0.0287\n",
      "Train on 12078 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0306\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0313\n",
      "Train on 12079 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0311\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.7130e-04 - val_loss: 0.0270\n",
      "Train on 12080 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0289\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0264\n",
      "Train on 12081 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0276\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0264\n",
      "Train on 12082 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0263\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0283\n",
      "Train on 12083 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.9032e-04 - val_loss: 0.0276\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0278\n",
      "Train on 12084 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0242\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.2962e-04 - val_loss: 0.0257\n",
      "Train on 12085 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0276\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.6004e-04 - val_loss: 0.0282\n",
      "Train on 12086 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.1123e-04 - val_loss: 0.0392\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0370\n",
      "Train on 12087 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0248\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.8469e-04 - val_loss: 0.0263\n",
      "Train on 12088 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.8920e-04 - val_loss: 0.0243\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0270\n",
      "Train on 12089 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.4409e-04 - val_loss: 0.0253\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.7141e-04 - val_loss: 0.0254\n",
      "Train on 12090 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0294\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.6732e-04 - val_loss: 0.0276\n",
      "Train on 12091 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.3666e-04 - val_loss: 0.0281\n",
      "Epoch 2/2\n",
      " - 9s - loss: 9.5839e-04 - val_loss: 0.0260\n",
      "Train on 12092 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.3375e-04 - val_loss: 0.0273\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.6975e-04 - val_loss: 0.0269\n",
      "Train on 12093 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9.3403e-04 - val_loss: 0.0314\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0320\n",
      "Train on 12094 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.5735e-04 - val_loss: 0.0277\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0010 - val_loss: 0.0295\n",
      "Train on 12095 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0010 - val_loss: 0.0315\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.6140e-04 - val_loss: 0.0298\n",
      "Train on 12096 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9.9450e-04 - val_loss: 0.0305\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0365\n",
      "Train on 12097 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0011 - val_loss: 0.0261\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.2460e-04 - val_loss: 0.0318\n",
      "Train on 12098 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0246\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.9096e-04 - val_loss: 0.0253\n",
      "Train on 12099 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0242\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.7815e-04 - val_loss: 0.0251\n",
      "Train on 12100 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 9.0060e-04 - val_loss: 0.0283\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.3156e-04 - val_loss: 0.0288\n",
      "Train on 12101 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0268\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0257\n",
      "Train on 12102 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0283\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.4715e-04 - val_loss: 0.0305\n",
      "Train on 12103 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0386\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.2172e-04 - val_loss: 0.0426\n",
      "Train on 12104 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0011 - val_loss: 0.0348\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0013 - val_loss: 0.0345\n",
      "Train on 12105 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.7475e-04 - val_loss: 0.0373\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.8187e-04 - val_loss: 0.0361\n",
      "Train on 12106 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.3540e-04 - val_loss: 0.0338\n",
      "Epoch 2/2\n",
      " - 9s - loss: 0.0012 - val_loss: 0.0341\n",
      "Train on 12107 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 0.0013 - val_loss: 0.0318\n",
      "Epoch 2/2\n",
      " - 9s - loss: 9.7236e-04 - val_loss: 0.0291\n",
      "Train on 12108 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.6619e-04 - val_loss: 0.0320\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.3202e-04 - val_loss: 0.0334\n",
      "Train on 12109 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.1656e-04 - val_loss: 0.0338\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.2137e-04 - val_loss: 0.0321\n",
      "Train on 12110 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.4134e-04 - val_loss: 0.0454\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.7751e-04 - val_loss: 0.0429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12111 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0412\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.7810e-04 - val_loss: 0.0436\n",
      "Train on 12112 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0277\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.8790e-04 - val_loss: 0.0271\n",
      "Train on 12113 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.3300e-04 - val_loss: 0.0165\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.4576e-04 - val_loss: 0.0206\n",
      "Train on 12114 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0218\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.0547e-04 - val_loss: 0.0213\n",
      "Train on 12115 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.9313e-04 - val_loss: 0.0269\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.2442e-04 - val_loss: 0.0282\n",
      "Train on 12116 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.7615e-04 - val_loss: 0.0329\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.7732e-04 - val_loss: 0.0366\n",
      "Train on 12117 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 8.9701e-04 - val_loss: 0.0327\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.0691e-04 - val_loss: 0.0285\n",
      "Train on 12118 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.0492e-04 - val_loss: 0.0304\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.9013e-04 - val_loss: 0.0300\n",
      "Train on 12119 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.7982e-04 - val_loss: 0.0269\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.4164e-04 - val_loss: 0.0247\n",
      "Train on 12120 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.9898e-04 - val_loss: 0.0253\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.1849e-04 - val_loss: 0.0218\n",
      "Train on 12121 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 8.9557e-04 - val_loss: 0.0290\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0012 - val_loss: 0.0276\n",
      "Train on 12122 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.9918e-04 - val_loss: 0.0375\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.9527e-04 - val_loss: 0.0346\n",
      "Train on 12123 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.2637e-04 - val_loss: 0.0349\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.1272e-04 - val_loss: 0.0327\n",
      "Train on 12124 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.9236e-04 - val_loss: 0.0324\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.3936e-04 - val_loss: 0.0340\n",
      "Train on 12125 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.0507e-04 - val_loss: 0.0340\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.4045e-04 - val_loss: 0.0346\n",
      "Train on 12126 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.5917e-04 - val_loss: 0.0256\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.0737e-04 - val_loss: 0.0249\n",
      "Train on 12127 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.3093e-04 - val_loss: 0.0252\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0010 - val_loss: 0.0255\n",
      "Train on 12128 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.2532e-04 - val_loss: 0.0347\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.4317e-04 - val_loss: 0.0379\n",
      "Train on 12129 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.3589e-04 - val_loss: 0.0310\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.5187e-04 - val_loss: 0.0299\n",
      "Train on 12130 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0296\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.2309e-04 - val_loss: 0.0315\n",
      "Train on 12131 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.9398e-04 - val_loss: 0.0375\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.2669e-04 - val_loss: 0.0405\n",
      "Train on 12132 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0012 - val_loss: 0.0309\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.1798e-04 - val_loss: 0.0334\n",
      "Train on 12133 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.7958e-04 - val_loss: 0.0311\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.3859e-04 - val_loss: 0.0327\n",
      "Train on 12134 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.1296e-04 - val_loss: 0.0235\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.3384e-04 - val_loss: 0.0243\n",
      "Train on 12135 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.0793e-04 - val_loss: 0.0256\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.6879e-04 - val_loss: 0.0253\n",
      "Train on 12136 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.2596e-04 - val_loss: 0.0471\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.1173e-04 - val_loss: 0.0458\n",
      "Train on 12137 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.8078e-04 - val_loss: 0.0531\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.0175e-04 - val_loss: 0.0555\n",
      "Train on 12138 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9.0178e-04 - val_loss: 0.0501\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.1100e-04 - val_loss: 0.0425\n",
      "Train on 12139 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.9049e-04 - val_loss: 0.0490\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.1469e-04 - val_loss: 0.0481\n",
      "Train on 12140 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.9567e-04 - val_loss: 0.0432\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.1754e-04 - val_loss: 0.0413\n",
      "Train on 12141 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.0287e-04 - val_loss: 0.0370\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.2765e-04 - val_loss: 0.0366\n",
      "Train on 12142 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.1122e-04 - val_loss: 0.0409\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.1881e-04 - val_loss: 0.0384\n",
      "Train on 12143 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0010 - val_loss: 0.0334\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.1280e-04 - val_loss: 0.0326\n",
      "Train on 12144 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0351\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.0321e-04 - val_loss: 0.0352\n",
      "Train on 12145 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.7095e-04 - val_loss: 0.0325\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0014 - val_loss: 0.0353\n",
      "Train on 12146 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.7552e-04 - val_loss: 0.0341\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.6334e-04 - val_loss: 0.0354\n",
      "Train on 12147 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.5618e-04 - val_loss: 0.0389\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.9643e-04 - val_loss: 0.0397\n",
      "Train on 12148 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.9323e-04 - val_loss: 0.0333\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.3665e-04 - val_loss: 0.0341\n",
      "Train on 12149 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.5864e-04 - val_loss: 0.0334\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.2945e-04 - val_loss: 0.0348\n",
      "Train on 12150 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.0463e-04 - val_loss: 0.0348\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.5170e-04 - val_loss: 0.0398\n",
      "Train on 12151 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.9678e-04 - val_loss: 0.0387\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.1721e-04 - val_loss: 0.0405\n",
      "Train on 12152 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.4584e-04 - val_loss: 0.0419\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.5530e-04 - val_loss: 0.0405\n",
      "Train on 12153 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.1618e-04 - val_loss: 0.0459\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0433\n",
      "Train on 12154 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.0433e-04 - val_loss: 0.0463\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.9208e-04 - val_loss: 0.0456\n",
      "Train on 12155 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.1588e-04 - val_loss: 0.0384\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.9222e-04 - val_loss: 0.0389\n",
      "Train on 12156 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.6788e-04 - val_loss: 0.0335\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.8909e-04 - val_loss: 0.0387\n",
      "Train on 12157 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.0792e-04 - val_loss: 0.0350\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.6904e-04 - val_loss: 0.0355\n",
      "Train on 12158 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.9558e-04 - val_loss: 0.0322\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.2242e-04 - val_loss: 0.0332\n",
      "Train on 12159 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.4029e-04 - val_loss: 0.0418\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.7105e-04 - val_loss: 0.0422\n",
      "Train on 12160 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.8299e-04 - val_loss: 0.0432\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.1156e-04 - val_loss: 0.0439\n",
      "Train on 12161 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0010 - val_loss: 0.0332\n",
      "Epoch 2/2\n",
      " - 7s - loss: 9.0913e-04 - val_loss: 0.0362\n",
      "Train on 12162 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.1542e-04 - val_loss: 0.0361\n",
      "Epoch 2/2\n",
      " - 9s - loss: 9.0143e-04 - val_loss: 0.0338\n",
      "Train on 12163 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.6594e-04 - val_loss: 0.0334\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.0662e-04 - val_loss: 0.0325\n",
      "Train on 12164 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.0968e-04 - val_loss: 0.0394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 9s - loss: 6.4763e-04 - val_loss: 0.0378\n",
      "Train on 12165 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.8263e-04 - val_loss: 0.0389\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0360\n",
      "Train on 12166 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.9754e-04 - val_loss: 0.0406\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.9954e-04 - val_loss: 0.0368\n",
      "Train on 12167 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.3595e-04 - val_loss: 0.0415\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6572e-04 - val_loss: 0.0420\n",
      "Train on 12168 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.9713e-04 - val_loss: 0.0419\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.1365e-04 - val_loss: 0.0408\n",
      "Train on 12169 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.9388e-04 - val_loss: 0.0447\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.2523e-04 - val_loss: 0.0456\n",
      "Train on 12170 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.6974e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.0964e-04 - val_loss: 0.0444\n",
      "Train on 12171 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.3415e-04 - val_loss: 0.0415\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.3417e-04 - val_loss: 0.0444\n",
      "Train on 12172 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.6886e-04 - val_loss: 0.0405\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.0763e-04 - val_loss: 0.0373\n",
      "Train on 12173 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.8177e-04 - val_loss: 0.0379\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.1413e-04 - val_loss: 0.0368\n",
      "Train on 12174 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.0897e-04 - val_loss: 0.0437\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.8541e-04 - val_loss: 0.0429\n",
      "Train on 12175 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.5183e-04 - val_loss: 0.0442\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.5408e-04 - val_loss: 0.0432\n",
      "Train on 12176 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.6100e-04 - val_loss: 0.0408\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.9497e-04 - val_loss: 0.0406\n",
      "Train on 12177 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.7227e-04 - val_loss: 0.0433\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.9705e-04 - val_loss: 0.0419\n",
      "Train on 12178 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.3743e-04 - val_loss: 0.0413\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.7484e-04 - val_loss: 0.0449\n",
      "Train on 12179 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.4047e-04 - val_loss: 0.0371\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.8433e-04 - val_loss: 0.0365\n",
      "Train on 12180 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.4355e-04 - val_loss: 0.0411\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.9638e-04 - val_loss: 0.0391\n",
      "Train on 12181 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.1810e-04 - val_loss: 0.0443\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0439\n",
      "Train on 12182 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.8768e-04 - val_loss: 0.0356\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.9455e-04 - val_loss: 0.0368\n",
      "Train on 12183 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.9498e-04 - val_loss: 0.0392\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.4001e-04 - val_loss: 0.0384\n",
      "Train on 12184 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.0135e-04 - val_loss: 0.0396\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6548e-04 - val_loss: 0.0401\n",
      "Train on 12185 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.9870e-04 - val_loss: 0.0434\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.1792e-04 - val_loss: 0.0400\n",
      "Train on 12186 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.0299e-04 - val_loss: 0.0479\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.4817e-04 - val_loss: 0.0439\n",
      "Train on 12187 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.8328e-04 - val_loss: 0.0416\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.5327e-04 - val_loss: 0.0403\n",
      "Train on 12188 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0404\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.6248e-04 - val_loss: 0.0406\n",
      "Train on 12189 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.4622e-04 - val_loss: 0.0424\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.3107e-04 - val_loss: 0.0434\n",
      "Train on 12190 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.2877e-04 - val_loss: 0.0386\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.1416e-04 - val_loss: 0.0429\n",
      "Train on 12191 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.6146e-04 - val_loss: 0.0409\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.4980e-04 - val_loss: 0.0402\n",
      "Train on 12192 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.4294e-04 - val_loss: 0.0397\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.7118e-04 - val_loss: 0.0379\n",
      "Train on 12193 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.1069e-04 - val_loss: 0.0433\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.8177e-04 - val_loss: 0.0454\n",
      "Train on 12194 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.6361e-04 - val_loss: 0.0446\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.2457e-04 - val_loss: 0.0457\n",
      "Train on 12195 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.1982e-04 - val_loss: 0.0430\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.6617e-04 - val_loss: 0.0426\n",
      "Train on 12196 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.7344e-04 - val_loss: 0.0420\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.2917e-04 - val_loss: 0.0456\n",
      "Train on 12197 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.2944e-04 - val_loss: 0.0400\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.6884e-04 - val_loss: 0.0380\n",
      "Train on 12198 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.6137e-04 - val_loss: 0.0391\n",
      "Epoch 2/2\n",
      " - 7s - loss: 0.0011 - val_loss: 0.0396\n",
      "Train on 12199 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.3897e-04 - val_loss: 0.0429\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.1982e-04 - val_loss: 0.0412\n",
      "Train on 12200 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.8585e-04 - val_loss: 0.0427\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.2584e-04 - val_loss: 0.0417\n",
      "Train on 12201 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.1157e-04 - val_loss: 0.0384\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.5190e-04 - val_loss: 0.0358\n",
      "Train on 12202 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9.6747e-04 - val_loss: 0.0353\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.4785e-04 - val_loss: 0.0348\n",
      "Train on 12203 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.1486e-04 - val_loss: 0.0531\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.9862e-04 - val_loss: 0.0509\n",
      "Train on 12204 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.0345e-04 - val_loss: 0.0565\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.2240e-04 - val_loss: 0.0563\n",
      "Train on 12205 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.8230e-04 - val_loss: 0.0513\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.0513e-04 - val_loss: 0.0456\n",
      "Train on 12206 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.1534e-04 - val_loss: 0.0474\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.5801e-04 - val_loss: 0.0545\n",
      "Train on 12207 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9.7630e-04 - val_loss: 0.0504\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.0755e-04 - val_loss: 0.0517\n",
      "Train on 12208 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.2244e-04 - val_loss: 0.0423\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.8080e-04 - val_loss: 0.0441\n",
      "Train on 12209 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.7711e-04 - val_loss: 0.0447\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.4215e-04 - val_loss: 0.0418\n",
      "Train on 12210 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.4609e-04 - val_loss: 0.0419\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.9904e-04 - val_loss: 0.0463\n",
      "Train on 12211 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.4327e-04 - val_loss: 0.0409\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.3943e-04 - val_loss: 0.0432\n",
      "Train on 12212 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.4110e-04 - val_loss: 0.0430\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.7595e-04 - val_loss: 0.0437\n",
      "Train on 12213 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.5515e-04 - val_loss: 0.0473\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.0530e-04 - val_loss: 0.0462\n",
      "Train on 12214 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.7329e-04 - val_loss: 0.0465\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6716e-04 - val_loss: 0.0501\n",
      "Train on 12215 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.9605e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.2801e-04 - val_loss: 0.0466\n",
      "Train on 12216 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.4763e-04 - val_loss: 0.0451\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.4518e-04 - val_loss: 0.0470\n",
      "Train on 12217 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.2783e-04 - val_loss: 0.0458\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.8926e-04 - val_loss: 0.0451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12218 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.6246e-04 - val_loss: 0.0479\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.0827e-04 - val_loss: 0.0438\n",
      "Train on 12219 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.7693e-04 - val_loss: 0.0424\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.2600e-04 - val_loss: 0.0426\n",
      "Train on 12220 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.0067e-04 - val_loss: 0.0471\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.9895e-04 - val_loss: 0.0432\n",
      "Train on 12221 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.9142e-04 - val_loss: 0.0504\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.0430e-04 - val_loss: 0.0531\n",
      "Train on 12222 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 8.5396e-04 - val_loss: 0.0535\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.5396e-04 - val_loss: 0.0516\n",
      "Train on 12223 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.8398e-04 - val_loss: 0.0390\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.0694e-04 - val_loss: 0.0388\n",
      "Train on 12224 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.8136e-04 - val_loss: 0.0227\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.5132e-04 - val_loss: 0.0218\n",
      "Train on 12225 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.2786e-04 - val_loss: 0.0371\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.2830e-04 - val_loss: 0.0342\n",
      "Train on 12226 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.3790e-04 - val_loss: 0.0339\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.2394e-04 - val_loss: 0.0335\n",
      "Train on 12227 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.0907e-04 - val_loss: 0.0298\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.2726e-04 - val_loss: 0.0318\n",
      "Train on 12228 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.3125e-04 - val_loss: 0.0388\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.4872e-04 - val_loss: 0.0382\n",
      "Train on 12229 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.3348e-04 - val_loss: 0.0369\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.4038e-04 - val_loss: 0.0393\n",
      "Train on 12230 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.9666e-04 - val_loss: 0.0374\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.9327e-04 - val_loss: 0.0348\n",
      "Train on 12231 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.0916e-04 - val_loss: 0.0384\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.8203e-04 - val_loss: 0.0392\n",
      "Train on 12232 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.7001e-04 - val_loss: 0.0322\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.4253e-04 - val_loss: 0.0348\n",
      "Train on 12233 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.2555e-04 - val_loss: 0.0368\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.2262e-04 - val_loss: 0.0366\n",
      "Train on 12234 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.6172e-04 - val_loss: 0.0386\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.9271e-04 - val_loss: 0.0361\n",
      "Train on 12235 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.2719e-04 - val_loss: 0.0384\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6241e-04 - val_loss: 0.0366\n",
      "Train on 12236 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.3532e-04 - val_loss: 0.0348\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.2338e-04 - val_loss: 0.0402\n",
      "Train on 12237 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.8601e-04 - val_loss: 0.0370\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0010 - val_loss: 0.0453\n",
      "Train on 12238 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.9904e-04 - val_loss: 0.0394\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.7588e-04 - val_loss: 0.0327\n",
      "Train on 12239 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.0268e-04 - val_loss: 0.0329\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6419e-04 - val_loss: 0.0313\n",
      "Train on 12240 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.1845e-04 - val_loss: 0.0347\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.3148e-04 - val_loss: 0.0320\n",
      "Train on 12241 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.6605e-04 - val_loss: 0.0301\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.2968e-04 - val_loss: 0.0311\n",
      "Train on 12242 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.7162e-04 - val_loss: 0.0381\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.8381e-04 - val_loss: 0.0418\n",
      "Train on 12243 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.0147e-04 - val_loss: 0.0420\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.4176e-04 - val_loss: 0.0384\n",
      "Train on 12244 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.1446e-04 - val_loss: 0.0381\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.0691e-04 - val_loss: 0.0421\n",
      "Train on 12245 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.9914e-04 - val_loss: 0.0434\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.7720e-04 - val_loss: 0.0382\n",
      "Train on 12246 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.6031e-04 - val_loss: 0.0375\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.4481e-04 - val_loss: 0.0454\n",
      "Train on 12247 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.0520e-04 - val_loss: 0.0366\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.7403e-04 - val_loss: 0.0323\n",
      "Train on 12248 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.0033e-04 - val_loss: 0.0419\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.1727e-04 - val_loss: 0.0416\n",
      "Train on 12249 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.0869e-04 - val_loss: 0.0361\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.3836e-04 - val_loss: 0.0389\n",
      "Train on 12250 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.5606e-04 - val_loss: 0.0364\n",
      "Epoch 2/2\n",
      " - 9s - loss: 8.1897e-04 - val_loss: 0.0407\n",
      "Train on 12251 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.1212e-04 - val_loss: 0.0378\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.9349e-04 - val_loss: 0.0438\n",
      "Train on 12252 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.6125e-04 - val_loss: 0.0384\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.8478e-04 - val_loss: 0.0399\n",
      "Train on 12253 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.8036e-04 - val_loss: 0.0275\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.2487e-04 - val_loss: 0.0301\n",
      "Train on 12254 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.8194e-04 - val_loss: 0.0276\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.3329e-04 - val_loss: 0.0295\n",
      "Train on 12255 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.9742e-04 - val_loss: 0.0332\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.7308e-04 - val_loss: 0.0350\n",
      "Train on 12256 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.6602e-04 - val_loss: 0.0485\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.7876e-04 - val_loss: 0.0500\n",
      "Train on 12257 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.3857e-04 - val_loss: 0.0488\n",
      "Epoch 2/2\n",
      " - 7s - loss: 8.2443e-04 - val_loss: 0.0469\n",
      "Train on 12258 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.2554e-04 - val_loss: 0.0414\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.8936e-04 - val_loss: 0.0400\n",
      "Train on 12259 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.1545e-04 - val_loss: 0.0413\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.0234e-04 - val_loss: 0.0416\n",
      "Train on 12260 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.5754e-04 - val_loss: 0.0371\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.8724e-04 - val_loss: 0.0393\n",
      "Train on 12261 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.8058e-04 - val_loss: 0.0389\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.2063e-04 - val_loss: 0.0404\n",
      "Train on 12262 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.1524e-04 - val_loss: 0.0403\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.1974e-04 - val_loss: 0.0369\n",
      "Train on 12263 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.3041e-04 - val_loss: 0.0412\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.2705e-04 - val_loss: 0.0448\n",
      "Train on 12264 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 5.7496e-04 - val_loss: 0.0419\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.1696e-04 - val_loss: 0.0427\n",
      "Train on 12265 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.3810e-04 - val_loss: 0.0354\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.5035e-04 - val_loss: 0.0357\n",
      "Train on 12266 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9.4022e-04 - val_loss: 0.0381\n",
      "Epoch 2/2\n",
      " - 7s - loss: 7.5422e-04 - val_loss: 0.0294\n",
      "Train on 12267 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.3532e-04 - val_loss: 0.0334\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.7676e-04 - val_loss: 0.0380\n",
      "Train on 12268 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.1685e-04 - val_loss: 0.0404\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.4260e-04 - val_loss: 0.0376\n",
      "Train on 12269 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9.0041e-04 - val_loss: 0.0387\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.0833e-04 - val_loss: 0.0414\n",
      "Train on 12270 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.5705e-04 - val_loss: 0.0370\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6205e-04 - val_loss: 0.0385\n",
      "Train on 12271 samples, validate on 1 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 8s - loss: 5.8869e-04 - val_loss: 0.0362\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.7599e-04 - val_loss: 0.0403\n",
      "Train on 12272 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.3589e-04 - val_loss: 0.0410\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.9106e-04 - val_loss: 0.0363\n",
      "Train on 12273 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.0213e-04 - val_loss: 0.0401\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.0741e-04 - val_loss: 0.0414\n",
      "Train on 12274 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.2099e-04 - val_loss: 0.0405\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.7719e-04 - val_loss: 0.0425\n",
      "Train on 12275 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.0598e-04 - val_loss: 0.0491\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.7355e-04 - val_loss: 0.0427\n",
      "Train on 12276 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.5808e-04 - val_loss: 0.0432\n",
      "Epoch 2/2\n",
      " - 8s - loss: 0.0011 - val_loss: 0.0464\n",
      "Train on 12277 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.5889e-04 - val_loss: 0.0352\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.4190e-04 - val_loss: 0.0329\n",
      "Train on 12278 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 6.1909e-04 - val_loss: 0.0344\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.9370e-04 - val_loss: 0.0393\n",
      "Train on 12279 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.2873e-04 - val_loss: 0.0343\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.1410e-04 - val_loss: 0.0414\n",
      "Train on 12280 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.2670e-04 - val_loss: 0.0384\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.0989e-04 - val_loss: 0.0373\n",
      "Train on 12281 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.5259e-04 - val_loss: 0.0416\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.8224e-04 - val_loss: 0.0387\n",
      "Train on 12282 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.0205e-04 - val_loss: 0.0437\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.3005e-04 - val_loss: 0.0442\n",
      "Train on 12283 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.9237e-04 - val_loss: 0.0415\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.9586e-04 - val_loss: 0.0519\n",
      "Train on 12284 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.9859e-04 - val_loss: 0.0442\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.8512e-04 - val_loss: 0.0391\n",
      "Train on 12285 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.0064e-04 - val_loss: 0.0334\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6716e-04 - val_loss: 0.0369\n",
      "Train on 12286 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.9520e-04 - val_loss: 0.0354\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.9526e-04 - val_loss: 0.0378\n",
      "Train on 12287 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 7.1804e-04 - val_loss: 0.0415\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.9669e-04 - val_loss: 0.0345\n",
      "Train on 12288 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.8533e-04 - val_loss: 0.0408\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.5271e-04 - val_loss: 0.0392\n",
      "Train on 12289 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.4830e-04 - val_loss: 0.0379\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.4548e-04 - val_loss: 0.0380\n",
      "Train on 12290 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.2415e-04 - val_loss: 0.0351\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.4403e-04 - val_loss: 0.0369\n",
      "Train on 12291 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.3450e-04 - val_loss: 0.0467\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.6093e-04 - val_loss: 0.0453\n",
      "Train on 12292 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.2938e-04 - val_loss: 0.0446\n",
      "Epoch 2/2\n",
      " - 7s - loss: 6.5997e-04 - val_loss: 0.0490\n",
      "Train on 12293 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.1544e-04 - val_loss: 0.0405\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.2735e-04 - val_loss: 0.0450\n",
      "Train on 12294 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.3433e-04 - val_loss: 0.0436\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6616e-04 - val_loss: 0.0434\n",
      "Train on 12295 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.3108e-04 - val_loss: 0.0410\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.7670e-04 - val_loss: 0.0408\n",
      "Train on 12296 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.4509e-04 - val_loss: 0.0434\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6540e-04 - val_loss: 0.0416\n",
      "Train on 12297 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.0439e-04 - val_loss: 0.0414\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.8584e-04 - val_loss: 0.0401\n",
      "Train on 12298 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 8.6354e-04 - val_loss: 0.0444\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.4389e-04 - val_loss: 0.0392\n",
      "Train on 12299 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.0360e-04 - val_loss: 0.0509\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.0419e-04 - val_loss: 0.0450\n",
      "Train on 12300 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.2761e-04 - val_loss: 0.0470\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.4300e-04 - val_loss: 0.0433\n",
      "Train on 12301 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.9334e-04 - val_loss: 0.0476\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.0577e-04 - val_loss: 0.0425\n",
      "Train on 12302 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.1409e-04 - val_loss: 0.0442\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.5651e-04 - val_loss: 0.0421\n",
      "Train on 12303 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.4622e-04 - val_loss: 0.0445\n",
      "Epoch 2/2\n",
      " - 7s - loss: 5.5632e-04 - val_loss: 0.0419\n",
      "Train on 12304 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.1826e-04 - val_loss: 0.0430\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.5538e-04 - val_loss: 0.0414\n",
      "Train on 12305 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.1005e-04 - val_loss: 0.0472\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.9943e-04 - val_loss: 0.0455\n",
      "Train on 12306 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.5610e-04 - val_loss: 0.0444\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.9592e-04 - val_loss: 0.0425\n",
      "Train on 12307 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.8447e-04 - val_loss: 0.0452\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.7524e-04 - val_loss: 0.0461\n",
      "Train on 12308 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.2277e-04 - val_loss: 0.0418\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.2095e-04 - val_loss: 0.0440\n",
      "Train on 12309 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.6711e-04 - val_loss: 0.0467\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.5658e-04 - val_loss: 0.0473\n",
      "Train on 12310 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 9.1258e-04 - val_loss: 0.0441\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.7395e-04 - val_loss: 0.0426\n",
      "Train on 12311 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.0595e-04 - val_loss: 0.0369\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.4087e-04 - val_loss: 0.0405\n",
      "Train on 12312 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.1978e-04 - val_loss: 0.0417\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.2058e-04 - val_loss: 0.0418\n",
      "Train on 12313 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.9356e-04 - val_loss: 0.0355\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.0685e-04 - val_loss: 0.0419\n",
      "Train on 12314 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.6558e-04 - val_loss: 0.0385\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.7579e-04 - val_loss: 0.0408\n",
      "Train on 12315 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.7126e-04 - val_loss: 0.0388\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6069e-04 - val_loss: 0.0387\n",
      "Train on 12316 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.4262e-04 - val_loss: 0.0379\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.9059e-04 - val_loss: 0.0391\n",
      "Train on 12317 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.9709e-04 - val_loss: 0.0378\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.5856e-04 - val_loss: 0.0386\n",
      "Train on 12318 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.1489e-04 - val_loss: 0.0392\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.6613e-04 - val_loss: 0.0408\n",
      "Train on 12319 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.3508e-04 - val_loss: 0.0451\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.2617e-04 - val_loss: 0.0434\n",
      "Train on 12320 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.7817e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 8s - loss: 9.2869e-04 - val_loss: 0.0392\n",
      "Train on 12321 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.5519e-04 - val_loss: 0.0483\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.4175e-04 - val_loss: 0.0449\n",
      "Train on 12322 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.0410e-04 - val_loss: 0.0487\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.9496e-04 - val_loss: 0.0480\n",
      "Train on 12323 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.6768e-04 - val_loss: 0.0426\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.4646e-04 - val_loss: 0.0422\n",
      "Train on 12324 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.9115e-04 - val_loss: 0.0371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 9s - loss: 6.7254e-04 - val_loss: 0.0360\n",
      "Train on 12325 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.7215e-04 - val_loss: 0.0439\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.0857e-04 - val_loss: 0.0421\n",
      "Train on 12326 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.6732e-04 - val_loss: 0.0357\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.8143e-04 - val_loss: 0.0387\n",
      "Train on 12327 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.7904e-04 - val_loss: 0.0264\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.7037e-04 - val_loss: 0.0272\n",
      "Train on 12328 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.7326e-04 - val_loss: 0.0502\n",
      "Epoch 2/2\n",
      " - 8s - loss: 4.4947e-04 - val_loss: 0.0539\n",
      "Train on 12329 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.9138e-04 - val_loss: 0.0554\n",
      "Epoch 2/2\n",
      " - 8s - loss: 4.7401e-04 - val_loss: 0.0589\n",
      "Train on 12330 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.5122e-04 - val_loss: 0.0455\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.8795e-04 - val_loss: 0.0460\n",
      "Train on 12331 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.3208e-04 - val_loss: 0.0453\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.0941e-04 - val_loss: 0.0437\n",
      "Train on 12332 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.9246e-04 - val_loss: 0.0412\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.8862e-04 - val_loss: 0.0437\n",
      "Train on 12333 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.8035e-04 - val_loss: 0.0436\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.2457e-04 - val_loss: 0.0441\n",
      "Train on 12334 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.1575e-04 - val_loss: 0.0448\n",
      "Epoch 2/2\n",
      " - 9s - loss: 9.0702e-04 - val_loss: 0.0462\n",
      "Train on 12335 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.9952e-04 - val_loss: 0.0459\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.7142e-04 - val_loss: 0.0455\n",
      "Train on 12336 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.4409e-04 - val_loss: 0.0451\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.5640e-04 - val_loss: 0.0451\n",
      "Train on 12337 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.8871e-04 - val_loss: 0.0435\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.0625e-04 - val_loss: 0.0449\n",
      "Train on 12338 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.2015e-04 - val_loss: 0.0466\n",
      "Epoch 2/2\n",
      " - 9s - loss: 8.3842e-04 - val_loss: 0.0460\n",
      "Train on 12339 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.7777e-04 - val_loss: 0.0431\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.6843e-04 - val_loss: 0.0465\n"
     ]
    }
   ],
   "source": [
    "res_4 = make_rolling_window(LSTM_model_4, train_X, train_y, val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.models.save_model(\n",
    "#     LSTM_model_4,\n",
    "#     './saved_models/LSTM_model_4_fit.hdf5',\n",
    "#     overwrite=True,\n",
    "#     include_optimizer=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inverse transform the predictions into the units we care about. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2 = StandardScaler()\n",
    "scaled = scaler_2.fit_transform(np.array(df_train.y).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = scaler_2.inverse_transform(np.array(res_4[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = scaler_2.inverse_transform(np.array(res_4[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 596.715\n"
     ]
    }
   ],
   "source": [
    "rmse = math.sqrt(mean_squared_error(predicts, actuals))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the RMSE without the rolling_window approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM_model_copy = keras.models.clone_model(LSTM_model_4)\n",
    "# LSTM_model_copy.set_weights(LSTM_model_4.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_copy = load_model('./saved_models/LSTM_model_4_fit.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_and_val_X = np.concatenate((train_X, val_X), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_val_y = np.concatenate((train_y, val_y), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12341,)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12341 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 5.8148e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.9582e-04 - val_loss: 0.0485\n",
      "Train on 12342 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 7.6007e-04 - val_loss: 0.0439\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.1701e-04 - val_loss: 0.0421\n",
      "Train on 12343 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.4487e-04 - val_loss: 0.0439\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.4975e-04 - val_loss: 0.0398\n",
      "Train on 12344 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.8533e-04 - val_loss: 0.0514\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.4684e-04 - val_loss: 0.0519\n",
      "Train on 12345 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.6137e-04 - val_loss: 0.0552\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.5816e-04 - val_loss: 0.0577\n",
      "Train on 12346 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.2000e-04 - val_loss: 0.0519\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.3381e-04 - val_loss: 0.0519\n",
      "Train on 12347 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.3213e-04 - val_loss: 0.0534\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.7873e-04 - val_loss: 0.0507\n",
      "Train on 12348 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.2773e-04 - val_loss: 0.0506\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.8025e-04 - val_loss: 0.0476\n",
      "Train on 12349 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.6974e-04 - val_loss: 0.0499\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.6115e-04 - val_loss: 0.0476\n",
      "Train on 12350 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.6054e-04 - val_loss: 0.0482\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.2747e-04 - val_loss: 0.0506\n",
      "Train on 12351 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 8.6742e-04 - val_loss: 0.0478\n",
      "Epoch 2/2\n",
      " - 8s - loss: 7.5183e-04 - val_loss: 0.0484\n",
      "Train on 12352 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.5845e-04 - val_loss: 0.0441\n",
      "Epoch 2/2\n",
      " - 8s - loss: 8.4059e-04 - val_loss: 0.0489\n",
      "Train on 12353 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.8796e-04 - val_loss: 0.0454\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.2304e-04 - val_loss: 0.0471\n",
      "Train on 12354 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.8407e-04 - val_loss: 0.0497\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.1868e-04 - val_loss: 0.0493\n",
      "Train on 12355 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.2552e-04 - val_loss: 0.0466\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.5622e-04 - val_loss: 0.0474\n",
      "Train on 12356 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.1385e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.7781e-04 - val_loss: 0.0501\n",
      "Train on 12357 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.7332e-04 - val_loss: 0.0493\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.4939e-04 - val_loss: 0.0475\n",
      "Train on 12358 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1843e-04 - val_loss: 0.0467\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.0644e-04 - val_loss: 0.0439\n",
      "Train on 12359 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.9855e-04 - val_loss: 0.0449\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.2558e-04 - val_loss: 0.0443\n",
      "Train on 12360 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.9199e-04 - val_loss: 0.0480\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.8400e-04 - val_loss: 0.0451\n",
      "Train on 12361 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 9.7354e-04 - val_loss: 0.0432\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.3028e-04 - val_loss: 0.0460\n",
      "Train on 12362 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.7102e-04 - val_loss: 0.0448\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.6633e-04 - val_loss: 0.0450\n",
      "Train on 12363 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.9129e-04 - val_loss: 0.0494\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.8474e-04 - val_loss: 0.0474\n",
      "Train on 12364 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.2536e-04 - val_loss: 0.0467\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.8621e-04 - val_loss: 0.0481\n",
      "Train on 12365 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.7994e-04 - val_loss: 0.0489\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.1319e-04 - val_loss: 0.0515\n",
      "Train on 12366 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.9349e-04 - val_loss: 0.0537\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.6894e-04 - val_loss: 0.0539\n",
      "Train on 12367 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.6094e-04 - val_loss: 0.0429\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.8228e-04 - val_loss: 0.0390\n",
      "Train on 12368 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.2656e-04 - val_loss: 0.0356\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.8390e-04 - val_loss: 0.0350\n",
      "Train on 12369 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9590e-04 - val_loss: 0.0365\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.4206e-04 - val_loss: 0.0355\n",
      "Train on 12370 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9492e-04 - val_loss: 0.0331\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.0974e-04 - val_loss: 0.0347\n",
      "Train on 12371 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.9181e-04 - val_loss: 0.0359\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.5289e-04 - val_loss: 0.0407\n",
      "Train on 12372 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.4564e-04 - val_loss: 0.0351\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5365e-04 - val_loss: 0.0381\n",
      "Train on 12373 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.8665e-04 - val_loss: 0.0413\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.9445e-04 - val_loss: 0.0440\n",
      "Train on 12374 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.8412e-04 - val_loss: 0.0462\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.7658e-04 - val_loss: 0.0421\n",
      "Train on 12375 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.2146e-04 - val_loss: 0.0435\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.0342e-04 - val_loss: 0.0435\n",
      "Train on 12376 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.1844e-04 - val_loss: 0.0443\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.2188e-04 - val_loss: 0.0426\n",
      "Train on 12377 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.6480e-04 - val_loss: 0.0398\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.3674e-04 - val_loss: 0.0425\n",
      "Train on 12378 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.1196e-04 - val_loss: 0.0420\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.0300e-04 - val_loss: 0.0408\n",
      "Train on 12379 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.5413e-04 - val_loss: 0.0433\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.9871e-04 - val_loss: 0.0425\n",
      "Train on 12380 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.4345e-04 - val_loss: 0.0454\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.9465e-04 - val_loss: 0.0464\n",
      "Train on 12381 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.0464e-04 - val_loss: 0.0441\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.7582e-04 - val_loss: 0.0437\n",
      "Train on 12382 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.3038e-04 - val_loss: 0.0465\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.9327e-04 - val_loss: 0.0448\n",
      "Train on 12383 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.9201e-04 - val_loss: 0.0437\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.4322e-04 - val_loss: 0.0431\n",
      "Train on 12384 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.4018e-04 - val_loss: 0.0436\n",
      "Epoch 2/2\n",
      " - 8s - loss: 4.8637e-04 - val_loss: 0.0417\n",
      "Train on 12385 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.6391e-04 - val_loss: 0.0448\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.2289e-04 - val_loss: 0.0473\n",
      "Train on 12386 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.0805e-04 - val_loss: 0.0463\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.4718e-04 - val_loss: 0.0441\n",
      "Train on 12387 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.2196e-04 - val_loss: 0.0444\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.5204e-04 - val_loss: 0.0446\n",
      "Train on 12388 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.1770e-04 - val_loss: 0.0475\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.7250e-04 - val_loss: 0.0445\n",
      "Train on 12389 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.7599e-04 - val_loss: 0.0403\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.5243e-04 - val_loss: 0.0401\n",
      "Train on 12390 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.4611e-04 - val_loss: 0.0388\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.0332e-04 - val_loss: 0.0409\n",
      "Train on 12391 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.1541e-04 - val_loss: 0.0456\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.5545e-04 - val_loss: 0.0467\n",
      "Train on 12392 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.7627e-04 - val_loss: 0.0464\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.4579e-04 - val_loss: 0.0447\n",
      "Train on 12393 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.2724e-04 - val_loss: 0.0462\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.4060e-04 - val_loss: 0.0426\n",
      "Train on 12394 samples, validate on 1 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 9s - loss: 8.1042e-04 - val_loss: 0.0404\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.8288e-04 - val_loss: 0.0428\n",
      "Train on 12395 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.8810e-04 - val_loss: 0.0437\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.9308e-04 - val_loss: 0.0437\n",
      "Train on 12396 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.0254e-04 - val_loss: 0.0471\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.7872e-04 - val_loss: 0.0471\n",
      "Train on 12397 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.0220e-04 - val_loss: 0.0501\n",
      "Epoch 2/2\n",
      " - 8s - loss: 4.4120e-04 - val_loss: 0.0516\n",
      "Train on 12398 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.2328e-04 - val_loss: 0.0476\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.7248e-04 - val_loss: 0.0498\n",
      "Train on 12399 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 6.1911e-04 - val_loss: 0.0458\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.6389e-04 - val_loss: 0.0474\n",
      "Train on 12400 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.0239e-04 - val_loss: 0.0460\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.8912e-04 - val_loss: 0.0459\n",
      "Train on 12401 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.6422e-04 - val_loss: 0.0467\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.7355e-04 - val_loss: 0.0449\n",
      "Train on 12402 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 8.8652e-04 - val_loss: 0.0478\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.4354e-04 - val_loss: 0.0499\n",
      "Train on 12403 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.1963e-04 - val_loss: 0.0446\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.9674e-04 - val_loss: 0.0453\n",
      "Train on 12404 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.6272e-04 - val_loss: 0.0437\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.3539e-04 - val_loss: 0.0419\n",
      "Train on 12405 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.1992e-04 - val_loss: 0.0430\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0845e-04 - val_loss: 0.0430\n",
      "Train on 12406 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 7.8753e-04 - val_loss: 0.0446\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5617e-04 - val_loss: 0.0441\n",
      "Train on 12407 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.4883e-04 - val_loss: 0.0489\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.6925e-04 - val_loss: 0.0486\n",
      "Train on 12408 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5013e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.3110e-04 - val_loss: 0.0476\n",
      "Train on 12409 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1964e-04 - val_loss: 0.0428\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5392e-04 - val_loss: 0.0404\n",
      "Train on 12410 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6086e-04 - val_loss: 0.0432\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.6583e-04 - val_loss: 0.0434\n",
      "Train on 12411 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.2028e-04 - val_loss: 0.0433\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.9075e-04 - val_loss: 0.0404\n",
      "Train on 12412 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 7.1797e-04 - val_loss: 0.0368\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.5763e-04 - val_loss: 0.0403\n",
      "Train on 12413 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.1290e-04 - val_loss: 0.0423\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.9209e-04 - val_loss: 0.0410\n",
      "Train on 12414 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.1436e-04 - val_loss: 0.0439\n",
      "Epoch 2/2\n",
      " - 8s - loss: 6.5138e-04 - val_loss: 0.0429\n",
      "Train on 12415 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.0276e-04 - val_loss: 0.0445\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.1801e-04 - val_loss: 0.0424\n",
      "Train on 12416 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.8084e-04 - val_loss: 0.0458\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.6279e-04 - val_loss: 0.0461\n",
      "Train on 12417 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.7010e-04 - val_loss: 0.0441\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.7547e-04 - val_loss: 0.0447\n",
      "Train on 12418 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.8092e-04 - val_loss: 0.0405\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.9585e-04 - val_loss: 0.0413\n",
      "Train on 12419 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.8144e-04 - val_loss: 0.0425\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.5034e-04 - val_loss: 0.0463\n",
      "Train on 12420 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 7.0890e-04 - val_loss: 0.0457\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.4075e-04 - val_loss: 0.0459\n",
      "Train on 12421 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.1343e-04 - val_loss: 0.0428\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.6693e-04 - val_loss: 0.0445\n",
      "Train on 12422 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.1871e-04 - val_loss: 0.0425\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.8063e-04 - val_loss: 0.0423\n",
      "Train on 12423 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.7696e-04 - val_loss: 0.0406\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.0872e-04 - val_loss: 0.0431\n",
      "Train on 12424 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 6.1823e-04 - val_loss: 0.0411\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.2437e-04 - val_loss: 0.0408\n",
      "Train on 12425 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.3095e-04 - val_loss: 0.0427\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8170e-04 - val_loss: 0.0431\n",
      "Train on 12426 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.7936e-04 - val_loss: 0.0437\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.6025e-04 - val_loss: 0.0454\n",
      "Train on 12427 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.9158e-04 - val_loss: 0.0448\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.7116e-04 - val_loss: 0.0458\n",
      "Train on 12428 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.6815e-04 - val_loss: 0.0441\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1685e-04 - val_loss: 0.0480\n",
      "Train on 12429 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 7.6112e-04 - val_loss: 0.0459\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.9683e-04 - val_loss: 0.0451\n",
      "Train on 12430 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.7537e-04 - val_loss: 0.0437\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.6091e-04 - val_loss: 0.0459\n",
      "Train on 12431 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1844e-04 - val_loss: 0.0458\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.9987e-04 - val_loss: 0.0437\n",
      "Train on 12432 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.3922e-04 - val_loss: 0.0427\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.1327e-04 - val_loss: 0.0441\n",
      "Train on 12433 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6336e-04 - val_loss: 0.0453\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.1209e-04 - val_loss: 0.0449\n",
      "Train on 12434 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.2827e-04 - val_loss: 0.0455\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.9767e-04 - val_loss: 0.0442\n",
      "Train on 12435 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1169e-04 - val_loss: 0.0440\n",
      "Epoch 2/2\n",
      " - 10s - loss: 7.1131e-04 - val_loss: 0.0433\n",
      "Train on 12436 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.2475e-04 - val_loss: 0.0440\n",
      "Epoch 2/2\n",
      " - 10s - loss: 9.7833e-04 - val_loss: 0.0433\n",
      "Train on 12437 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5635e-04 - val_loss: 0.0470\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.8501e-04 - val_loss: 0.0448\n",
      "Train on 12438 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9552e-04 - val_loss: 0.0484\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1649e-04 - val_loss: 0.0475\n",
      "Train on 12439 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.7134e-04 - val_loss: 0.0445\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.6382e-04 - val_loss: 0.0442\n",
      "Train on 12440 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.7145e-04 - val_loss: 0.0421\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.6262e-04 - val_loss: 0.0434\n",
      "Train on 12441 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.3718e-04 - val_loss: 0.0439\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.8388e-04 - val_loss: 0.0429\n",
      "Train on 12442 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.8420e-04 - val_loss: 0.0399\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5960e-04 - val_loss: 0.0439\n",
      "Train on 12443 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.7204e-04 - val_loss: 0.0453\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.6180e-04 - val_loss: 0.0462\n",
      "Train on 12444 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.8975e-04 - val_loss: 0.0476\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.0119e-04 - val_loss: 0.0467\n",
      "Train on 12445 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 7.7913e-04 - val_loss: 0.0421\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5914e-04 - val_loss: 0.0441\n",
      "Train on 12446 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4324e-04 - val_loss: 0.0465\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.2202e-04 - val_loss: 0.0445\n",
      "Train on 12447 samples, validate on 1 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 10s - loss: 4.4993e-04 - val_loss: 0.0435\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.8267e-04 - val_loss: 0.0442\n",
      "Train on 12448 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2677e-04 - val_loss: 0.0440\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.3236e-04 - val_loss: 0.0467\n",
      "Train on 12449 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.3158e-04 - val_loss: 0.0516\n",
      "Epoch 2/2\n",
      " - 10s - loss: 7.9487e-04 - val_loss: 0.0493\n",
      "Train on 12450 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.9852e-04 - val_loss: 0.0497\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.6936e-04 - val_loss: 0.0530\n",
      "Train on 12451 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 8.1387e-04 - val_loss: 0.0500\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.2831e-04 - val_loss: 0.0465\n",
      "Train on 12452 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 6.1476e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.1005e-04 - val_loss: 0.0438\n",
      "Train on 12453 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.0335e-04 - val_loss: 0.0439\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5138e-04 - val_loss: 0.0447\n",
      "Train on 12454 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 6.1895e-04 - val_loss: 0.0449\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.3207e-04 - val_loss: 0.0438\n",
      "Train on 12455 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.3996e-04 - val_loss: 0.0449\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.3130e-04 - val_loss: 0.0448\n",
      "Train on 12456 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.0334e-04 - val_loss: 0.0428\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.1204e-04 - val_loss: 0.0439\n",
      "Train on 12457 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 5.0408e-04 - val_loss: 0.0447\n",
      "Epoch 2/2\n",
      " - 8s - loss: 4.6090e-04 - val_loss: 0.0425\n",
      "Train on 12458 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.9403e-04 - val_loss: 0.0428\n",
      "Epoch 2/2\n",
      " - 10s - loss: 8.0340e-04 - val_loss: 0.0469\n",
      "Train on 12459 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.8725e-04 - val_loss: 0.0490\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.2004e-04 - val_loss: 0.0500\n",
      "Train on 12460 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.7258e-04 - val_loss: 0.0523\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0200e-04 - val_loss: 0.0506\n",
      "Train on 12461 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.3461e-04 - val_loss: 0.0502\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.6846e-04 - val_loss: 0.0467\n",
      "Train on 12462 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.3115e-04 - val_loss: 0.0476\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0318e-04 - val_loss: 0.0441\n",
      "Train on 12463 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9472e-04 - val_loss: 0.0393\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.3101e-04 - val_loss: 0.0422\n",
      "Train on 12464 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.7556e-04 - val_loss: 0.0434\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1985e-04 - val_loss: 0.0428\n",
      "Train on 12465 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.8013e-04 - val_loss: 0.0435\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9628e-04 - val_loss: 0.0446\n",
      "Train on 12466 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.0226e-04 - val_loss: 0.0422\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.4369e-04 - val_loss: 0.0458\n",
      "Train on 12467 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6332e-04 - val_loss: 0.0464\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.2082e-04 - val_loss: 0.0446\n",
      "Train on 12468 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5058e-04 - val_loss: 0.0438\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5557e-04 - val_loss: 0.0423\n",
      "Train on 12469 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5460e-04 - val_loss: 0.0418\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8171e-04 - val_loss: 0.0425\n",
      "Train on 12470 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1608e-04 - val_loss: 0.0433\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.3029e-04 - val_loss: 0.0414\n",
      "Train on 12471 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.6278e-04 - val_loss: 0.0419\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9002e-04 - val_loss: 0.0433\n",
      "Train on 12472 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6196e-04 - val_loss: 0.0442\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.3180e-04 - val_loss: 0.0447\n",
      "Train on 12473 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.8877e-04 - val_loss: 0.0445\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.7054e-04 - val_loss: 0.0456\n",
      "Train on 12474 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.7278e-04 - val_loss: 0.0422\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7754e-04 - val_loss: 0.0425\n",
      "Train on 12475 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.0541e-04 - val_loss: 0.0453\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5185e-04 - val_loss: 0.0463\n",
      "Train on 12476 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2578e-04 - val_loss: 0.0472\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.9475e-04 - val_loss: 0.0438\n",
      "Train on 12477 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.8831e-04 - val_loss: 0.0437\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8433e-04 - val_loss: 0.0458\n",
      "Train on 12478 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 8.0165e-04 - val_loss: 0.0455\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.6604e-04 - val_loss: 0.0432\n",
      "Train on 12479 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.8433e-04 - val_loss: 0.0425\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.6916e-04 - val_loss: 0.0417\n",
      "Train on 12480 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.9303e-04 - val_loss: 0.0460\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9460e-04 - val_loss: 0.0497\n",
      "Train on 12481 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.0982e-04 - val_loss: 0.0451\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8821e-04 - val_loss: 0.0491\n",
      "Train on 12482 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.3652e-04 - val_loss: 0.0348\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3381e-04 - val_loss: 0.0332\n",
      "Train on 12483 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7423e-04 - val_loss: 0.0362\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5804e-04 - val_loss: 0.0340\n",
      "Train on 12484 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5884e-04 - val_loss: 0.0371\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0856e-04 - val_loss: 0.0376\n",
      "Train on 12485 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.3017e-04 - val_loss: 0.0391\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.5074e-04 - val_loss: 0.0386\n",
      "Train on 12486 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2444e-04 - val_loss: 0.0435\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0806e-04 - val_loss: 0.0420\n",
      "Train on 12487 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.3698e-04 - val_loss: 0.0422\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.7747e-04 - val_loss: 0.0411\n",
      "Train on 12488 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.8151e-04 - val_loss: 0.0420\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1630e-04 - val_loss: 0.0419\n",
      "Train on 12489 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.3196e-04 - val_loss: 0.0436\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.2180e-04 - val_loss: 0.0421\n",
      "Train on 12490 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 4.4814e-04 - val_loss: 0.0421\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6288e-04 - val_loss: 0.0434\n",
      "Train on 12491 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.2105e-04 - val_loss: 0.0450\n",
      "Epoch 2/2\n",
      " - 8s - loss: 5.0166e-04 - val_loss: 0.0446\n",
      "Train on 12492 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.7337e-04 - val_loss: 0.0446\n",
      "Epoch 2/2\n",
      " - 10s - loss: 8.1087e-04 - val_loss: 0.0421\n",
      "Train on 12493 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.7838e-04 - val_loss: 0.0421\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8532e-04 - val_loss: 0.0417\n",
      "Train on 12494 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5213e-04 - val_loss: 0.0412\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.2668e-04 - val_loss: 0.0397\n",
      "Train on 12495 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.8852e-04 - val_loss: 0.0431\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8697e-04 - val_loss: 0.0446\n",
      "Train on 12496 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.5870e-04 - val_loss: 0.0435\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.0171e-04 - val_loss: 0.0432\n",
      "Train on 12497 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 7.0182e-04 - val_loss: 0.0444\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9090e-04 - val_loss: 0.0406\n",
      "Train on 12498 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.0043e-04 - val_loss: 0.0404\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.0566e-04 - val_loss: 0.0437\n",
      "Train on 12499 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.9945e-04 - val_loss: 0.0419\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.2741e-04 - val_loss: 0.0428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12500 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.8003e-04 - val_loss: 0.0417\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4947e-04 - val_loss: 0.0407\n",
      "Train on 12501 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.0064e-04 - val_loss: 0.0438\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1509e-04 - val_loss: 0.0432\n",
      "Train on 12502 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.3845e-04 - val_loss: 0.0424\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8686e-04 - val_loss: 0.0415\n",
      "Train on 12503 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6699e-04 - val_loss: 0.0416\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1915e-04 - val_loss: 0.0425\n",
      "Train on 12504 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2416e-04 - val_loss: 0.0423\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4292e-04 - val_loss: 0.0449\n",
      "Train on 12505 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.0644e-04 - val_loss: 0.0397\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1473e-04 - val_loss: 0.0373\n",
      "Train on 12506 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.9659e-04 - val_loss: 0.0366\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5950e-04 - val_loss: 0.0345\n",
      "Train on 12507 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2748e-04 - val_loss: 0.0447\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.7549e-04 - val_loss: 0.0448\n",
      "Train on 12508 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1220e-04 - val_loss: 0.0620\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.1196e-04 - val_loss: 0.0636\n",
      "Train on 12509 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.8137e-04 - val_loss: 0.0570\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.3231e-04 - val_loss: 0.0590\n",
      "Train on 12510 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9593e-04 - val_loss: 0.0561\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.8478e-04 - val_loss: 0.0528\n",
      "Train on 12511 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 5.0931e-04 - val_loss: 0.0506\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9540e-04 - val_loss: 0.0469\n",
      "Train on 12512 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.4436e-04 - val_loss: 0.0464\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6661e-04 - val_loss: 0.0455\n",
      "Train on 12513 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6542e-04 - val_loss: 0.0463\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8314e-04 - val_loss: 0.0442\n",
      "Train on 12514 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9722e-04 - val_loss: 0.0459\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.8767e-04 - val_loss: 0.0456\n",
      "Train on 12515 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.4544e-04 - val_loss: 0.0435\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4982e-04 - val_loss: 0.0479\n",
      "Train on 12516 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.4948e-04 - val_loss: 0.0466\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.5256e-04 - val_loss: 0.0458\n",
      "Train on 12517 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.0275e-04 - val_loss: 0.0399\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8840e-04 - val_loss: 0.0442\n",
      "Train on 12518 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9639e-04 - val_loss: 0.0451\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.5405e-04 - val_loss: 0.0434\n",
      "Train on 12519 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5420e-04 - val_loss: 0.0435\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.5960e-04 - val_loss: 0.0425\n",
      "Train on 12520 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 7.0511e-04 - val_loss: 0.0451\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4896e-04 - val_loss: 0.0453\n",
      "Train on 12521 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.3110e-04 - val_loss: 0.0432\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6057e-04 - val_loss: 0.0417\n",
      "Train on 12522 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5868e-04 - val_loss: 0.0429\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.5794e-04 - val_loss: 0.0443\n",
      "Train on 12523 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2833e-04 - val_loss: 0.0491\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.9471e-04 - val_loss: 0.0461\n",
      "Train on 12524 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1425e-04 - val_loss: 0.0488\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4754e-04 - val_loss: 0.0485\n",
      "Train on 12525 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5703e-04 - val_loss: 0.0481\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9098e-04 - val_loss: 0.0479\n",
      "Train on 12526 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2964e-04 - val_loss: 0.0480\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.3901e-04 - val_loss: 0.0442\n",
      "Train on 12527 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.5213e-04 - val_loss: 0.0454\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5509e-04 - val_loss: 0.0468\n",
      "Train on 12528 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7400e-04 - val_loss: 0.0479\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.1091e-04 - val_loss: 0.0501\n",
      "Train on 12529 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.4722e-04 - val_loss: 0.0484\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.3029e-04 - val_loss: 0.0456\n",
      "Train on 12530 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.2958e-04 - val_loss: 0.0447\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3315e-04 - val_loss: 0.0466\n",
      "Train on 12531 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.1103e-04 - val_loss: 0.0429\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0903e-04 - val_loss: 0.0437\n",
      "Train on 12532 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.0968e-04 - val_loss: 0.0424\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.8747e-04 - val_loss: 0.0435\n",
      "Train on 12533 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2300e-04 - val_loss: 0.0425\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.2809e-04 - val_loss: 0.0436\n",
      "Train on 12534 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.6766e-04 - val_loss: 0.0433\n",
      "Epoch 2/2\n",
      " - 9s - loss: 6.1206e-04 - val_loss: 0.0425\n",
      "Train on 12535 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9369e-04 - val_loss: 0.0429\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.8330e-04 - val_loss: 0.0446\n",
      "Train on 12536 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.0733e-04 - val_loss: 0.0444\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.9672e-04 - val_loss: 0.0425\n",
      "Train on 12537 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4815e-04 - val_loss: 0.0421\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7886e-04 - val_loss: 0.0401\n",
      "Train on 12538 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.6078e-04 - val_loss: 0.0415\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.4179e-04 - val_loss: 0.0444\n",
      "Train on 12539 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9159e-04 - val_loss: 0.0407\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.9446e-04 - val_loss: 0.0409\n",
      "Train on 12540 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.1381e-04 - val_loss: 0.0445\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0616e-04 - val_loss: 0.0410\n",
      "Train on 12541 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.8126e-04 - val_loss: 0.0424\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.7135e-04 - val_loss: 0.0425\n",
      "Train on 12542 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4767e-04 - val_loss: 0.0363\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9511e-04 - val_loss: 0.0362\n",
      "Train on 12543 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 8.5871e-04 - val_loss: 0.0337\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7937e-04 - val_loss: 0.0354\n",
      "Train on 12544 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2798e-04 - val_loss: 0.0483\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.4469e-04 - val_loss: 0.0493\n",
      "Train on 12545 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5651e-04 - val_loss: 0.0547\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.8736e-04 - val_loss: 0.0533\n",
      "Train on 12546 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.4375e-04 - val_loss: 0.0483\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.7041e-04 - val_loss: 0.0461\n",
      "Train on 12547 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1517e-04 - val_loss: 0.0451\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1775e-04 - val_loss: 0.0471\n",
      "Train on 12548 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1118e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.2321e-04 - val_loss: 0.0445\n",
      "Train on 12549 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.4059e-04 - val_loss: 0.0475\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3933e-04 - val_loss: 0.0462\n",
      "Train on 12550 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 5.1507e-04 - val_loss: 0.0463\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3229e-04 - val_loss: 0.0466\n",
      "Train on 12551 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2440e-04 - val_loss: 0.0494\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.2821e-04 - val_loss: 0.0486\n",
      "Train on 12552 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1902e-04 - val_loss: 0.0490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 10s - loss: 5.6129e-04 - val_loss: 0.0479\n",
      "Train on 12553 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5645e-04 - val_loss: 0.0492\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1804e-04 - val_loss: 0.0489\n",
      "Train on 12554 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.5387e-04 - val_loss: 0.0469\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.5990e-04 - val_loss: 0.0453\n",
      "Train on 12555 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7109e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.8560e-04 - val_loss: 0.0431\n",
      "Train on 12556 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2685e-04 - val_loss: 0.0462\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1109e-04 - val_loss: 0.0471\n",
      "Train on 12557 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.8202e-04 - val_loss: 0.0428\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.0596e-04 - val_loss: 0.0472\n",
      "Train on 12558 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7355e-04 - val_loss: 0.0456\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.1677e-04 - val_loss: 0.0481\n",
      "Train on 12559 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6294e-04 - val_loss: 0.0498\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5273e-04 - val_loss: 0.0482\n",
      "Train on 12560 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.8629e-04 - val_loss: 0.0478\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.2320e-04 - val_loss: 0.0497\n",
      "Train on 12561 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5080e-04 - val_loss: 0.0473\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.7639e-04 - val_loss: 0.0443\n",
      "Train on 12562 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9805e-04 - val_loss: 0.0505\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.5512e-04 - val_loss: 0.0479\n",
      "Train on 12563 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.8819e-04 - val_loss: 0.0472\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9238e-04 - val_loss: 0.0456\n",
      "Train on 12564 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.9915e-04 - val_loss: 0.0440\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3090e-04 - val_loss: 0.0472\n",
      "Train on 12565 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5121e-04 - val_loss: 0.0465\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1258e-04 - val_loss: 0.0464\n",
      "Train on 12566 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.0963e-04 - val_loss: 0.0681\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6047e-04 - val_loss: 0.0708\n",
      "Train on 12567 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4984e-04 - val_loss: 0.0786\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.9157e-04 - val_loss: 0.0785\n",
      "Train on 12568 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5559e-04 - val_loss: 0.0318\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.8090e-04 - val_loss: 0.0297\n",
      "Train on 12569 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 4.7856e-04 - val_loss: 0.0321\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.1995e-04 - val_loss: 0.0318\n",
      "Train on 12570 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 4.5428e-04 - val_loss: 0.0427\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6443e-04 - val_loss: 0.0389\n",
      "Train on 12571 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.0763e-04 - val_loss: 0.0398\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8660e-04 - val_loss: 0.0426\n",
      "Train on 12572 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 4.1960e-04 - val_loss: 0.0509\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.3142e-04 - val_loss: 0.0474\n",
      "Train on 12573 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2269e-04 - val_loss: 0.0473\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1667e-04 - val_loss: 0.0520\n",
      "Train on 12574 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2539e-04 - val_loss: 0.0461\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6360e-04 - val_loss: 0.0491\n",
      "Train on 12575 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5953e-04 - val_loss: 0.0486\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3748e-04 - val_loss: 0.0495\n",
      "Train on 12576 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.1174e-04 - val_loss: 0.0460\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.1119e-04 - val_loss: 0.0458\n",
      "Train on 12577 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4562e-04 - val_loss: 0.0395\n",
      "Epoch 2/2\n",
      " - 11s - loss: 4.1994e-04 - val_loss: 0.0409\n",
      "Train on 12578 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.3953e-04 - val_loss: 0.0389\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3946e-04 - val_loss: 0.0376\n",
      "Train on 12579 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7311e-04 - val_loss: 0.0361\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.6522e-04 - val_loss: 0.0390\n",
      "Train on 12580 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 4.8558e-04 - val_loss: 0.0371\n",
      "Epoch 2/2\n",
      " - 12s - loss: 6.0050e-04 - val_loss: 0.0387\n",
      "Train on 12581 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 7.1441e-04 - val_loss: 0.0363\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.4916e-04 - val_loss: 0.0409\n",
      "Train on 12582 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.4628e-04 - val_loss: 0.0404\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.8127e-04 - val_loss: 0.0379\n",
      "Train on 12583 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6432e-04 - val_loss: 0.0378\n",
      "Epoch 2/2\n",
      " - 11s - loss: 4.2928e-04 - val_loss: 0.0395\n",
      "Train on 12584 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.7481e-04 - val_loss: 0.0398\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.7626e-04 - val_loss: 0.0402\n",
      "Train on 12585 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 5.5846e-04 - val_loss: 0.0382\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9740e-04 - val_loss: 0.0407\n",
      "Train on 12586 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2357e-04 - val_loss: 0.0418\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.6245e-04 - val_loss: 0.0403\n",
      "Train on 12587 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.8884e-04 - val_loss: 0.0417\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3960e-04 - val_loss: 0.0399\n",
      "Train on 12588 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 4.7291e-04 - val_loss: 0.0407\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.5570e-04 - val_loss: 0.0404\n",
      "Train on 12589 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5854e-04 - val_loss: 0.0390\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.9460e-04 - val_loss: 0.0406\n",
      "Train on 12590 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.7848e-04 - val_loss: 0.0542\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.8831e-04 - val_loss: 0.0533\n",
      "Train on 12591 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.3974e-04 - val_loss: 0.0569\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.8772e-04 - val_loss: 0.0538\n",
      "Train on 12592 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.1802e-04 - val_loss: 0.0209\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.1819e-04 - val_loss: 0.0204\n",
      "Train on 12593 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5108e-04 - val_loss: 0.0166\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4271e-04 - val_loss: 0.0178\n",
      "Train on 12594 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7493e-04 - val_loss: 0.0241\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7506e-04 - val_loss: 0.0254\n",
      "Train on 12595 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.0650e-04 - val_loss: 0.0263\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7053e-04 - val_loss: 0.0273\n",
      "Train on 12596 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.4550e-04 - val_loss: 0.0306\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6484e-04 - val_loss: 0.0320\n",
      "Train on 12597 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7806e-04 - val_loss: 0.0321\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6883e-04 - val_loss: 0.0300\n",
      "Train on 12598 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.3249e-04 - val_loss: 0.0330\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.0453e-04 - val_loss: 0.0304\n",
      "Train on 12599 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.3765e-04 - val_loss: 0.0296\n",
      "Epoch 2/2\n",
      " - 11s - loss: 4.8134e-04 - val_loss: 0.0283\n",
      "Train on 12600 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.4742e-04 - val_loss: 0.0319\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.2087e-04 - val_loss: 0.0305\n",
      "Train on 12601 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.7059e-04 - val_loss: 0.0286\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.4299e-04 - val_loss: 0.0244\n",
      "Train on 12602 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.6365e-04 - val_loss: 0.0271\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.9849e-04 - val_loss: 0.0279\n",
      "Train on 12603 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.9591e-04 - val_loss: 0.0282\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.7266e-04 - val_loss: 0.0282\n",
      "Train on 12604 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1854e-04 - val_loss: 0.0299\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.2765e-04 - val_loss: 0.0285\n",
      "Train on 12605 samples, validate on 1 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 10s - loss: 4.4921e-04 - val_loss: 0.0268\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.9956e-04 - val_loss: 0.0269\n",
      "Train on 12606 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.0157e-04 - val_loss: 0.0270\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7071e-04 - val_loss: 0.0284\n",
      "Train on 12607 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.9828e-04 - val_loss: 0.0291\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.5637e-04 - val_loss: 0.0285\n",
      "Train on 12608 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.0669e-04 - val_loss: 0.0280\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.2375e-04 - val_loss: 0.0275\n",
      "Train on 12609 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5116e-04 - val_loss: 0.0307\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.4348e-04 - val_loss: 0.0304\n",
      "Train on 12610 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.4511e-04 - val_loss: 0.0324\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7117e-04 - val_loss: 0.0304\n",
      "Train on 12611 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4065e-04 - val_loss: 0.0297\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4496e-04 - val_loss: 0.0283\n",
      "Train on 12612 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.7789e-04 - val_loss: 0.0289\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.6968e-04 - val_loss: 0.0278\n",
      "Train on 12613 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4989e-04 - val_loss: 0.0274\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6038e-04 - val_loss: 0.0285\n",
      "Train on 12614 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.9601e-04 - val_loss: 0.0915\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.5371e-04 - val_loss: 0.0905\n",
      "Train on 12615 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4812e-04 - val_loss: 0.0878\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8687e-04 - val_loss: 0.0896\n",
      "Train on 12616 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.6191e-04 - val_loss: 0.0049\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7638e-04 - val_loss: 0.0034\n",
      "Train on 12617 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 6.1009e-04 - val_loss: 0.0032\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7012e-04 - val_loss: 0.0036\n",
      "Train on 12618 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2592e-04 - val_loss: 0.0015\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8602e-04 - val_loss: 0.0016\n",
      "Train on 12619 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4240e-04 - val_loss: 0.0029\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.2954e-04 - val_loss: 0.0028\n",
      "Train on 12620 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2808e-04 - val_loss: 0.0062\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.9215e-04 - val_loss: 0.0053\n",
      "Train on 12621 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.2123e-04 - val_loss: 0.0064\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.0239e-04 - val_loss: 0.0052\n",
      "Train on 12622 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.1312e-04 - val_loss: 0.0047\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.2373e-04 - val_loss: 0.0046\n",
      "Train on 12623 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7067e-04 - val_loss: 0.0051\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.1003e-04 - val_loss: 0.0044\n",
      "Train on 12624 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.0889e-04 - val_loss: 0.0049\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6045e-04 - val_loss: 0.0040\n",
      "Train on 12625 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.0443e-04 - val_loss: 0.0048\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.6959e-04 - val_loss: 0.0051\n",
      "Train on 12626 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.0780e-04 - val_loss: 0.0038\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.9411e-04 - val_loss: 0.0036\n",
      "Train on 12627 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7418e-04 - val_loss: 0.0029\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.2875e-04 - val_loss: 0.0029\n",
      "Train on 12628 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.1106e-04 - val_loss: 0.0044\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.8992e-04 - val_loss: 0.0062\n",
      "Train on 12629 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.4869e-04 - val_loss: 0.0063\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.1830e-04 - val_loss: 0.0035\n",
      "Train on 12630 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.4956e-04 - val_loss: 0.0054\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4596e-04 - val_loss: 0.0049\n",
      "Train on 12631 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.6898e-04 - val_loss: 0.0059\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0043e-04 - val_loss: 0.0049\n",
      "Train on 12632 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2336e-04 - val_loss: 0.0043\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.9740e-04 - val_loss: 0.0055\n",
      "Train on 12633 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.6921e-04 - val_loss: 0.0055\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.3842e-04 - val_loss: 0.0065\n",
      "Train on 12634 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.3696e-04 - val_loss: 0.0071\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.9935e-04 - val_loss: 0.0072\n",
      "Train on 12635 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4045e-04 - val_loss: 0.0084\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.4546e-04 - val_loss: 0.0072\n",
      "Train on 12636 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.8061e-04 - val_loss: 0.0076\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.1331e-04 - val_loss: 0.0061\n",
      "Train on 12637 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4522e-04 - val_loss: 0.0069\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.0762e-04 - val_loss: 0.0080\n",
      "Train on 12638 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.0764e-04 - val_loss: 0.0085\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.1754e-04 - val_loss: 0.0071\n",
      "Train on 12639 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 3.9745e-04 - val_loss: 0.0127\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.0627e-04 - val_loss: 0.0126\n",
      "Train on 12640 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.9172e-04 - val_loss: 0.0444\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.3608e-04 - val_loss: 0.0423\n",
      "Train on 12641 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.4090e-04 - val_loss: 0.0099\n",
      "Epoch 2/2\n",
      " - 9s - loss: 7.5354e-04 - val_loss: 0.0046\n",
      "Train on 12642 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.1502e-04 - val_loss: 2.9242e-06\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.3975e-04 - val_loss: 9.7544e-04\n",
      "Train on 12643 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.5127e-04 - val_loss: 7.9680e-04\n",
      "Epoch 2/2\n",
      " - 9s - loss: 4.0995e-04 - val_loss: 0.0014\n",
      "Train on 12644 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 5.3533e-04 - val_loss: 4.1017e-04\n",
      "Epoch 2/2\n",
      " - 9s - loss: 5.3212e-04 - val_loss: 1.2647e-05\n",
      "Train on 12645 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.6050e-04 - val_loss: 1.6784e-04\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.9182e-04 - val_loss: 8.1405e-04\n",
      "Train on 12646 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 5.7721e-04 - val_loss: 6.1033e-04\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.0392e-04 - val_loss: 0.0034\n",
      "Train on 12647 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.9353e-04 - val_loss: 0.0031\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.9690e-04 - val_loss: 0.0028\n",
      "Train on 12648 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.3171e-04 - val_loss: 0.0039\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.4945e-04 - val_loss: 0.0025\n",
      "Train on 12649 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.7360e-04 - val_loss: 0.0031\n",
      "Epoch 2/2\n",
      " - 9s - loss: 3.7234e-04 - val_loss: 0.0056\n",
      "Train on 12650 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4996e-04 - val_loss: 0.0039\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.3634e-04 - val_loss: 0.0046\n",
      "Train on 12651 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.5021e-04 - val_loss: 0.0055\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.8665e-04 - val_loss: 0.0027\n",
      "Train on 12652 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.7919e-04 - val_loss: 0.0014\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.2363e-04 - val_loss: 0.0030\n",
      "Train on 12653 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.8143e-04 - val_loss: 0.0048\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.0904e-04 - val_loss: 0.0039\n",
      "Train on 12654 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.1978e-04 - val_loss: 0.0028\n",
      "Epoch 2/2\n",
      " - 10s - loss: 6.0312e-04 - val_loss: 0.0050\n",
      "Train on 12655 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 5.2462e-04 - val_loss: 0.0029\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.6639e-04 - val_loss: 0.0011\n",
      "Train on 12656 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4.4523e-04 - val_loss: 0.0046\n",
      "Epoch 2/2\n",
      " - 10s - loss: 3.7291e-04 - val_loss: 0.0065\n",
      "Train on 12657 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.4279e-04 - val_loss: 0.0048\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.1708e-04 - val_loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12658 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3.5090e-04 - val_loss: 0.0051\n",
      "Epoch 2/2\n",
      " - 10s - loss: 4.7269e-04 - val_loss: 0.0043\n",
      "Train on 12659 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 4.5841e-04 - val_loss: 0.0028\n",
      "Epoch 2/2\n",
      " - 10s - loss: 5.2126e-04 - val_loss: 0.0025\n"
     ]
    }
   ],
   "source": [
    "res_5 = make_rolling_window(LSTM_model_copy, train_and_val_X, train_and_val_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 639.572\n"
     ]
    }
   ],
   "source": [
    "predicts_roll = scaler_2.inverse_transform(np.array(res_5[0]))\n",
    "actuals_roll = scaler_2.inverse_transform(np.array(res_5[1]))\n",
    "rmse = math.sqrt(mean_squared_error(predicts_roll, actuals_roll))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(\n",
    "    LSTM_model_copy,\n",
    "    './saved_models/LSTM_model_4_fit_after_preds.hdf5',\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
