{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.tsa.stattools as ts\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from fbprophet import Prophet\n",
    "\n",
    "import math\n",
    "\n",
    "# import pyflux as pf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM\n",
    "#from keras.layers import Concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(2019)\n",
    "set_random_seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_pickle('./processed_data/df_combined.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>vix</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-08 00:00:00</td>\n",
       "      <td>1054.03</td>\n",
       "      <td>18.879</td>\n",
       "      <td>2732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-08 01:00:00</td>\n",
       "      <td>1060.48</td>\n",
       "      <td>18.915</td>\n",
       "      <td>2693.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds        y     vix    gold\n",
       "0 2017-02-08 00:00:00  1054.03  18.879  2732.0\n",
       "1 2017-02-08 01:00:00  1060.48  18.915  2693.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlations = df_combined.corr()\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(correlations, square=True, cmap=\"RdBu_r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_chronological(df, ratio = 0.9, use_ratio = True, index = 1000):\n",
    "    \n",
    "    '''\n",
    "    Input is a dataframe, and a ratio. Splits dataframe into 2 dataframes chronologically.\n",
    "    Returns first dataframe up to the index of the length of the input dataframe times the input ratio, \n",
    "    and returns second dataframe of remaining elements.\n",
    "    use_ratio is a flag, wether ratio should be used or indicies instead.\n",
    "    \n",
    "    df = input dataframe\n",
    "    ratio = ratio to be used for splitting\n",
    "    use_ratio = if True, use ratio, \n",
    "    index = index to split input dataframe on\n",
    "    \n",
    "    '''\n",
    "    if use_ratio:\n",
    "        size = len(df) * ratio\n",
    "        size_round = round(size)\n",
    "\n",
    "        df_train = df[0:(size_round)]\n",
    "        df_test = df[size_round:]\n",
    "    else:\n",
    "        df_train = df[0:(index)]\n",
    "        df_test = df[index:]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variables(df, lags, look_back, predict_window):\n",
    "    \n",
    "    '''\n",
    "    In order to use keras LSTM, we need to convert the input into a keras-friendly input.\n",
    "    \n",
    "    df = input dataframe\n",
    "    lags = number of lags\n",
    "    look_back = number of preceding elements to be considered\n",
    "    predict_window = size of window for predictions\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features = lags + 1\n",
    "    start = look_back\n",
    "    stop = len(df) - lags - predict_window\n",
    "\n",
    "    lstm_in_X = np.zeros(shape=(stop-start, look_back+1, features))\n",
    "    lstm_in_Y = np.zeros(shape=(stop-start, look_back+1))\n",
    "\n",
    "    iter_list = [num for num in range(look_back+1)][::-1]\n",
    "    for i in range(start, stop):\n",
    "        for index, j in enumerate(iter_list):\n",
    "            X = df[i - j : i - j + lags + 1, -1]\n",
    "            lstm_in_X[i - start, index] = np.ravel(X)\n",
    "            Y = df[i - j + lags + 1, -1]\n",
    "            lstm_in_Y[i-start, index] = Y\n",
    "            \n",
    "    return lstm_in_X, lstm_in_Y, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(train_X, train_Y, lags, look_back, predict_window, lstm_nodes,\n",
    "               dense_layers, dropout = 0.1, loss_type = 'hinge', optimizer_type = 'adam',\n",
    "               number_epochs = 300, batch_size = 24, ):\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_nodes, input_shape=(look_back+1, features)))\n",
    "    model.add(Dropout(dropout))\n",
    "    for nodes in dense_layers:\n",
    "        model.add(Dense(nodes))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(look_back + 1))\n",
    "    model.compile(loss=loss_type, optimizer= optimizer_type)\n",
    "    model.fit(train_X, train_Y, epochs=number_epochs, batch_size = batch_size, verbose = 1)\n",
    "    \n",
    "    pred_Y_train = model.predict(train_X)\n",
    "    predictions = pred_Y_train[:,-1]\n",
    "    actuals = train_Y[:,-1]\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model, dataset, train_X, train_Y, predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rolling_window(model, train_x, train_y, test_x, test_y, batch_size = 32, epochs = 2):\n",
    "    predictions_test = []\n",
    "    actuals_test = []\n",
    "    \n",
    "    for i in range(0, len(test_y) - 1):\n",
    "        model.fit(train_x, train_y, \n",
    "                    epochs= epochs, \n",
    "                    batch_size = batch_size, \n",
    "                    validation_data=(test_x[i].reshape(1,1,23), (test_y[i].reshape(1 ,))),\n",
    "                    verbose=2,\n",
    "#                     callbacks=[earlystopper],\n",
    "                    shuffle=False)\n",
    "        pred_Y_test = model.predict(test_x)\n",
    "        train_x = np.concatenate((train_x, (test_x[i].reshape(1 , 1 , 23))))\n",
    "\n",
    "        train_y = np.concatenate((train_y, (test_y[i].reshape(1 ,))))\n",
    "        predict_test = pred_Y_test[-1,-1]\n",
    "        actual_test = train_y[-1]\n",
    "        predictions_test.append(predict_test)\n",
    "        actuals_test.append(actual_test)\n",
    "        \n",
    "    \n",
    "    return predictions_test, actuals_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Val, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_train_test_chronological(df_combined, ratio = .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = split_train_test_chronological(df_combined, ratio = .95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-7)</th>\n",
       "      <th>var2(t-7)</th>\n",
       "      <th>var3(t-7)</th>\n",
       "      <th>var1(t-6)</th>\n",
       "      <th>var2(t-6)</th>\n",
       "      <th>var3(t-6)</th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var2(t-5)</th>\n",
       "      <th>var3(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1054.030029</td>\n",
       "      <td>18.879000</td>\n",
       "      <td>2732.000000</td>\n",
       "      <td>1060.479980</td>\n",
       "      <td>18.915001</td>\n",
       "      <td>2693.000000</td>\n",
       "      <td>1062.939941</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>2712.120117</td>\n",
       "      <td>1065.819946</td>\n",
       "      <td>...</td>\n",
       "      <td>2742.100098</td>\n",
       "      <td>1066.310059</td>\n",
       "      <td>18.878000</td>\n",
       "      <td>2735.270020</td>\n",
       "      <td>1066.060059</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.120117</td>\n",
       "      <td>1066.260010</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2731.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1060.479980</td>\n",
       "      <td>18.915001</td>\n",
       "      <td>2693.000000</td>\n",
       "      <td>1062.939941</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>2712.120117</td>\n",
       "      <td>1065.819946</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2743.989990</td>\n",
       "      <td>1068.150024</td>\n",
       "      <td>...</td>\n",
       "      <td>2735.270020</td>\n",
       "      <td>1066.060059</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.120117</td>\n",
       "      <td>1066.260010</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2731.959961</td>\n",
       "      <td>1033.900024</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2710.209961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1062.939941</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>2712.120117</td>\n",
       "      <td>1065.819946</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2743.989990</td>\n",
       "      <td>1068.150024</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2742.100098</td>\n",
       "      <td>1066.310059</td>\n",
       "      <td>...</td>\n",
       "      <td>2732.120117</td>\n",
       "      <td>1066.260010</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2731.959961</td>\n",
       "      <td>1033.900024</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2710.209961</td>\n",
       "      <td>1032.180054</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2719.310059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1065.819946</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2743.989990</td>\n",
       "      <td>1068.150024</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2742.100098</td>\n",
       "      <td>1066.310059</td>\n",
       "      <td>18.878000</td>\n",
       "      <td>2735.270020</td>\n",
       "      <td>1066.060059</td>\n",
       "      <td>...</td>\n",
       "      <td>2731.959961</td>\n",
       "      <td>1033.900024</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2710.209961</td>\n",
       "      <td>1032.180054</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2719.310059</td>\n",
       "      <td>1037.780029</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.989990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1068.150024</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>2742.100098</td>\n",
       "      <td>1066.310059</td>\n",
       "      <td>18.878000</td>\n",
       "      <td>2735.270020</td>\n",
       "      <td>1066.060059</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.120117</td>\n",
       "      <td>1066.260010</td>\n",
       "      <td>...</td>\n",
       "      <td>2710.209961</td>\n",
       "      <td>1032.180054</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2719.310059</td>\n",
       "      <td>1037.780029</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2732.989990</td>\n",
       "      <td>1045.300049</td>\n",
       "      <td>18.886999</td>\n",
       "      <td>2719.979980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var1(t-7)  var2(t-7)    var3(t-7)    var1(t-6)  var2(t-6)    var3(t-6)  \\\n",
       "7   1054.030029  18.879000  2732.000000  1060.479980  18.915001  2693.000000   \n",
       "8   1060.479980  18.915001  2693.000000  1062.939941  18.860001  2712.120117   \n",
       "9   1062.939941  18.860001  2712.120117  1065.819946  18.770000  2743.989990   \n",
       "10  1065.819946  18.770000  2743.989990  1068.150024  18.770000  2742.100098   \n",
       "11  1068.150024  18.770000  2742.100098  1066.310059  18.878000  2735.270020   \n",
       "\n",
       "      var1(t-5)  var2(t-5)    var3(t-5)    var1(t-4)  ...    var3(t-3)  \\\n",
       "7   1062.939941  18.860001  2712.120117  1065.819946  ...  2742.100098   \n",
       "8   1065.819946  18.770000  2743.989990  1068.150024  ...  2735.270020   \n",
       "9   1068.150024  18.770000  2742.100098  1066.310059  ...  2732.120117   \n",
       "10  1066.310059  18.878000  2735.270020  1066.060059  ...  2731.959961   \n",
       "11  1066.060059  18.886999  2732.120117  1066.260010  ...  2710.209961   \n",
       "\n",
       "      var1(t-2)  var2(t-2)    var3(t-2)    var1(t-1)  var2(t-1)    var3(t-1)  \\\n",
       "7   1066.310059  18.878000  2735.270020  1066.060059  18.886999  2732.120117   \n",
       "8   1066.060059  18.886999  2732.120117  1066.260010  18.886999  2731.959961   \n",
       "9   1066.260010  18.886999  2731.959961  1033.900024  18.886999  2710.209961   \n",
       "10  1033.900024  18.886999  2710.209961  1032.180054  18.886999  2719.310059   \n",
       "11  1032.180054  18.886999  2719.310059  1037.780029  18.886999  2732.989990   \n",
       "\n",
       "        var1(t)    var2(t)      var3(t)  \n",
       "7   1066.260010  18.886999  2731.959961  \n",
       "8   1033.900024  18.886999  2710.209961  \n",
       "9   1032.180054  18.886999  2719.310059  \n",
       "10  1037.780029  18.886999  2732.989990  \n",
       "11  1045.300049  18.886999  2719.979980  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "values = df_combined.drop('ds', axis = 1).values\n",
    "# integer encode direction\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 7, 1)\n",
    "\n",
    "reframed_2 = series_to_supervised(values, 7, 1)\n",
    "reframed_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 1, 23) (12000,) (341, 1, 23) (341,) (320, 1, 23) (320,)\n"
     ]
    }
   ],
   "source": [
    "# drop columns we don't want to predict\n",
    "y = reframed.iloc[:,-12].values\n",
    "X = reframed.drop('var1(t)', axis =1).values\n",
    "# split into train and test sets\n",
    "\n",
    "n_train_hours = 12000\n",
    "n_test_hours = 320\n",
    "train_X = X[:n_train_hours,:]\n",
    "train_y = y[:n_train_hours]\n",
    "\n",
    "val_X= X[n_train_hours:-n_test_hours,]\n",
    "val_y= y[n_train_hours:-n_test_hours]\n",
    "\n",
    "test_X = X[-n_test_hours:,:]\n",
    "test_y = y[-n_test_hours:]\n",
    "\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape,val_X.shape, val_y.shape ,test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00600698, 0.00590796, 0.00589451, ..., 0.40667784, 0.4065094 ,\n",
       "       0.40857488], dtype=float32)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 1, 23) (12000,) (341, 1, 23) (341,) (320, 1, 23) (320,)\n"
     ]
    }
   ],
   "source": [
    "# drop columns we don't want to predict\n",
    "y = reframed_2.iloc[:,-12].values\n",
    "X = reframed_2.drop('var1(t)', axis =1).values\n",
    "# split into train and test sets\n",
    "\n",
    "n_train_hours = 12000\n",
    "n_test_hours = 320\n",
    "train_X = X[:n_train_hours,:]\n",
    "train_y = y[:n_train_hours]\n",
    "\n",
    "val_X= X[n_train_hours:-n_test_hours,]\n",
    "val_y= y[n_train_hours:-n_test_hours]\n",
    "\n",
    "test_X = X[-n_test_hours:,:]\n",
    "test_y = y[-n_test_hours:]\n",
    "\n",
    "\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape,val_X.shape, val_y.shape ,test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1068.15, 1066.31, 1066.06, ..., 8513.3 , 8510.17, 8548.55],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_2 = Sequential()\n",
    "LSTM_model_2.add(LSTM(128, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]), dropout=0.20,recurrent_dropout=0.20))\n",
    "LSTM_model_2.add(Dense(64))\n",
    "# LSTM_model_2.add(LSTM(16, activation='relu'))\n",
    "LSTM_model_2.add(Dense(1))\n",
    "LSTM_model_2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 341 samples\n",
      "Epoch 1/200\n",
      " - 8s - loss: 1155521.1083 - val_loss: 510859.1422\n",
      "Epoch 2/200\n",
      " - 2s - loss: 552400.2267 - val_loss: 499067.5001\n",
      "Epoch 3/200\n",
      " - 2s - loss: 393317.6611 - val_loss: 566411.4622\n",
      "Epoch 4/200\n",
      " - 2s - loss: 354509.8768 - val_loss: 526273.4775\n",
      "Epoch 5/200\n",
      " - 2s - loss: 262476.7765 - val_loss: 607219.6069\n",
      "Epoch 6/200\n",
      " - 2s - loss: 235657.7090 - val_loss: 591851.1710\n",
      "Epoch 7/200\n",
      " - 2s - loss: 214402.2766 - val_loss: 642345.9998\n",
      "Epoch 8/200\n",
      " - 2s - loss: 192961.7354 - val_loss: 585742.9106\n",
      "Epoch 9/200\n",
      " - 2s - loss: 167234.7339 - val_loss: 598396.1626\n",
      "Epoch 10/200\n",
      " - 2s - loss: 142929.1472 - val_loss: 605608.8706\n",
      "Epoch 11/200\n",
      " - 2s - loss: 126166.7817 - val_loss: 609330.8468\n",
      "Epoch 12/200\n",
      " - 2s - loss: 124570.9578 - val_loss: 636181.8488\n",
      "Epoch 13/200\n",
      " - 2s - loss: 104540.1089 - val_loss: 622463.0581\n",
      "Epoch 14/200\n",
      " - 2s - loss: 118909.8614 - val_loss: 602211.8785\n",
      "Epoch 15/200\n",
      " - 2s - loss: 89234.3142 - val_loss: 613371.6404\n",
      "Epoch 16/200\n",
      " - 2s - loss: 83344.9734 - val_loss: 619912.7139\n",
      "Epoch 17/200\n",
      " - 2s - loss: 62679.8195 - val_loss: 604470.3801\n",
      "Epoch 18/200\n",
      " - 2s - loss: 67380.8433 - val_loss: 616139.7681\n",
      "Epoch 19/200\n",
      " - 2s - loss: 63908.9885 - val_loss: 603651.7095\n",
      "Epoch 20/200\n",
      " - 2s - loss: 44781.0584 - val_loss: 612483.7542\n",
      "Epoch 21/200\n",
      " - 2s - loss: 45678.9097 - val_loss: 597539.7527\n",
      "Epoch 22/200\n",
      " - 2s - loss: 55309.1742 - val_loss: 614808.2984\n",
      "Epoch 23/200\n",
      " - 2s - loss: 35554.0837 - val_loss: 609220.2247\n",
      "Epoch 24/200\n",
      " - 2s - loss: 30418.2667 - val_loss: 611416.0453\n",
      "Epoch 25/200\n",
      " - 2s - loss: 31011.2746 - val_loss: 603996.6397\n",
      "Epoch 26/200\n",
      " - 2s - loss: 32608.2668 - val_loss: 599525.6056\n",
      "Epoch 27/200\n",
      " - 2s - loss: 28839.1794 - val_loss: 608218.1842\n",
      "Epoch 28/200\n",
      " - 2s - loss: 27993.9904 - val_loss: 588776.8552\n",
      "Epoch 29/200\n",
      " - 2s - loss: 31126.6956 - val_loss: 619701.6459\n",
      "Epoch 30/200\n",
      " - 2s - loss: 26884.5048 - val_loss: 607177.6895\n",
      "Epoch 31/200\n",
      " - 2s - loss: 31044.7788 - val_loss: 617766.4366\n",
      "Epoch 32/200\n",
      " - 2s - loss: 24916.9636 - val_loss: 607332.9098\n",
      "Epoch 33/200\n",
      " - 2s - loss: 26836.3451 - val_loss: 594562.0321\n",
      "Epoch 34/200\n",
      " - 2s - loss: 21155.6172 - val_loss: 608241.6835\n",
      "Epoch 35/200\n",
      " - 2s - loss: 22297.0904 - val_loss: 593557.8462\n",
      "Epoch 36/200\n",
      " - 2s - loss: 22751.0311 - val_loss: 595310.1917\n",
      "Epoch 37/200\n",
      " - 2s - loss: 19476.0238 - val_loss: 612765.0537\n",
      "Epoch 38/200\n",
      " - 2s - loss: 17252.3924 - val_loss: 603442.5024\n",
      "Epoch 39/200\n",
      " - 2s - loss: 17559.6604 - val_loss: 588222.9615\n",
      "Epoch 40/200\n",
      " - 2s - loss: 18265.3087 - val_loss: 605905.5510\n",
      "Epoch 41/200\n",
      " - 2s - loss: 22088.8606 - val_loss: 599290.2597\n",
      "Epoch 42/200\n",
      " - 2s - loss: 22612.9769 - val_loss: 599077.7335\n",
      "Epoch 43/200\n",
      " - 2s - loss: 18389.6268 - val_loss: 591141.1281\n",
      "Epoch 44/200\n",
      " - 2s - loss: 23227.9452 - val_loss: 601497.4162\n",
      "Epoch 45/200\n",
      " - 2s - loss: 15495.9603 - val_loss: 603874.1563\n",
      "Epoch 46/200\n",
      " - 2s - loss: 14294.6903 - val_loss: 603925.3224\n",
      "Epoch 47/200\n",
      " - 2s - loss: 20399.2673 - val_loss: 603089.2817\n",
      "Epoch 48/200\n",
      " - 2s - loss: 17231.0873 - val_loss: 608571.4687\n",
      "Epoch 49/200\n",
      " - 2s - loss: 15084.9652 - val_loss: 611533.3037\n",
      "Epoch 50/200\n",
      " - 2s - loss: 14579.7531 - val_loss: 613163.1276\n",
      "Epoch 51/200\n",
      " - 2s - loss: 16883.1936 - val_loss: 613896.3909\n",
      "Epoch 52/200\n",
      " - 2s - loss: 18597.1348 - val_loss: 616876.0073\n",
      "Epoch 53/200\n",
      " - 2s - loss: 24767.1902 - val_loss: 608298.6023\n",
      "Epoch 54/200\n",
      " - 2s - loss: 17742.2798 - val_loss: 620357.7872\n",
      "Epoch 55/200\n",
      " - 2s - loss: 18770.6097 - val_loss: 613449.5663\n",
      "Epoch 56/200\n",
      " - 2s - loss: 15275.2055 - val_loss: 620877.3948\n",
      "Epoch 57/200\n",
      " - 2s - loss: 17930.3600 - val_loss: 596433.6232\n",
      "Epoch 58/200\n",
      " - 2s - loss: 14764.1919 - val_loss: 611151.7033\n",
      "Epoch 59/200\n",
      " - 2s - loss: 20997.3269 - val_loss: 608272.3550\n",
      "Epoch 60/200\n",
      " - 2s - loss: 15581.7095 - val_loss: 623556.8301\n",
      "Epoch 61/200\n",
      " - 2s - loss: 18004.2546 - val_loss: 606422.5953\n",
      "Epoch 62/200\n",
      " - 2s - loss: 15728.0971 - val_loss: 620483.0658\n",
      "Epoch 63/200\n",
      " - 2s - loss: 19951.8442 - val_loss: 626911.7817\n",
      "Epoch 64/200\n",
      " - 2s - loss: 13352.4545 - val_loss: 628370.3581\n",
      "Epoch 65/200\n",
      " - 2s - loss: 14042.4984 - val_loss: 614460.9386\n",
      "Epoch 66/200\n",
      " - 2s - loss: 18576.0363 - val_loss: 606615.8347\n",
      "Epoch 67/200\n",
      " - 2s - loss: 19196.7543 - val_loss: 619668.2441\n",
      "Epoch 68/200\n",
      " - 2s - loss: 17048.6985 - val_loss: 596321.4635\n",
      "Epoch 69/200\n",
      " - 2s - loss: 16091.0420 - val_loss: 606005.5858\n",
      "Epoch 70/200\n",
      " - 2s - loss: 12653.6553 - val_loss: 609530.6842\n",
      "Epoch 71/200\n",
      " - 2s - loss: 15770.7230 - val_loss: 614127.4778\n",
      "Epoch 72/200\n",
      " - 2s - loss: 20323.5974 - val_loss: 610764.0902\n",
      "Epoch 73/200\n",
      " - 2s - loss: 13934.6807 - val_loss: 614609.6036\n",
      "Epoch 74/200\n",
      " - 2s - loss: 15900.2856 - val_loss: 598345.3162\n",
      "Epoch 75/200\n",
      " - 2s - loss: 14195.9919 - val_loss: 599569.2958\n",
      "Epoch 76/200\n",
      " - 2s - loss: 20113.1983 - val_loss: 616621.8985\n",
      "Epoch 77/200\n",
      " - 2s - loss: 18472.1872 - val_loss: 619128.1277\n",
      "Epoch 78/200\n",
      " - 2s - loss: 13587.2693 - val_loss: 628812.8081\n",
      "Epoch 79/200\n",
      " - 2s - loss: 12970.3194 - val_loss: 602508.3055\n",
      "Epoch 80/200\n",
      " - 2s - loss: 14246.8203 - val_loss: 613322.9820\n",
      "Epoch 81/200\n",
      " - 2s - loss: 12745.2046 - val_loss: 610150.9984\n",
      "Epoch 82/200\n",
      " - 2s - loss: 13086.4616 - val_loss: 609691.4870\n",
      "Epoch 83/200\n",
      " - 2s - loss: 15023.0947 - val_loss: 620137.4080\n",
      "Epoch 84/200\n",
      " - 2s - loss: 10656.7866 - val_loss: 599888.6871\n",
      "Epoch 85/200\n",
      " - 2s - loss: 15438.6693 - val_loss: 607403.8787\n",
      "Epoch 86/200\n",
      " - 2s - loss: 11896.8394 - val_loss: 602907.8460\n",
      "Epoch 87/200\n",
      " - 2s - loss: 14889.0459 - val_loss: 614321.2377\n",
      "Epoch 88/200\n",
      " - 2s - loss: 13905.5522 - val_loss: 630597.0883\n",
      "Epoch 89/200\n",
      " - 2s - loss: 15639.7018 - val_loss: 623590.7958\n",
      "Epoch 90/200\n",
      " - 2s - loss: 10986.6421 - val_loss: 593710.1032\n",
      "Epoch 91/200\n",
      " - 2s - loss: 24023.1094 - val_loss: 596403.8343\n",
      "Epoch 92/200\n",
      " - 2s - loss: 14820.4372 - val_loss: 617597.5581\n",
      "Epoch 93/200\n",
      " - 2s - loss: 11937.0758 - val_loss: 608307.9018\n",
      "Epoch 94/200\n",
      " - 2s - loss: 10331.3462 - val_loss: 612749.7452\n",
      "Epoch 95/200\n",
      " - 2s - loss: 10685.0922 - val_loss: 608361.2588\n",
      "Epoch 96/200\n",
      " - 2s - loss: 11425.9087 - val_loss: 602536.6074\n",
      "Epoch 97/200\n",
      " - 2s - loss: 13932.4638 - val_loss: 605006.1628\n",
      "Epoch 98/200\n",
      " - 2s - loss: 12231.9323 - val_loss: 612660.1695\n",
      "Epoch 99/200\n",
      " - 2s - loss: 11179.1475 - val_loss: 611762.0541\n",
      "Epoch 100/200\n",
      " - 2s - loss: 17479.9036 - val_loss: 611067.2198\n",
      "Epoch 101/200\n",
      " - 2s - loss: 13605.8915 - val_loss: 603741.7311\n",
      "Epoch 102/200\n",
      " - 2s - loss: 18700.3669 - val_loss: 604465.1397\n",
      "Epoch 103/200\n",
      " - 2s - loss: 10771.1565 - val_loss: 605549.6472\n",
      "Epoch 104/200\n",
      " - 2s - loss: 11203.4194 - val_loss: 602989.7141\n",
      "Epoch 105/200\n",
      " - 2s - loss: 11320.8091 - val_loss: 599829.8561\n",
      "Epoch 106/200\n",
      " - 2s - loss: 13318.8351 - val_loss: 604898.8220\n",
      "Epoch 107/200\n",
      " - 2s - loss: 14898.0311 - val_loss: 595859.9351\n",
      "Epoch 108/200\n",
      " - 2s - loss: 11707.0522 - val_loss: 603326.3724\n",
      "Epoch 109/200\n",
      " - 2s - loss: 13438.7816 - val_loss: 616037.2476\n",
      "Epoch 110/200\n",
      " - 2s - loss: 15261.3498 - val_loss: 593850.7548\n",
      "Epoch 111/200\n",
      " - 2s - loss: 10433.0433 - val_loss: 612040.0005\n",
      "Epoch 112/200\n",
      " - 2s - loss: 17261.8357 - val_loss: 611566.2617\n",
      "Epoch 113/200\n",
      " - 2s - loss: 10741.2023 - val_loss: 611055.3501\n",
      "Epoch 114/200\n",
      " - 2s - loss: 12322.5833 - val_loss: 598836.4798\n",
      "Epoch 115/200\n",
      " - 2s - loss: 10156.5081 - val_loss: 622231.2654\n",
      "Epoch 116/200\n",
      " - 2s - loss: 14054.7539 - val_loss: 611653.5026\n",
      "Epoch 117/200\n",
      " - 2s - loss: 9983.0833 - val_loss: 605163.2597\n",
      "Epoch 118/200\n",
      " - 2s - loss: 10710.7602 - val_loss: 595933.7201\n",
      "Epoch 119/200\n",
      " - 2s - loss: 9743.2076 - val_loss: 607529.2515\n",
      "Epoch 120/200\n",
      " - 2s - loss: 15426.0124 - val_loss: 617989.2396\n",
      "Epoch 121/200\n",
      " - 2s - loss: 20382.8111 - val_loss: 623324.1946\n",
      "Epoch 122/200\n",
      " - 2s - loss: 10736.6561 - val_loss: 606177.5590\n",
      "Epoch 123/200\n",
      " - 2s - loss: 20727.8627 - val_loss: 619948.6058\n",
      "Epoch 124/200\n",
      " - 2s - loss: 12771.7940 - val_loss: 612767.8873\n",
      "Epoch 125/200\n",
      " - 2s - loss: 9200.0037 - val_loss: 610192.9606\n",
      "Epoch 126/200\n",
      " - 2s - loss: 10120.9127 - val_loss: 615618.9289\n",
      "Epoch 127/200\n",
      " - 2s - loss: 11381.1537 - val_loss: 606964.9063\n",
      "Epoch 128/200\n",
      " - 2s - loss: 11265.3302 - val_loss: 607256.2925\n",
      "Epoch 129/200\n",
      " - 2s - loss: 12623.1564 - val_loss: 617994.2742\n",
      "Epoch 130/200\n",
      " - 2s - loss: 13630.4954 - val_loss: 605933.6527\n",
      "Epoch 131/200\n",
      " - 2s - loss: 15215.5712 - val_loss: 619574.8191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      " - 2s - loss: 10401.4476 - val_loss: 616130.1937\n",
      "Epoch 133/200\n",
      " - 2s - loss: 11550.8372 - val_loss: 602026.1813\n",
      "Epoch 134/200\n",
      " - 2s - loss: 9455.2049 - val_loss: 613259.9765\n",
      "Epoch 135/200\n",
      " - 2s - loss: 17475.4735 - val_loss: 600711.1481\n",
      "Epoch 136/200\n",
      " - 2s - loss: 10587.5354 - val_loss: 616772.9820\n",
      "Epoch 137/200\n",
      " - 2s - loss: 8955.7734 - val_loss: 611937.0231\n",
      "Epoch 138/200\n",
      " - 2s - loss: 10608.2661 - val_loss: 597525.3369\n",
      "Epoch 139/200\n",
      " - 2s - loss: 11371.1344 - val_loss: 606406.6026\n",
      "Epoch 140/200\n",
      " - 2s - loss: 9615.3815 - val_loss: 595373.8382\n",
      "Epoch 141/200\n",
      " - 2s - loss: 10079.1981 - val_loss: 614805.8499\n",
      "Epoch 142/200\n",
      " - 2s - loss: 9800.4246 - val_loss: 607451.3283\n",
      "Epoch 143/200\n",
      " - 2s - loss: 10909.4729 - val_loss: 605746.9467\n",
      "Epoch 144/200\n",
      " - 2s - loss: 10554.4870 - val_loss: 602591.2390\n",
      "Epoch 145/200\n",
      " - 2s - loss: 9944.4172 - val_loss: 606344.9470\n",
      "Epoch 146/200\n",
      " - 2s - loss: 10700.5158 - val_loss: 622790.0209\n",
      "Epoch 147/200\n",
      " - 2s - loss: 12288.6308 - val_loss: 604881.3561\n",
      "Epoch 148/200\n",
      " - 2s - loss: 11371.1019 - val_loss: 620660.6191\n",
      "Epoch 149/200\n",
      " - 2s - loss: 9549.7644 - val_loss: 621507.6252\n",
      "Epoch 150/200\n",
      " - 2s - loss: 26490.0041 - val_loss: 605502.2577\n",
      "Epoch 151/200\n",
      " - 2s - loss: 11086.2502 - val_loss: 599918.6206\n",
      "Epoch 152/200\n",
      " - 2s - loss: 8729.9407 - val_loss: 604562.6833\n",
      "Epoch 153/200\n",
      " - 2s - loss: 9725.2935 - val_loss: 597381.0643\n",
      "Epoch 154/200\n",
      " - 2s - loss: 7609.3784 - val_loss: 608964.7148\n",
      "Epoch 155/200\n",
      " - 2s - loss: 8264.2230 - val_loss: 613853.2234\n",
      "Epoch 156/200\n",
      " - 2s - loss: 18916.7905 - val_loss: 611644.5013\n",
      "Epoch 157/200\n",
      " - 2s - loss: 15973.3003 - val_loss: 618064.5433\n",
      "Epoch 158/200\n",
      " - 2s - loss: 15234.4523 - val_loss: 627601.9879\n",
      "Epoch 159/200\n",
      " - 2s - loss: 8646.0134 - val_loss: 613567.0852\n",
      "Epoch 160/200\n",
      " - 2s - loss: 9509.6381 - val_loss: 606401.2685\n",
      "Epoch 161/200\n",
      " - 2s - loss: 10564.0117 - val_loss: 615961.5262\n",
      "Epoch 162/200\n",
      " - 2s - loss: 9733.2465 - val_loss: 614569.4337\n",
      "Epoch 163/200\n",
      " - 2s - loss: 8962.6027 - val_loss: 613978.0872\n",
      "Epoch 164/200\n",
      " - 2s - loss: 8515.2505 - val_loss: 606404.5885\n",
      "Epoch 165/200\n",
      " - 2s - loss: 15318.8762 - val_loss: 607869.3387\n",
      "Epoch 166/200\n",
      " - 2s - loss: 10034.4104 - val_loss: 601578.1968\n",
      "Epoch 167/200\n",
      " - 2s - loss: 8754.8869 - val_loss: 612250.0416\n",
      "Epoch 168/200\n",
      " - 2s - loss: 14162.1302 - val_loss: 614813.6826\n",
      "Epoch 169/200\n",
      " - 2s - loss: 10991.7119 - val_loss: 612992.7744\n",
      "Epoch 170/200\n",
      " - 2s - loss: 8909.7923 - val_loss: 598119.1202\n",
      "Epoch 171/200\n",
      " - 2s - loss: 9005.6139 - val_loss: 607191.3655\n",
      "Epoch 172/200\n",
      " - 2s - loss: 9104.8202 - val_loss: 608392.3865\n",
      "Epoch 173/200\n",
      " - 2s - loss: 9705.9548 - val_loss: 607239.2130\n",
      "Epoch 174/200\n",
      " - 2s - loss: 8973.4301 - val_loss: 605062.3378\n",
      "Epoch 175/200\n",
      " - 2s - loss: 10337.8904 - val_loss: 612809.8559\n",
      "Epoch 176/200\n",
      " - 2s - loss: 9738.0419 - val_loss: 594720.8536\n",
      "Epoch 177/200\n",
      " - 2s - loss: 9290.1086 - val_loss: 597722.1204\n",
      "Epoch 178/200\n",
      " - 2s - loss: 7195.4590 - val_loss: 605347.3228\n",
      "Epoch 179/200\n",
      " - 2s - loss: 7131.1628 - val_loss: 610232.9619\n",
      "Epoch 180/200\n",
      " - 2s - loss: 11350.8112 - val_loss: 606928.7073\n",
      "Epoch 181/200\n",
      " - 2s - loss: 8217.0796 - val_loss: 607698.4282\n",
      "Epoch 182/200\n",
      " - 2s - loss: 9894.3258 - val_loss: 599713.7174\n",
      "Epoch 183/200\n",
      " - 2s - loss: 16695.1103 - val_loss: 604233.5834\n",
      "Epoch 184/200\n",
      " - 2s - loss: 7168.9974 - val_loss: 607990.8087\n",
      "Epoch 185/200\n",
      " - 2s - loss: 8796.3084 - val_loss: 612380.4375\n",
      "Epoch 186/200\n",
      " - 2s - loss: 6619.5687 - val_loss: 609115.0084\n",
      "Epoch 187/200\n",
      " - 2s - loss: 9475.9550 - val_loss: 600425.7535\n",
      "Epoch 188/200\n",
      " - 2s - loss: 8908.4120 - val_loss: 609519.9434\n",
      "Epoch 189/200\n",
      " - 2s - loss: 9878.2152 - val_loss: 601077.0887\n",
      "Epoch 190/200\n",
      " - 2s - loss: 12256.5886 - val_loss: 611749.7665\n",
      "Epoch 191/200\n",
      " - 2s - loss: 6819.2107 - val_loss: 600916.7353\n",
      "Epoch 192/200\n",
      " - 2s - loss: 9515.4265 - val_loss: 595899.7852\n",
      "Epoch 193/200\n",
      " - 2s - loss: 7801.6323 - val_loss: 609614.8328\n",
      "Epoch 194/200\n",
      " - 2s - loss: 7137.7529 - val_loss: 608120.6408\n",
      "Epoch 195/200\n",
      " - 2s - loss: 16547.2496 - val_loss: 599159.9452\n",
      "Epoch 196/200\n",
      " - 2s - loss: 14112.8777 - val_loss: 589683.3746\n",
      "Epoch 197/200\n",
      " - 2s - loss: 12222.3916 - val_loss: 591201.0794\n",
      "Epoch 198/200\n",
      " - 2s - loss: 22042.9060 - val_loss: 599361.7599\n",
      "Epoch 199/200\n",
      " - 2s - loss: 9080.7587 - val_loss: 603543.3411\n",
      "Epoch 200/200\n",
      " - 2s - loss: 8892.0868 - val_loss: 594565.9137\n"
     ]
    }
   ],
   "source": [
    "history_2 = LSTM_model_2.fit(train_X, train_y, \n",
    "                    epochs= 200, \n",
    "                    batch_size = 32, \n",
    "                    validation_data=(val_X, val_y),\n",
    "                    verbose=2,\n",
    "#                     callbacks=[earlystopper],\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 9486.7992 - val_loss: 566046.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10180.3848 - val_loss: 551187.0000\n",
      "Train on 12001 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6436.2544 - val_loss: 576307.0625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6924.9651 - val_loss: 574620.6250\n",
      "Train on 12002 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7054.1497 - val_loss: 579432.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7309.6793 - val_loss: 588328.6875\n",
      "Train on 12003 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8139.2625 - val_loss: 604909.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10030.5209 - val_loss: 605064.8125\n",
      "Train on 12004 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10616.3699 - val_loss: 592430.1250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8775.1244 - val_loss: 612942.9375\n",
      "Train on 12005 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7226.9026 - val_loss: 694522.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12435.9439 - val_loss: 687045.1250\n",
      "Train on 12006 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10209.9836 - val_loss: 604302.7500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7164.8329 - val_loss: 603306.0625\n",
      "Train on 12007 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10622.3181 - val_loss: 576991.5625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9016.7440 - val_loss: 569624.6875\n",
      "Train on 12008 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8254.7866 - val_loss: 572779.5625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12301.6457 - val_loss: 570495.1250\n",
      "Train on 12009 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9628.4875 - val_loss: 599809.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10747.3857 - val_loss: 602448.8125\n",
      "Train on 12010 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 11830.5393 - val_loss: 613191.0625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6727.7931 - val_loss: 606967.3125\n",
      "Train on 12011 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6354.7167 - val_loss: 629303.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6528.7064 - val_loss: 629679.0625\n",
      "Train on 12012 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10419.0600 - val_loss: 566758.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 12580.4100 - val_loss: 571371.0000\n",
      "Train on 12013 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 11328.7327 - val_loss: 524441.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7847.9988 - val_loss: 526794.1875\n",
      "Train on 12014 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8314.2239 - val_loss: 550546.6250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9955.9954 - val_loss: 546406.8125\n",
      "Train on 12015 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6882.7149 - val_loss: 561837.0000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7070.6281 - val_loss: 564249.3125\n",
      "Train on 12016 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 11364.7143 - val_loss: 559747.2500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10337.6445 - val_loss: 547528.4375\n",
      "Train on 12017 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6724.7340 - val_loss: 598506.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7449.1357 - val_loss: 596588.0625\n",
      "Train on 12018 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7784.1913 - val_loss: 596348.9375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6072.3742 - val_loss: 592570.6875\n",
      "Train on 12019 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10188.1133 - val_loss: 584387.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9264.5223 - val_loss: 577295.3750\n",
      "Train on 12020 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8585.8359 - val_loss: 598835.6875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7684.1634 - val_loss: 589040.8750\n",
      "Train on 12021 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6436.8334 - val_loss: 566775.9375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9287.3791 - val_loss: 558993.5000\n",
      "Train on 12022 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7381.8923 - val_loss: 501504.2812\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9683.3841 - val_loss: 505566.4688\n",
      "Train on 12023 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7964.6462 - val_loss: 468172.3438\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6912.4908 - val_loss: 465407.7812\n",
      "Train on 12024 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8279.5598 - val_loss: 691440.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6865.1526 - val_loss: 693744.1875\n",
      "Train on 12025 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6149.3452 - val_loss: 749218.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8703.1718 - val_loss: 766530.1875\n",
      "Train on 12026 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9117.3075 - val_loss: 739027.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8634.7341 - val_loss: 741086.8750\n",
      "Train on 12027 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6637.5677 - val_loss: 690704.6250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7730.5804 - val_loss: 695212.3125\n",
      "Train on 12028 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7503.5178 - val_loss: 699851.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9614.5373 - val_loss: 698561.7500\n",
      "Train on 12029 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7520.4161 - val_loss: 645864.1250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6932.2448 - val_loss: 634547.1875\n",
      "Train on 12030 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8977.1160 - val_loss: 650054.0000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9929.2349 - val_loss: 645573.4375\n",
      "Train on 12031 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8745.9758 - val_loss: 646951.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8771.1734 - val_loss: 645863.7500\n",
      "Train on 12032 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 8212.0886 - val_loss: 712211.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9468.3338 - val_loss: 716169.6250\n",
      "Train on 12033 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8266.9111 - val_loss: 711734.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6103.5460 - val_loss: 719888.0625\n",
      "Train on 12034 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 7923.9210 - val_loss: 700748.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7414.2671 - val_loss: 707415.6875\n",
      "Train on 12035 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 6625.0139 - val_loss: 697774.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9778.4110 - val_loss: 694033.8125\n",
      "Train on 12036 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 12242.0927 - val_loss: 561568.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10343.2368 - val_loss: 549346.9375\n",
      "Train on 12037 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8462.0536 - val_loss: 587782.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7845.6743 - val_loss: 574824.2500\n",
      "Train on 12038 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 5626.0526 - val_loss: 696650.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8712.0570 - val_loss: 707649.0000\n",
      "Train on 12039 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 6939.9875 - val_loss: 715918.4375\n",
      "Epoch 2/2\n",
      " - 12s - loss: 6951.3032 - val_loss: 706226.0625\n",
      "Train on 12040 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 13967.9657 - val_loss: 677318.5625\n",
      "Epoch 2/2\n",
      " - 398s - loss: 7576.3821 - val_loss: 659622.3750\n",
      "Train on 12041 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6280.4497 - val_loss: 747391.0625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6377.5674 - val_loss: 738449.8750\n",
      "Train on 12042 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9449.9502 - val_loss: 682714.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6490.2204 - val_loss: 679786.1875\n",
      "Train on 12043 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7882.6744 - val_loss: 672143.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6641.5633 - val_loss: 673665.4375\n",
      "Train on 12044 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8860.3950 - val_loss: 691104.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12397.4880 - val_loss: 685512.0625\n",
      "Train on 12045 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7507.9164 - val_loss: 569322.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8017.1102 - val_loss: 573048.6250\n",
      "Train on 12046 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8521.4684 - val_loss: 646584.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6521.0927 - val_loss: 638511.8125\n",
      "Train on 12047 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7650.5710 - val_loss: 659231.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7983.1825 - val_loss: 661861.6875\n",
      "Train on 12048 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8453.1206 - val_loss: 719118.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11308.5649 - val_loss: 723957.5000\n",
      "Train on 12049 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9694.5681 - val_loss: 656471.0625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7843.2616 - val_loss: 651163.5000\n",
      "Train on 12050 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8298.3052 - val_loss: 639043.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 2s - loss: 15111.8315 - val_loss: 627341.7500\n",
      "Train on 12051 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5691.2105 - val_loss: 667759.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9801.7381 - val_loss: 657505.1875\n",
      "Train on 12052 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8237.1120 - val_loss: 688776.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7951.0529 - val_loss: 681097.1875\n",
      "Train on 12053 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6789.2671 - val_loss: 689422.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8549.1835 - val_loss: 697618.5000\n",
      "Train on 12054 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7438.2145 - val_loss: 698974.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7133.4240 - val_loss: 695915.6250\n",
      "Train on 12055 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7981.1816 - val_loss: 645723.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5468.8570 - val_loss: 651088.6250\n",
      "Train on 12056 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7641.6511 - val_loss: 651209.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8943.6612 - val_loss: 664047.9375\n",
      "Train on 12057 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7026.0841 - val_loss: 664482.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6698.4773 - val_loss: 662645.6875\n",
      "Train on 12058 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 6358.6988 - val_loss: 650539.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9057.9215 - val_loss: 661526.4375\n",
      "Train on 12059 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6037.8395 - val_loss: 614049.3750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 5494.1785 - val_loss: 600017.0625\n",
      "Train on 12060 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10297.8465 - val_loss: 558647.1250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9350.5128 - val_loss: 553613.3750\n",
      "Train on 12061 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7676.0700 - val_loss: 595726.1875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 5625.8895 - val_loss: 590634.2500\n",
      "Train on 12062 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6628.5390 - val_loss: 607847.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5535.5784 - val_loss: 610155.5000\n",
      "Train on 12063 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 7393.3604 - val_loss: 622413.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9630.9350 - val_loss: 615996.5625\n",
      "Train on 12064 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9042.5506 - val_loss: 634886.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9878.5972 - val_loss: 620353.9375\n",
      "Train on 12065 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8011.7354 - val_loss: 595782.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10095.7303 - val_loss: 591864.2500\n",
      "Train on 12066 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8166.0410 - val_loss: 598334.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5876.5322 - val_loss: 613990.0625\n",
      "Train on 12067 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10257.1459 - val_loss: 614391.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7526.9714 - val_loss: 618980.9375\n",
      "Train on 12068 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 16642.0369 - val_loss: 604037.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10369.9380 - val_loss: 594795.6875\n",
      "Train on 12069 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7396.7287 - val_loss: 585636.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8829.8329 - val_loss: 580967.7500\n",
      "Train on 12070 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9262.3304 - val_loss: 628677.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7449.8797 - val_loss: 622449.7500\n",
      "Train on 12071 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8571.0378 - val_loss: 610341.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7539.1875 - val_loss: 606271.6875\n",
      "Train on 12072 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6385.0012 - val_loss: 603076.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5872.6176 - val_loss: 597985.4375\n",
      "Train on 12073 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6499.7959 - val_loss: 649197.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6520.0319 - val_loss: 649320.0000\n",
      "Train on 12074 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9580.1132 - val_loss: 669103.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7406.7980 - val_loss: 660385.1875\n",
      "Train on 12075 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 7116.1659 - val_loss: 626716.9375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7754.3378 - val_loss: 630120.4375\n",
      "Train on 12076 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8225.7155 - val_loss: 618699.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8726.5790 - val_loss: 611481.6250\n",
      "Train on 12077 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5664.6225 - val_loss: 600044.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7611.1925 - val_loss: 603791.6250\n",
      "Train on 12078 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7095.2905 - val_loss: 588838.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5873.0779 - val_loss: 580483.6250\n",
      "Train on 12079 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7016.9172 - val_loss: 616825.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7999.1904 - val_loss: 609992.2500\n",
      "Train on 12080 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6656.1736 - val_loss: 619305.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 12435.7211 - val_loss: 624777.9375\n",
      "Train on 12081 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6599.3552 - val_loss: 601231.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6090.2613 - val_loss: 594907.9375\n",
      "Train on 12082 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7020.0962 - val_loss: 616159.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7899.0659 - val_loss: 613504.2500\n",
      "Train on 12083 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7223.3795 - val_loss: 627890.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9572.7347 - val_loss: 634646.3750\n",
      "Train on 12084 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8783.5136 - val_loss: 636823.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5662.8246 - val_loss: 644550.2500\n",
      "Train on 12085 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8955.9176 - val_loss: 627875.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6132.5077 - val_loss: 638331.9375\n",
      "Train on 12086 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10999.6284 - val_loss: 556270.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6372.0202 - val_loss: 562658.9375\n",
      "Train on 12087 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9698.0196 - val_loss: 694470.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6934.9108 - val_loss: 685388.7500\n",
      "Train on 12088 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6564.7427 - val_loss: 691601.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5306.5836 - val_loss: 684467.3750\n",
      "Train on 12089 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8989.5476 - val_loss: 684118.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10337.4394 - val_loss: 678139.0000\n",
      "Train on 12090 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9263.1785 - val_loss: 647887.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9607.3112 - val_loss: 650159.5625\n",
      "Train on 12091 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 15993.3987 - val_loss: 679970.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5250.3905 - val_loss: 683055.0625\n",
      "Train on 12092 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6648.1317 - val_loss: 674246.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9927.7367 - val_loss: 675539.9375\n",
      "Train on 12093 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6733.0798 - val_loss: 666885.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7390.4356 - val_loss: 673539.1875\n",
      "Train on 12094 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10131.8022 - val_loss: 672150.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8007.7470 - val_loss: 675139.8750\n",
      "Train on 12095 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8153.1789 - val_loss: 638659.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7759.4240 - val_loss: 642079.4375\n",
      "Train on 12096 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8471.8647 - val_loss: 642358.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8128.4921 - val_loss: 648075.6875\n",
      "Train on 12097 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5559.5508 - val_loss: 649503.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5798.3391 - val_loss: 648424.4375\n",
      "Train on 12098 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 16601.6831 - val_loss: 695010.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8886.2290 - val_loss: 688075.5000\n",
      "Train on 12099 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5820.1063 - val_loss: 675580.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7438.6947 - val_loss: 682907.7500\n",
      "Train on 12100 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7514.3019 - val_loss: 678947.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7035.0851 - val_loss: 682361.9375\n",
      "Train on 12101 samples, validate on 1 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 7635.8968 - val_loss: 682100.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6846.5229 - val_loss: 696490.5000\n",
      "Train on 12102 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7133.1516 - val_loss: 657721.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7086.9949 - val_loss: 659666.7500\n",
      "Train on 12103 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7917.9898 - val_loss: 607225.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9926.7962 - val_loss: 606894.2500\n",
      "Train on 12104 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5883.3696 - val_loss: 648719.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6614.4498 - val_loss: 644444.0000\n",
      "Train on 12105 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5985.0278 - val_loss: 645921.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7910.4140 - val_loss: 639333.0000\n",
      "Train on 12106 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6644.3145 - val_loss: 672472.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6870.8860 - val_loss: 665759.1875\n",
      "Train on 12107 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8842.8895 - val_loss: 658456.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7522.8611 - val_loss: 667449.8750\n",
      "Train on 12108 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 11387.3410 - val_loss: 646098.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7861.0375 - val_loss: 643254.1250\n",
      "Train on 12109 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6115.3065 - val_loss: 665813.0000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8937.5589 - val_loss: 654356.1875\n",
      "Train on 12110 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8260.8924 - val_loss: 587719.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5094.4811 - val_loss: 594635.6250\n",
      "Train on 12111 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 7223.2431 - val_loss: 575706.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9719.2752 - val_loss: 580512.3125\n",
      "Train on 12112 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6262.5061 - val_loss: 724578.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6847.5072 - val_loss: 728008.8750\n",
      "Train on 12113 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 5754.5928 - val_loss: 804896.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8105.9147 - val_loss: 799393.1250\n",
      "Train on 12114 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 6735.0897 - val_loss: 747432.0000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6072.1161 - val_loss: 736956.8750\n",
      "Train on 12115 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 9230.0898 - val_loss: 736481.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6458.7749 - val_loss: 721407.6250\n",
      "Train on 12116 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 8474.0417 - val_loss: 699654.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6512.6948 - val_loss: 702830.0625\n",
      "Train on 12117 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6496.6810 - val_loss: 758854.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5913.6979 - val_loss: 749125.3125\n",
      "Train on 12118 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 6533.6734 - val_loss: 721693.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6569.1172 - val_loss: 729368.5625\n",
      "Train on 12119 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10268.3784 - val_loss: 729284.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6350.7037 - val_loss: 733332.5625\n",
      "Train on 12120 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6093.8773 - val_loss: 754056.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8309.9719 - val_loss: 758272.7500\n",
      "Train on 12121 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5651.8803 - val_loss: 754919.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7369.4364 - val_loss: 762147.7500\n",
      "Train on 12122 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 7518.5825 - val_loss: 693770.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5910.3483 - val_loss: 688138.3125\n",
      "Train on 12123 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9179.2661 - val_loss: 694529.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5536.9680 - val_loss: 706830.6250\n",
      "Train on 12124 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6693.0871 - val_loss: 694503.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7170.5595 - val_loss: 682751.1875\n",
      "Train on 12125 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7580.0050 - val_loss: 709698.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7704.3836 - val_loss: 691517.3125\n",
      "Train on 12126 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 7160.5043 - val_loss: 764977.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6267.5237 - val_loss: 766656.3125\n",
      "Train on 12127 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 9227.2798 - val_loss: 766998.8125\n",
      "Epoch 2/2\n",
      " - 1s - loss: 5379.9456 - val_loss: 757677.5625\n",
      "Train on 12128 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6420.1641 - val_loss: 648538.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6623.5835 - val_loss: 654492.4375\n",
      "Train on 12129 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5512.7822 - val_loss: 700113.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8027.5320 - val_loss: 699307.5000\n",
      "Train on 12130 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5717.0769 - val_loss: 678695.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8714.1634 - val_loss: 685237.9375\n",
      "Train on 12131 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6658.0483 - val_loss: 641385.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6243.7218 - val_loss: 634575.6250\n",
      "Train on 12132 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7639.6993 - val_loss: 669686.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6986.1581 - val_loss: 669830.3750\n",
      "Train on 12133 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6468.2864 - val_loss: 681268.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11852.9562 - val_loss: 684660.8750\n",
      "Train on 12134 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9562.5374 - val_loss: 750563.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8250.2360 - val_loss: 757535.1875\n",
      "Train on 12135 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7952.7147 - val_loss: 759710.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5098.6536 - val_loss: 756998.1250\n",
      "Train on 12136 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 7672.8004 - val_loss: 555919.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7307.0088 - val_loss: 564327.0625\n",
      "Train on 12137 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6799.3919 - val_loss: 583326.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7947.4520 - val_loss: 584849.3125\n",
      "Train on 12138 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4829.5626 - val_loss: 619922.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7064.0202 - val_loss: 605916.6875\n",
      "Train on 12139 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8116.3786 - val_loss: 575700.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7370.1592 - val_loss: 588997.0625\n",
      "Train on 12140 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9757.5370 - val_loss: 563623.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6235.2256 - val_loss: 571626.8125\n",
      "Train on 12141 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10920.9382 - val_loss: 617703.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5747.0054 - val_loss: 620552.0000\n",
      "Train on 12142 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10318.4221 - val_loss: 605874.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5365.5002 - val_loss: 604179.0625\n",
      "Train on 12143 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5850.6933 - val_loss: 622723.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7213.9317 - val_loss: 619161.8750\n",
      "Train on 12144 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6712.0628 - val_loss: 574393.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6357.9769 - val_loss: 587471.7500\n",
      "Train on 12145 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5921.2282 - val_loss: 605111.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6693.6708 - val_loss: 596784.5625\n",
      "Train on 12146 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8618.4850 - val_loss: 597874.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7216.6813 - val_loss: 590079.0000\n",
      "Train on 12147 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 12455.8362 - val_loss: 578544.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9058.4399 - val_loss: 581745.1250\n",
      "Train on 12148 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7136.0447 - val_loss: 594462.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8178.4663 - val_loss: 603805.2500\n",
      "Train on 12149 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7264.3195 - val_loss: 609550.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5723.9270 - val_loss: 612933.8125\n",
      "Train on 12150 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 5359.5128 - val_loss: 598681.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6504.5201 - val_loss: 596295.0000\n",
      "Train on 12151 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6401.7057 - val_loss: 571698.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9747.3826 - val_loss: 576911.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12152 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 5489.1685 - val_loss: 613240.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6511.4156 - val_loss: 613623.2500\n",
      "Train on 12153 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5579.0499 - val_loss: 557590.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7091.3499 - val_loss: 564389.3750\n",
      "Train on 12154 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7383.4437 - val_loss: 571074.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8934.8502 - val_loss: 569069.5000\n",
      "Train on 12155 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8273.5357 - val_loss: 580305.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 13251.7052 - val_loss: 595175.3125\n",
      "Train on 12156 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 11324.5357 - val_loss: 626014.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7510.0611 - val_loss: 623585.1250\n",
      "Train on 12157 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7158.7921 - val_loss: 617258.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5821.8291 - val_loss: 610728.5000\n",
      "Train on 12158 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6036.4967 - val_loss: 634758.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7044.2322 - val_loss: 631891.8750\n",
      "Train on 12159 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5303.6906 - val_loss: 557447.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7049.9017 - val_loss: 559515.3125\n",
      "Train on 12160 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 8606.1640 - val_loss: 574236.5000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 5589.9764 - val_loss: 574906.7500\n",
      "Train on 12161 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8775.7695 - val_loss: 625285.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9903.4957 - val_loss: 627223.3750\n",
      "Train on 12162 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9343.8314 - val_loss: 635276.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8118.9873 - val_loss: 640873.3750\n",
      "Train on 12163 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5528.5769 - val_loss: 629352.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6269.4068 - val_loss: 617657.8125\n",
      "Train on 12164 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6266.6590 - val_loss: 596613.6875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8143.0434 - val_loss: 597961.2500\n",
      "Train on 12165 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5341.6155 - val_loss: 629128.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11722.0115 - val_loss: 614969.5625\n",
      "Train on 12166 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6129.9589 - val_loss: 614474.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6776.4680 - val_loss: 619537.3125\n",
      "Train on 12167 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8336.0340 - val_loss: 590836.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7160.7505 - val_loss: 593877.5625\n",
      "Train on 12168 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5359.2520 - val_loss: 581941.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5467.5935 - val_loss: 569227.1250\n",
      "Train on 12169 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8114.3508 - val_loss: 581859.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7760.9551 - val_loss: 583729.9375\n",
      "Train on 12170 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7747.6897 - val_loss: 571382.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6129.7506 - val_loss: 577185.5625\n",
      "Train on 12171 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7192.8745 - val_loss: 581949.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6914.6137 - val_loss: 584343.4375\n",
      "Train on 12172 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9484.0146 - val_loss: 592559.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10280.4338 - val_loss: 597273.1250\n",
      "Train on 12173 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6050.2979 - val_loss: 619336.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9814.7204 - val_loss: 621177.1875\n",
      "Train on 12174 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5758.3895 - val_loss: 560678.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6303.4760 - val_loss: 554572.9375\n",
      "Train on 12175 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5868.0580 - val_loss: 575779.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4834.4442 - val_loss: 575999.1250\n",
      "Train on 12176 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9091.7718 - val_loss: 580434.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10789.5127 - val_loss: 579084.9375\n",
      "Train on 12177 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7450.1944 - val_loss: 580831.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7034.6262 - val_loss: 580312.1875\n",
      "Train on 12178 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8772.7029 - val_loss: 578120.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4951.1086 - val_loss: 581812.5000\n",
      "Train on 12179 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5791.6194 - val_loss: 623429.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5831.0994 - val_loss: 628129.3750\n",
      "Train on 12180 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7358.6554 - val_loss: 597367.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8355.6026 - val_loss: 596624.6250\n",
      "Train on 12181 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6180.3969 - val_loss: 579765.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9809.3810 - val_loss: 586171.9375\n",
      "Train on 12182 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5827.2286 - val_loss: 628761.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7223.3197 - val_loss: 628139.4375\n",
      "Train on 12183 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5095.4244 - val_loss: 623628.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8654.2653 - val_loss: 631074.3125\n",
      "Train on 12184 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7468.2490 - val_loss: 616037.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5682.4975 - val_loss: 623644.5000\n",
      "Train on 12185 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8262.9849 - val_loss: 604574.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6399.5191 - val_loss: 613985.1250\n",
      "Train on 12186 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6181.0010 - val_loss: 568816.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7777.4033 - val_loss: 573365.8125\n",
      "Train on 12187 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7154.9617 - val_loss: 604130.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6168.1653 - val_loss: 599256.3125\n",
      "Train on 12188 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9485.5483 - val_loss: 595223.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9213.1354 - val_loss: 588648.9375\n",
      "Train on 12189 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6776.4163 - val_loss: 567823.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5541.9524 - val_loss: 569814.1250\n",
      "Train on 12190 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5401.9610 - val_loss: 596486.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9013.5752 - val_loss: 585025.9375\n",
      "Train on 12191 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6567.8528 - val_loss: 591386.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5864.2778 - val_loss: 587240.8125\n",
      "Train on 12192 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 6120.5207 - val_loss: 601014.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7234.4311 - val_loss: 599878.2500\n",
      "Train on 12193 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6443.4388 - val_loss: 582176.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5694.2490 - val_loss: 582961.3125\n",
      "Train on 12194 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5279.6387 - val_loss: 583251.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7078.9615 - val_loss: 586643.8125\n",
      "Train on 12195 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8377.7997 - val_loss: 583201.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8621.6238 - val_loss: 585071.1250\n",
      "Train on 12196 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 12225.6435 - val_loss: 602725.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5690.9811 - val_loss: 594810.0000\n",
      "Train on 12197 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6419.5102 - val_loss: 610382.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6865.1144 - val_loss: 600636.7500\n",
      "Train on 12198 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4855.9427 - val_loss: 590516.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5177.0621 - val_loss: 591052.7500\n",
      "Train on 12199 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5919.2925 - val_loss: 571792.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5837.3617 - val_loss: 568303.5625\n",
      "Train on 12200 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6986.0900 - val_loss: 597411.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5668.4900 - val_loss: 601198.4375\n",
      "Train on 12201 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8188.7931 - val_loss: 609704.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7401.4338 - val_loss: 622799.9375\n",
      "Train on 12202 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5379.8593 - val_loss: 628424.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 2s - loss: 9398.9430 - val_loss: 646084.3125\n",
      "Train on 12203 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6788.1089 - val_loss: 521146.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6076.8468 - val_loss: 521345.3438\n",
      "Train on 12204 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6898.9224 - val_loss: 522103.2812\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5228.8071 - val_loss: 518235.1250\n",
      "Train on 12205 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5789.1044 - val_loss: 533432.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5391.2725 - val_loss: 528450.5625\n",
      "Train on 12206 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7740.5854 - val_loss: 525937.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6046.5261 - val_loss: 541462.0625\n",
      "Train on 12207 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6928.4911 - val_loss: 534088.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6271.2040 - val_loss: 530088.5000\n",
      "Train on 12208 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10374.5687 - val_loss: 560656.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10169.7545 - val_loss: 553437.5625\n",
      "Train on 12209 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7717.9862 - val_loss: 543211.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7388.7174 - val_loss: 546115.9375\n",
      "Train on 12210 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5610.5179 - val_loss: 543819.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8834.1580 - val_loss: 550273.5000\n",
      "Train on 12211 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9393.0418 - val_loss: 546550.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5695.1386 - val_loss: 548843.3125\n",
      "Train on 12212 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6817.9407 - val_loss: 546947.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6120.2749 - val_loss: 545337.5625\n",
      "Train on 12213 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6000.5204 - val_loss: 546186.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6027.1773 - val_loss: 553608.3125\n",
      "Train on 12214 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10097.5999 - val_loss: 532725.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5340.3388 - val_loss: 536294.5000\n",
      "Train on 12215 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 11286.4940 - val_loss: 549711.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5341.5983 - val_loss: 546196.4375\n",
      "Train on 12216 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6064.6243 - val_loss: 552232.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10745.4045 - val_loss: 560006.6875\n",
      "Train on 12217 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5915.7354 - val_loss: 551068.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8059.9558 - val_loss: 554672.1875\n",
      "Train on 12218 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6595.0223 - val_loss: 546244.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7902.4037 - val_loss: 553179.3125\n",
      "Train on 12219 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5151.8462 - val_loss: 561663.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6072.1663 - val_loss: 568374.2500\n",
      "Train on 12220 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7661.8287 - val_loss: 549187.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6040.6887 - val_loss: 552644.1250\n",
      "Train on 12221 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6578.0401 - val_loss: 517523.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8090.9559 - val_loss: 515848.3438\n",
      "Train on 12222 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5572.8425 - val_loss: 485614.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7700.3279 - val_loss: 482494.4062\n",
      "Train on 12223 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7742.0576 - val_loss: 590708.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5751.4595 - val_loss: 595750.3125\n",
      "Train on 12224 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5162.0643 - val_loss: 689131.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5276.5174 - val_loss: 689959.3750\n",
      "Train on 12225 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8951.1613 - val_loss: 621289.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8576.2736 - val_loss: 626628.0000\n",
      "Train on 12226 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6596.0176 - val_loss: 630852.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7516.8493 - val_loss: 626127.1875\n",
      "Train on 12227 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5703.5088 - val_loss: 653997.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10440.7912 - val_loss: 655477.6250\n",
      "Train on 12228 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5267.5412 - val_loss: 636270.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6915.5073 - val_loss: 628607.0000\n",
      "Train on 12229 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 11353.1800 - val_loss: 644328.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11487.6902 - val_loss: 649456.1875\n",
      "Train on 12230 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8803.8662 - val_loss: 621453.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6036.7081 - val_loss: 634462.4375\n",
      "Train on 12231 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9992.2497 - val_loss: 609397.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6365.0160 - val_loss: 634236.0625\n",
      "Train on 12232 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7529.4449 - val_loss: 649028.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6754.4795 - val_loss: 649784.0000\n",
      "Train on 12233 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6627.7816 - val_loss: 644193.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7530.8754 - val_loss: 645682.8750\n",
      "Train on 12234 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 11534.8166 - val_loss: 633995.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10172.2623 - val_loss: 631560.0625\n",
      "Train on 12235 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7859.5759 - val_loss: 637839.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9610.4849 - val_loss: 643247.0625\n",
      "Train on 12236 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7918.5464 - val_loss: 631917.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 13629.0512 - val_loss: 630752.3750\n",
      "Train on 12237 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8327.5197 - val_loss: 634245.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 12322.8415 - val_loss: 637314.1250\n",
      "Train on 12238 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8175.1545 - val_loss: 642945.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8898.3183 - val_loss: 635026.1250\n",
      "Train on 12239 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10201.1677 - val_loss: 638937.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8666.5243 - val_loss: 640029.3125\n",
      "Train on 12240 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8289.5963 - val_loss: 641663.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8622.2302 - val_loss: 644831.7500\n",
      "Train on 12241 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6798.8805 - val_loss: 676293.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6892.9235 - val_loss: 674399.4375\n",
      "Train on 12242 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10081.4967 - val_loss: 595700.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11572.8525 - val_loss: 598845.5000\n",
      "Train on 12243 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7929.5781 - val_loss: 633423.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6280.9839 - val_loss: 621132.5625\n",
      "Train on 12244 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7051.4410 - val_loss: 640277.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6259.1734 - val_loss: 644339.7500\n",
      "Train on 12245 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7119.9259 - val_loss: 627247.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9521.7060 - val_loss: 632111.9375\n",
      "Train on 12246 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5396.7811 - val_loss: 637897.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5899.2356 - val_loss: 635882.4375\n",
      "Train on 12247 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 12192.8907 - val_loss: 659212.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6388.0732 - val_loss: 643953.7500\n",
      "Train on 12248 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5333.2135 - val_loss: 610328.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11865.6399 - val_loss: 603334.8750\n",
      "Train on 12249 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6840.1786 - val_loss: 629973.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6001.4318 - val_loss: 614483.3750\n",
      "Train on 12250 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8990.3621 - val_loss: 610894.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6977.8072 - val_loss: 613790.3750\n",
      "Train on 12251 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6512.4111 - val_loss: 598025.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5584.6228 - val_loss: 598525.5000\n",
      "Train on 12252 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6232.2066 - val_loss: 624117.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8844.1953 - val_loss: 620698.1875\n",
      "Train on 12253 samples, validate on 1 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 9298.2570 - val_loss: 672841.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6650.3393 - val_loss: 673052.0000\n",
      "Train on 12254 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6871.4476 - val_loss: 699216.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8678.7945 - val_loss: 716709.8125\n",
      "Train on 12255 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7246.5454 - val_loss: 614520.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6899.0483 - val_loss: 615091.3125\n",
      "Train on 12256 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10821.4056 - val_loss: 545077.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5997.8023 - val_loss: 545911.3750\n",
      "Train on 12257 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8206.7573 - val_loss: 567157.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7426.6725 - val_loss: 565935.5000\n",
      "Train on 12258 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4975.6751 - val_loss: 598164.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6154.1367 - val_loss: 586938.9375\n",
      "Train on 12259 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 14787.7208 - val_loss: 596521.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11105.9746 - val_loss: 582313.5625\n",
      "Train on 12260 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9334.6270 - val_loss: 605990.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10187.7594 - val_loss: 594243.7500\n",
      "Train on 12261 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8466.1399 - val_loss: 604508.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5707.8001 - val_loss: 595108.6875\n",
      "Train on 12262 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7350.7385 - val_loss: 592780.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9276.1234 - val_loss: 603903.5625\n",
      "Train on 12263 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6762.0563 - val_loss: 587383.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6748.5178 - val_loss: 584509.8750\n",
      "Train on 12264 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8332.4452 - val_loss: 577900.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6362.3227 - val_loss: 586513.6875\n",
      "Train on 12265 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5844.5730 - val_loss: 633276.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5513.2573 - val_loss: 627498.3750\n",
      "Train on 12266 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9018.3973 - val_loss: 643941.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5007.6451 - val_loss: 635956.4375\n",
      "Train on 12267 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6613.3665 - val_loss: 637872.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6159.5575 - val_loss: 638667.1250\n",
      "Train on 12268 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7492.3468 - val_loss: 595373.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5819.2234 - val_loss: 594018.6875\n",
      "Train on 12269 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7624.6762 - val_loss: 604794.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7585.1201 - val_loss: 603719.5000\n",
      "Train on 12270 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 11168.6488 - val_loss: 603060.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5924.8014 - val_loss: 604337.6875\n",
      "Train on 12271 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4921.8516 - val_loss: 615159.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5145.6924 - val_loss: 620096.2500\n",
      "Train on 12272 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6648.6675 - val_loss: 600464.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5498.2338 - val_loss: 608516.9375\n",
      "Train on 12273 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5868.0759 - val_loss: 615615.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4803.2879 - val_loss: 614582.1250\n",
      "Train on 12274 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5520.5532 - val_loss: 605258.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7555.6435 - val_loss: 611669.1250\n",
      "Train on 12275 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6998.4508 - val_loss: 595656.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8041.9533 - val_loss: 600142.6250\n",
      "Train on 12276 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6506.7759 - val_loss: 622174.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5268.6667 - val_loss: 614475.6875\n",
      "Train on 12277 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5046.7493 - val_loss: 622373.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9870.9242 - val_loss: 616954.2500\n",
      "Train on 12278 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6264.6872 - val_loss: 610840.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7794.3706 - val_loss: 614111.7500\n",
      "Train on 12279 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8736.1448 - val_loss: 622100.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5909.6211 - val_loss: 623359.6250\n",
      "Train on 12280 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8154.7140 - val_loss: 628456.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6766.1825 - val_loss: 628575.6875\n",
      "Train on 12281 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8397.3984 - val_loss: 604838.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6180.4256 - val_loss: 604595.4375\n",
      "Train on 12282 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6209.1449 - val_loss: 589914.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5231.8479 - val_loss: 587239.6875\n",
      "Train on 12283 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4813.7820 - val_loss: 593333.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7387.1830 - val_loss: 583796.7500\n",
      "Train on 12284 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5472.6004 - val_loss: 612190.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6982.0095 - val_loss: 603504.8125\n",
      "Train on 12285 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5075.0296 - val_loss: 600488.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5292.2766 - val_loss: 595407.7500\n",
      "Train on 12286 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6173.1854 - val_loss: 594899.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8251.4471 - val_loss: 605651.0000\n",
      "Train on 12287 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6833.4821 - val_loss: 606260.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7928.2596 - val_loss: 591793.2500\n",
      "Train on 12288 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5842.4428 - val_loss: 586601.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6640.7568 - val_loss: 583105.2500\n",
      "Train on 12289 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7056.8355 - val_loss: 613477.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6929.3241 - val_loss: 609618.1875\n",
      "Train on 12290 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4446.2573 - val_loss: 618755.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6140.1963 - val_loss: 627046.6875\n",
      "Train on 12291 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4717.0881 - val_loss: 561599.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6346.3211 - val_loss: 564381.6875\n",
      "Train on 12292 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 6513.4405 - val_loss: 572218.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4981.0875 - val_loss: 565720.6875\n",
      "Train on 12293 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6250.8432 - val_loss: 588626.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9379.9458 - val_loss: 595985.8750\n",
      "Train on 12294 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8758.7780 - val_loss: 597308.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6364.0196 - val_loss: 605076.2500\n",
      "Train on 12295 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7690.2706 - val_loss: 597797.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10017.2923 - val_loss: 596920.3125\n",
      "Train on 12296 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6436.8347 - val_loss: 597172.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7624.8164 - val_loss: 592926.6875\n",
      "Train on 12297 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8590.3135 - val_loss: 602206.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4561.1573 - val_loss: 595902.5625\n",
      "Train on 12298 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 6205.8246 - val_loss: 604377.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9538.1269 - val_loss: 618047.8125\n",
      "Train on 12299 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5610.6515 - val_loss: 555548.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5815.2778 - val_loss: 549612.2500\n",
      "Train on 12300 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5902.4161 - val_loss: 557096.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7151.8145 - val_loss: 560439.0000\n",
      "Train on 12301 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5833.4630 - val_loss: 555704.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5387.0347 - val_loss: 569414.3125\n",
      "Train on 12302 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7785.4686 - val_loss: 551511.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6260.7066 - val_loss: 553295.8750\n",
      "Train on 12303 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5907.6269 - val_loss: 583532.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5569.0245 - val_loss: 583970.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12304 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4215.2825 - val_loss: 574175.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5718.9294 - val_loss: 573085.6250\n",
      "Train on 12305 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6381.9964 - val_loss: 569945.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6062.7259 - val_loss: 570043.4375\n",
      "Train on 12306 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8796.4885 - val_loss: 552033.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11323.5679 - val_loss: 552616.5625\n",
      "Train on 12307 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7759.5803 - val_loss: 575070.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7073.3476 - val_loss: 566172.1250\n",
      "Train on 12308 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5761.3202 - val_loss: 571140.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4836.8582 - val_loss: 566584.4375\n",
      "Train on 12309 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6983.6027 - val_loss: 563120.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5336.9751 - val_loss: 564298.8125\n",
      "Train on 12310 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5352.8475 - val_loss: 569131.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7865.4852 - val_loss: 568058.4375\n",
      "Train on 12311 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6392.3680 - val_loss: 576282.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6797.1082 - val_loss: 587746.8125\n",
      "Train on 12312 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5357.4182 - val_loss: 583213.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6031.6637 - val_loss: 588300.6250\n",
      "Train on 12313 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5900.7924 - val_loss: 579000.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7592.2214 - val_loss: 582458.8750\n",
      "Train on 12314 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5667.6343 - val_loss: 564840.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11329.5911 - val_loss: 571336.6875\n",
      "Train on 12315 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5171.0559 - val_loss: 573318.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7003.4395 - val_loss: 575211.1250\n",
      "Train on 12316 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7538.8578 - val_loss: 577203.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8575.1666 - val_loss: 590544.2500\n",
      "Train on 12317 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6502.3277 - val_loss: 599286.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5783.3785 - val_loss: 597427.5000\n",
      "Train on 12318 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9616.7069 - val_loss: 577576.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5808.0057 - val_loss: 565444.5000\n",
      "Train on 12319 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4760.3700 - val_loss: 560159.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8180.3669 - val_loss: 556966.6875\n",
      "Train on 12320 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7485.9964 - val_loss: 574655.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8014.0788 - val_loss: 577998.2500\n",
      "Train on 12321 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6117.5962 - val_loss: 569153.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5693.5308 - val_loss: 571638.2500\n",
      "Train on 12322 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6530.5215 - val_loss: 534738.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6448.6805 - val_loss: 539562.0000\n",
      "Train on 12323 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4986.1581 - val_loss: 559786.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6103.7597 - val_loss: 561574.9375\n",
      "Train on 12324 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6893.4782 - val_loss: 598788.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8247.1985 - val_loss: 590221.9375\n",
      "Train on 12325 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4189.0655 - val_loss: 576937.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7184.8894 - val_loss: 568587.8125\n",
      "Train on 12326 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6150.9963 - val_loss: 591103.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5339.2219 - val_loss: 587180.9375\n",
      "Train on 12327 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5359.9346 - val_loss: 690325.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6908.2055 - val_loss: 691869.3750\n",
      "Train on 12328 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5616.0999 - val_loss: 489353.5312\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5938.8956 - val_loss: 488958.7500\n",
      "Train on 12329 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6619.8463 - val_loss: 516148.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6298.0545 - val_loss: 523393.2500\n",
      "Train on 12330 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6389.5129 - val_loss: 530842.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10304.8935 - val_loss: 529271.8750\n",
      "Train on 12331 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6725.3910 - val_loss: 554668.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5005.4006 - val_loss: 549538.8125\n",
      "Train on 12332 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5720.1830 - val_loss: 554129.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5253.8058 - val_loss: 545582.0625\n",
      "Train on 12333 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5863.1956 - val_loss: 545899.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5655.4522 - val_loss: 543104.9375\n",
      "Train on 12334 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5489.3460 - val_loss: 533205.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5161.1660 - val_loss: 542444.1250\n",
      "Train on 12335 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7972.1997 - val_loss: 532928.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7798.5895 - val_loss: 536160.3750\n",
      "Train on 12336 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4706.9666 - val_loss: 543478.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10970.2768 - val_loss: 543341.7500\n",
      "Train on 12337 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6311.2269 - val_loss: 541650.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6413.4206 - val_loss: 531330.3125\n",
      "Train on 12338 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6119.6389 - val_loss: 538805.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6790.3591 - val_loss: 537398.5000\n",
      "Train on 12339 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5223.8054 - val_loss: 541770.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6490.4373 - val_loss: 543013.9375\n"
     ]
    }
   ],
   "source": [
    "res_2 = make_rolling_window(LSTM_model_2, train_X, train_y, val_X, val_y, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_3 = Sequential()\n",
    "LSTM_model_3.add(LSTM(64, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]), dropout=0.20,recurrent_dropout=0.20))\n",
    "LSTM_model_3.add(Dense(32))\n",
    "# LSTM_model_3.add(LSTM(16, activation='relu'))\n",
    "LSTM_model_3.add(Dense(1))\n",
    "LSTM_model_3.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 341 samples\n",
      "Epoch 1/200\n",
      " - 10s - loss: 1502832.4637 - val_loss: 207035.2041\n",
      "Epoch 2/200\n",
      " - 5s - loss: 832724.0346 - val_loss: 395961.5041\n",
      "Epoch 3/200\n",
      " - 5s - loss: 634450.5901 - val_loss: 485697.0751\n",
      "Epoch 4/200\n",
      " - 5s - loss: 595665.4696 - val_loss: 333706.7309\n",
      "Epoch 5/200\n",
      " - 5s - loss: 545648.6228 - val_loss: 475599.9688\n",
      "Epoch 6/200\n",
      " - 5s - loss: 465224.5832 - val_loss: 514627.8890\n",
      "Epoch 7/200\n",
      " - 5s - loss: 353140.1324 - val_loss: 524312.6702\n",
      "Epoch 8/200\n",
      " - 5s - loss: 297420.5733 - val_loss: 528573.6164\n",
      "Epoch 9/200\n",
      " - 5s - loss: 227346.6146 - val_loss: 588274.5471\n",
      "Epoch 10/200\n",
      " - 5s - loss: 199497.2403 - val_loss: 592290.0527\n",
      "Epoch 11/200\n",
      " - 5s - loss: 183979.7126 - val_loss: 581165.4515\n",
      "Epoch 12/200\n",
      " - 5s - loss: 173360.6006 - val_loss: 597060.8239\n",
      "Epoch 13/200\n",
      " - 5s - loss: 128790.2654 - val_loss: 635450.1765\n",
      "Epoch 14/200\n",
      " - 5s - loss: 134742.0503 - val_loss: 583985.6070\n",
      "Epoch 15/200\n",
      " - 5s - loss: 134481.9852 - val_loss: 549157.5228\n",
      "Epoch 16/200\n",
      " - 5s - loss: 115208.8305 - val_loss: 552724.3670\n",
      "Epoch 17/200\n",
      " - 6s - loss: 101849.5197 - val_loss: 578746.7984\n",
      "Epoch 18/200\n",
      " - 6s - loss: 89137.5265 - val_loss: 564583.6148\n",
      "Epoch 19/200\n",
      " - 5s - loss: 94029.5568 - val_loss: 560267.5268\n",
      "Epoch 20/200\n",
      " - 5s - loss: 90663.0893 - val_loss: 576725.6118\n",
      "Epoch 21/200\n",
      " - 5s - loss: 83620.0248 - val_loss: 600814.3435\n",
      "Epoch 22/200\n",
      " - 5s - loss: 61324.4320 - val_loss: 600424.2014\n",
      "Epoch 23/200\n",
      " - 5s - loss: 60042.7833 - val_loss: 594270.5082\n",
      "Epoch 24/200\n",
      " - 5s - loss: 47292.1343 - val_loss: 594637.1135\n",
      "Epoch 25/200\n",
      " - 5s - loss: 51648.8055 - val_loss: 578277.2078\n",
      "Epoch 26/200\n",
      " - 5s - loss: 45178.9749 - val_loss: 603723.8218\n",
      "Epoch 27/200\n",
      " - 5s - loss: 52573.7360 - val_loss: 625364.9318\n",
      "Epoch 28/200\n",
      " - 5s - loss: 46542.8367 - val_loss: 592059.6915\n",
      "Epoch 29/200\n",
      " - 5s - loss: 52915.9807 - val_loss: 602579.9648\n",
      "Epoch 30/200\n",
      " - 5s - loss: 40116.5540 - val_loss: 600891.0830\n",
      "Epoch 31/200\n",
      " - 5s - loss: 38751.4634 - val_loss: 603514.1701\n",
      "Epoch 32/200\n",
      " - 5s - loss: 36881.9539 - val_loss: 588562.2725\n",
      "Epoch 33/200\n",
      " - 5s - loss: 39044.5185 - val_loss: 615162.6124\n",
      "Epoch 34/200\n",
      " - 5s - loss: 33697.1684 - val_loss: 598552.5433\n",
      "Epoch 35/200\n",
      " - 5s - loss: 33720.9433 - val_loss: 607184.0227\n",
      "Epoch 36/200\n",
      " - 5s - loss: 42507.9949 - val_loss: 597372.9903\n",
      "Epoch 37/200\n",
      " - 5s - loss: 34071.7310 - val_loss: 610218.1353\n",
      "Epoch 38/200\n",
      " - 5s - loss: 37311.0871 - val_loss: 605320.9496\n",
      "Epoch 39/200\n",
      " - 5s - loss: 34001.5692 - val_loss: 598540.1882\n",
      "Epoch 40/200\n",
      " - 5s - loss: 33963.3746 - val_loss: 609156.7223\n",
      "Epoch 41/200\n",
      " - 5s - loss: 32001.1449 - val_loss: 603774.1266\n",
      "Epoch 42/200\n",
      " - 5s - loss: 33266.0634 - val_loss: 591067.0229\n",
      "Epoch 43/200\n",
      " - 5s - loss: 31614.2940 - val_loss: 604556.6127\n",
      "Epoch 44/200\n",
      " - 5s - loss: 34052.3481 - val_loss: 592555.9340\n",
      "Epoch 45/200\n",
      " - 5s - loss: 31014.9616 - val_loss: 596596.0156\n",
      "Epoch 46/200\n",
      " - 5s - loss: 30012.4364 - val_loss: 590560.9448\n",
      "Epoch 47/200\n",
      " - 5s - loss: 24469.0161 - val_loss: 595445.8389\n",
      "Epoch 48/200\n",
      " - 5s - loss: 38675.2900 - val_loss: 608215.9606\n",
      "Epoch 49/200\n",
      " - 5s - loss: 22550.7850 - val_loss: 596250.6750\n",
      "Epoch 50/200\n",
      " - 5s - loss: 24037.2841 - val_loss: 616716.2113\n",
      "Epoch 51/200\n",
      " - 5s - loss: 28795.8188 - val_loss: 582484.4172\n",
      "Epoch 52/200\n",
      " - 5s - loss: 23247.1638 - val_loss: 603367.4340\n",
      "Epoch 53/200\n",
      " - 5s - loss: 17862.8081 - val_loss: 602525.3044\n",
      "Epoch 54/200\n",
      " - 5s - loss: 26148.8651 - val_loss: 603220.7102\n",
      "Epoch 55/200\n",
      " - 5s - loss: 19971.0694 - val_loss: 591377.1626\n",
      "Epoch 56/200\n",
      " - 5s - loss: 23131.3805 - val_loss: 610476.2337\n",
      "Epoch 57/200\n",
      " - 5s - loss: 23057.6384 - val_loss: 600845.5365\n",
      "Epoch 58/200\n",
      " - 5s - loss: 23893.2208 - val_loss: 602656.6582\n",
      "Epoch 59/200\n",
      " - 5s - loss: 22666.8261 - val_loss: 592913.7110\n",
      "Epoch 60/200\n",
      " - 5s - loss: 22332.7592 - val_loss: 634653.0689\n",
      "Epoch 61/200\n",
      " - 5s - loss: 23434.4556 - val_loss: 590174.3550\n",
      "Epoch 62/200\n",
      " - 5s - loss: 21534.0273 - val_loss: 604253.2359\n",
      "Epoch 63/200\n",
      " - 5s - loss: 22883.9806 - val_loss: 586206.2562\n",
      "Epoch 64/200\n",
      " - 5s - loss: 20225.7223 - val_loss: 593914.4018\n",
      "Epoch 65/200\n",
      " - 5s - loss: 25994.1606 - val_loss: 606267.8248\n",
      "Epoch 66/200\n",
      " - 5s - loss: 19571.4310 - val_loss: 612514.2198\n",
      "Epoch 67/200\n",
      " - 5s - loss: 20759.8065 - val_loss: 599853.8933\n",
      "Epoch 68/200\n",
      " - 5s - loss: 16227.1415 - val_loss: 600352.0480\n",
      "Epoch 69/200\n",
      " - 5s - loss: 17401.7136 - val_loss: 588386.2051\n",
      "Epoch 70/200\n",
      " - 5s - loss: 22254.8102 - val_loss: 607922.5015\n",
      "Epoch 71/200\n",
      " - 5s - loss: 20759.8900 - val_loss: 600451.4848\n",
      "Epoch 72/200\n",
      " - 5s - loss: 17646.1976 - val_loss: 603381.2674\n",
      "Epoch 73/200\n",
      " - 5s - loss: 22004.9251 - val_loss: 597254.9936\n",
      "Epoch 74/200\n",
      " - 5s - loss: 23888.3598 - val_loss: 603883.5434\n",
      "Epoch 75/200\n",
      " - 5s - loss: 17477.2823 - val_loss: 601150.5621\n",
      "Epoch 76/200\n",
      " - 5s - loss: 16301.2598 - val_loss: 597872.6180\n",
      "Epoch 77/200\n",
      " - 5s - loss: 18060.0960 - val_loss: 603419.4912\n",
      "Epoch 78/200\n",
      " - 5s - loss: 15938.5645 - val_loss: 600165.9027\n",
      "Epoch 79/200\n",
      " - 5s - loss: 20672.4172 - val_loss: 602552.7744\n",
      "Epoch 80/200\n",
      " - 5s - loss: 27497.5317 - val_loss: 608902.6860\n",
      "Epoch 81/200\n",
      " - 5s - loss: 17746.0912 - val_loss: 595233.9382\n",
      "Epoch 82/200\n",
      " - 5s - loss: 15568.6912 - val_loss: 602747.7100\n",
      "Epoch 83/200\n",
      " - 5s - loss: 64409.5848 - val_loss: 579219.8915\n",
      "Epoch 84/200\n",
      " - 5s - loss: 56993.3251 - val_loss: 616787.5729\n",
      "Epoch 85/200\n",
      " - 5s - loss: 44967.7373 - val_loss: 612628.1723\n",
      "Epoch 86/200\n",
      " - 5s - loss: 23152.2681 - val_loss: 617258.4485\n",
      "Epoch 87/200\n",
      " - 5s - loss: 21858.1880 - val_loss: 606272.2940\n",
      "Epoch 88/200\n",
      " - 5s - loss: 19641.9149 - val_loss: 586649.4714\n",
      "Epoch 89/200\n",
      " - 5s - loss: 20590.7333 - val_loss: 583070.9415\n",
      "Epoch 90/200\n",
      " - 5s - loss: 17915.2167 - val_loss: 584322.2111\n",
      "Epoch 91/200\n",
      " - 5s - loss: 20717.2362 - val_loss: 582601.0194\n",
      "Epoch 92/200\n",
      " - 5s - loss: 15184.8704 - val_loss: 589822.3433\n",
      "Epoch 93/200\n",
      " - 5s - loss: 18591.7107 - val_loss: 588365.7161\n",
      "Epoch 94/200\n",
      " - 5s - loss: 13592.2116 - val_loss: 596606.3796\n",
      "Epoch 95/200\n",
      " - 5s - loss: 19714.8801 - val_loss: 605702.8174\n",
      "Epoch 96/200\n",
      " - 5s - loss: 16308.5079 - val_loss: 604028.1065\n",
      "Epoch 97/200\n",
      " - 5s - loss: 16182.9465 - val_loss: 603380.1716\n",
      "Epoch 98/200\n",
      " - 5s - loss: 15969.7873 - val_loss: 597414.8755\n",
      "Epoch 99/200\n",
      " - 5s - loss: 19119.3951 - val_loss: 595519.6455\n",
      "Epoch 100/200\n",
      " - 5s - loss: 18270.7121 - val_loss: 595683.1840\n",
      "Epoch 101/200\n",
      " - 5s - loss: 21739.2091 - val_loss: 600380.4128\n",
      "Epoch 102/200\n",
      " - 5s - loss: 13240.9743 - val_loss: 595577.0691\n",
      "Epoch 103/200\n",
      " - 5s - loss: 14117.5416 - val_loss: 591524.4137\n",
      "Epoch 104/200\n",
      " - 5s - loss: 14437.4213 - val_loss: 591491.0363\n",
      "Epoch 105/200\n",
      " - 6s - loss: 21536.2049 - val_loss: 612080.8314\n",
      "Epoch 106/200\n",
      " - 5s - loss: 18540.7141 - val_loss: 602497.9483\n",
      "Epoch 107/200\n",
      " - 5s - loss: 18540.8007 - val_loss: 598135.9331\n",
      "Epoch 108/200\n",
      " - 5s - loss: 15147.7641 - val_loss: 598316.4551\n",
      "Epoch 109/200\n",
      " - 5s - loss: 18619.6118 - val_loss: 601104.3382\n",
      "Epoch 110/200\n",
      " - 6s - loss: 18255.4861 - val_loss: 603864.8853\n",
      "Epoch 111/200\n",
      " - 6s - loss: 13884.2470 - val_loss: 597131.1573\n",
      "Epoch 112/200\n",
      " - 6s - loss: 19957.2537 - val_loss: 594367.2157\n",
      "Epoch 113/200\n",
      " - 5s - loss: 17784.3069 - val_loss: 585420.8862\n",
      "Epoch 114/200\n",
      " - 5s - loss: 14438.7548 - val_loss: 590577.9402\n",
      "Epoch 115/200\n",
      " - 5s - loss: 16661.7745 - val_loss: 580703.4274\n",
      "Epoch 116/200\n",
      " - 5s - loss: 17371.8560 - val_loss: 589652.1505\n",
      "Epoch 117/200\n",
      " - 6s - loss: 18545.3225 - val_loss: 606563.1540\n",
      "Epoch 118/200\n",
      " - 5s - loss: 16975.6891 - val_loss: 601693.7630\n",
      "Epoch 119/200\n",
      " - 5s - loss: 19597.0102 - val_loss: 602831.3251\n",
      "Epoch 120/200\n",
      " - 5s - loss: 16608.0688 - val_loss: 593259.8455\n",
      "Epoch 121/200\n",
      " - 5s - loss: 12330.8033 - val_loss: 588754.0284\n",
      "Epoch 122/200\n",
      " - 5s - loss: 11840.5584 - val_loss: 582658.2988\n",
      "Epoch 123/200\n",
      " - 5s - loss: 12174.2182 - val_loss: 588486.9344\n",
      "Epoch 124/200\n",
      " - 5s - loss: 14791.9187 - val_loss: 597221.1001\n",
      "Epoch 125/200\n",
      " - 5s - loss: 17874.5615 - val_loss: 589434.3123\n",
      "Epoch 126/200\n",
      " - 5s - loss: 14897.9762 - val_loss: 600693.4276\n",
      "Epoch 127/200\n",
      " - 5s - loss: 14571.3150 - val_loss: 594355.9346\n",
      "Epoch 128/200\n",
      " - 5s - loss: 12092.5411 - val_loss: 584766.3655\n",
      "Epoch 129/200\n",
      " - 5s - loss: 13105.9588 - val_loss: 592460.1261\n",
      "Epoch 130/200\n",
      " - 5s - loss: 13518.4545 - val_loss: 598642.6846\n",
      "Epoch 131/200\n",
      " - 5s - loss: 17069.3962 - val_loss: 590685.2399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      " - 5s - loss: 12678.1495 - val_loss: 587833.8605\n",
      "Epoch 133/200\n",
      " - 5s - loss: 19304.8917 - val_loss: 598249.1464\n",
      "Epoch 134/200\n",
      " - 5s - loss: 21741.2229 - val_loss: 592944.5673\n",
      "Epoch 135/200\n",
      " - 5s - loss: 38325.1022 - val_loss: 438105.0641\n",
      "Epoch 136/200\n",
      " - 4s - loss: 71386.6170 - val_loss: 511312.9062\n",
      "Epoch 137/200\n",
      " - 5s - loss: 62133.7817 - val_loss: 521976.8347\n",
      "Epoch 138/200\n",
      " - 5s - loss: 51305.6448 - val_loss: 528719.8525\n",
      "Epoch 139/200\n",
      " - 5s - loss: 52565.9730 - val_loss: 527466.2823\n",
      "Epoch 140/200\n",
      " - 4s - loss: 50529.1371 - val_loss: 516719.1169\n",
      "Epoch 141/200\n",
      " - 4s - loss: 48297.9000 - val_loss: 516779.3955\n",
      "Epoch 142/200\n",
      " - 5s - loss: 41818.4026 - val_loss: 498540.1343\n",
      "Epoch 143/200\n",
      " - 4s - loss: 43843.2173 - val_loss: 494042.3712\n",
      "Epoch 144/200\n",
      " - 5s - loss: 45461.5500 - val_loss: 567680.6246\n",
      "Epoch 145/200\n",
      " - 5s - loss: 41672.6622 - val_loss: 562004.4992\n",
      "Epoch 146/200\n",
      " - 4s - loss: 39201.9569 - val_loss: 587623.9897\n",
      "Epoch 147/200\n",
      " - 5s - loss: 38617.4281 - val_loss: 574321.0897\n",
      "Epoch 148/200\n",
      " - 5s - loss: 38148.6009 - val_loss: 571262.5105\n",
      "Epoch 149/200\n",
      " - 4s - loss: 33705.6040 - val_loss: 573296.3392\n",
      "Epoch 150/200\n",
      " - 4s - loss: 38487.3236 - val_loss: 583430.4589\n",
      "Epoch 151/200\n",
      " - 4s - loss: 33516.7009 - val_loss: 580242.0668\n",
      "Epoch 152/200\n",
      " - 5s - loss: 36054.5721 - val_loss: 568253.9189\n",
      "Epoch 153/200\n",
      " - 4s - loss: 34635.9343 - val_loss: 580571.6043\n",
      "Epoch 154/200\n",
      " - 4s - loss: 30372.5412 - val_loss: 571164.7120\n",
      "Epoch 155/200\n",
      " - 5s - loss: 34697.7325 - val_loss: 582793.9533\n",
      "Epoch 156/200\n",
      " - 4s - loss: 27853.1870 - val_loss: 569867.3629\n",
      "Epoch 157/200\n",
      " - 4s - loss: 26886.4047 - val_loss: 577836.1556\n",
      "Epoch 158/200\n",
      " - 4s - loss: 30264.6129 - val_loss: 587168.6083\n",
      "Epoch 159/200\n",
      " - 5s - loss: 26045.2545 - val_loss: 577448.6430\n",
      "Epoch 160/200\n",
      " - 4s - loss: 27838.5428 - val_loss: 573410.4151\n",
      "Epoch 161/200\n",
      " - 4s - loss: 26188.7657 - val_loss: 566811.1724\n",
      "Epoch 162/200\n",
      " - 5s - loss: 27400.1458 - val_loss: 586873.6283\n",
      "Epoch 163/200\n",
      " - 5s - loss: 25573.2181 - val_loss: 578219.1608\n",
      "Epoch 164/200\n",
      " - 5s - loss: 23280.5290 - val_loss: 577818.7886\n",
      "Epoch 165/200\n",
      " - 5s - loss: 23444.7291 - val_loss: 580045.9463\n",
      "Epoch 166/200\n",
      " - 5s - loss: 24137.1185 - val_loss: 583253.6915\n",
      "Epoch 167/200\n",
      " - 5s - loss: 29396.4958 - val_loss: 594273.0790\n",
      "Epoch 168/200\n",
      " - 5s - loss: 20273.1826 - val_loss: 577595.4459\n",
      "Epoch 169/200\n",
      " - 5s - loss: 19500.7326 - val_loss: 579674.7657\n",
      "Epoch 170/200\n",
      " - 5s - loss: 17004.3090 - val_loss: 575781.4282\n",
      "Epoch 171/200\n",
      " - 5s - loss: 16905.1552 - val_loss: 580011.2656\n",
      "Epoch 172/200\n",
      " - 5s - loss: 17811.6981 - val_loss: 584737.3250\n",
      "Epoch 173/200\n",
      " - 5s - loss: 16649.6029 - val_loss: 577902.1217\n",
      "Epoch 174/200\n",
      " - 5s - loss: 16138.6777 - val_loss: 594226.4872\n",
      "Epoch 175/200\n",
      " - 5s - loss: 17337.0825 - val_loss: 576500.7768\n",
      "Epoch 176/200\n",
      " - 5s - loss: 14324.6256 - val_loss: 591580.6683\n",
      "Epoch 177/200\n",
      " - 5s - loss: 16535.5367 - val_loss: 581441.2047\n",
      "Epoch 178/200\n",
      " - 5s - loss: 14268.6445 - val_loss: 589118.7397\n",
      "Epoch 179/200\n",
      " - 5s - loss: 14034.8961 - val_loss: 585732.2760\n",
      "Epoch 180/200\n",
      " - 5s - loss: 18685.1308 - val_loss: 583573.4826\n",
      "Epoch 181/200\n",
      " - 5s - loss: 13714.9411 - val_loss: 589481.1224\n",
      "Epoch 182/200\n",
      " - 5s - loss: 13695.5742 - val_loss: 586433.4216\n",
      "Epoch 183/200\n",
      " - 5s - loss: 17303.9206 - val_loss: 597328.8552\n",
      "Epoch 184/200\n",
      " - 5s - loss: 15724.5544 - val_loss: 590767.7694\n",
      "Epoch 185/200\n",
      " - 5s - loss: 13865.8149 - val_loss: 588349.1457\n",
      "Epoch 186/200\n",
      " - 5s - loss: 16903.5554 - val_loss: 592150.0304\n",
      "Epoch 187/200\n",
      " - 6s - loss: 11962.8957 - val_loss: 591006.0850\n",
      "Epoch 188/200\n",
      " - 5s - loss: 12265.4294 - val_loss: 599339.1312\n",
      "Epoch 189/200\n",
      " - 5s - loss: 20166.2000 - val_loss: 591803.1998\n",
      "Epoch 190/200\n",
      " - 5s - loss: 12500.4139 - val_loss: 592006.2352\n",
      "Epoch 191/200\n",
      " - 5s - loss: 13962.9517 - val_loss: 591551.0662\n",
      "Epoch 192/200\n",
      " - 5s - loss: 10615.7495 - val_loss: 604083.9633\n",
      "Epoch 193/200\n",
      " - 5s - loss: 11562.7986 - val_loss: 591910.3796\n",
      "Epoch 194/200\n",
      " - 5s - loss: 18802.2970 - val_loss: 595102.0453\n",
      "Epoch 195/200\n",
      " - 5s - loss: 11064.4673 - val_loss: 592910.8706\n",
      "Epoch 196/200\n",
      " - 5s - loss: 10164.5761 - val_loss: 593377.4269\n",
      "Epoch 197/200\n",
      " - 5s - loss: 11607.2525 - val_loss: 600791.7502\n",
      "Epoch 198/200\n",
      " - 5s - loss: 13511.3981 - val_loss: 585151.2315\n",
      "Epoch 199/200\n",
      " - 5s - loss: 11603.4629 - val_loss: 591862.9131\n",
      "Epoch 200/200\n",
      " - 5s - loss: 11153.7417 - val_loss: 594558.9566\n"
     ]
    }
   ],
   "source": [
    "history_3 = LSTM_model_3.fit(train_X, train_y, \n",
    "                    epochs= 200, \n",
    "                    batch_size = 32, \n",
    "                    validation_data=(val_X, val_y),\n",
    "                    verbose=2,\n",
    "#                     callbacks=[earlystopper],\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 10789.0059 - val_loss: 541837.2500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10954.4502 - val_loss: 545002.2500\n",
      "Train on 12001 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 15788.2712 - val_loss: 579280.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11987.3138 - val_loss: 571716.5000\n",
      "Train on 12002 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 10390.5439 - val_loss: 564467.5625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9401.8322 - val_loss: 564954.0625\n",
      "Train on 12003 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 14435.5771 - val_loss: 593377.1875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9868.2343 - val_loss: 593680.8125\n",
      "Train on 12004 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 13585.9284 - val_loss: 588420.8125\n",
      "Epoch 2/2\n",
      " - 1s - loss: 11242.9788 - val_loss: 594861.1875\n",
      "Train on 12005 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10800.0311 - val_loss: 673894.3125\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10197.9621 - val_loss: 664575.6250\n",
      "Train on 12006 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10017.1813 - val_loss: 586402.6250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 11020.9671 - val_loss: 589585.1250\n",
      "Train on 12007 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9418.9335 - val_loss: 567531.5625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12002.9334 - val_loss: 557435.3750\n",
      "Train on 12008 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9181.5466 - val_loss: 590662.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10677.1510 - val_loss: 572888.5625\n",
      "Train on 12009 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 11583.1029 - val_loss: 598384.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8347.6056 - val_loss: 593800.0625\n",
      "Train on 12010 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 12430.2531 - val_loss: 591036.2500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9800.3181 - val_loss: 597220.3125\n",
      "Train on 12011 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7780.5816 - val_loss: 620006.3125\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9931.2612 - val_loss: 608896.7500\n",
      "Train on 12012 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8748.6232 - val_loss: 556685.3750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10423.2022 - val_loss: 551430.6250\n",
      "Train on 12013 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 11318.2418 - val_loss: 521629.5312\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7980.8040 - val_loss: 534272.1250\n",
      "Train on 12014 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 13759.0630 - val_loss: 565120.0000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9156.6370 - val_loss: 568508.6250\n",
      "Train on 12015 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7705.5338 - val_loss: 561243.1250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8440.0052 - val_loss: 559487.1875\n",
      "Train on 12016 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 12920.5510 - val_loss: 545802.8125\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9246.8250 - val_loss: 549498.2500\n",
      "Train on 12017 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 11011.9289 - val_loss: 578638.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11548.1680 - val_loss: 582089.2500\n",
      "Train on 12018 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9379.0429 - val_loss: 582875.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 15109.8482 - val_loss: 578674.4375\n",
      "Train on 12019 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8832.6608 - val_loss: 561337.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9284.8078 - val_loss: 564032.1875\n",
      "Train on 12020 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8958.0054 - val_loss: 574610.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10890.3877 - val_loss: 584983.7500\n",
      "Train on 12021 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8019.1574 - val_loss: 558453.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8763.4137 - val_loss: 556471.1875\n",
      "Train on 12022 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 13664.4453 - val_loss: 515233.4062\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11761.6883 - val_loss: 524754.8750\n",
      "Train on 12023 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10508.5152 - val_loss: 499044.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 12124.3233 - val_loss: 502782.7812\n",
      "Train on 12024 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7978.9551 - val_loss: 691094.6875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12192.0237 - val_loss: 694265.3125\n",
      "Train on 12025 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10450.0195 - val_loss: 712958.8125\n",
      "Epoch 2/2\n",
      " - 1s - loss: 11983.5920 - val_loss: 717245.6250\n",
      "Train on 12026 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 13661.9057 - val_loss: 694417.0625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10555.6949 - val_loss: 689817.0625\n",
      "Train on 12027 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9206.4004 - val_loss: 679566.7500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 19667.5623 - val_loss: 682287.3125\n",
      "Train on 12028 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8400.4180 - val_loss: 684336.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10510.8444 - val_loss: 685107.4375\n",
      "Train on 12029 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10850.0844 - val_loss: 640955.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8246.5375 - val_loss: 639261.9375\n",
      "Train on 12030 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9474.8563 - val_loss: 652581.1250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8674.8828 - val_loss: 653723.1875\n",
      "Train on 12031 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 10465.6511 - val_loss: 659767.9375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10433.4374 - val_loss: 652206.0625\n",
      "Train on 12032 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 8597.7934 - val_loss: 702483.3750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 14283.6696 - val_loss: 713626.0625\n",
      "Train on 12033 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8128.0595 - val_loss: 697033.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10716.3573 - val_loss: 695380.0625\n",
      "Train on 12034 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 10357.4475 - val_loss: 682013.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6872.9046 - val_loss: 677915.4375\n",
      "Train on 12035 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 7073.3405 - val_loss: 689322.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7767.6853 - val_loss: 689105.5000\n",
      "Train on 12036 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 7292.5060 - val_loss: 572745.5625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10125.5301 - val_loss: 571420.1250\n",
      "Train on 12037 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 10435.1653 - val_loss: 605734.2500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8192.2944 - val_loss: 610104.0000\n",
      "Train on 12038 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 9835.9543 - val_loss: 704120.5000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8445.8374 - val_loss: 710026.7500\n",
      "Train on 12039 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 9071.4629 - val_loss: 675956.9375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8305.3522 - val_loss: 687653.1250\n",
      "Train on 12040 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 13288.7001 - val_loss: 655153.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9796.1496 - val_loss: 646657.4375\n",
      "Train on 12041 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 11925.6436 - val_loss: 729287.2500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10199.0815 - val_loss: 728533.5000\n",
      "Train on 12042 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8161.6995 - val_loss: 667457.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8699.1686 - val_loss: 666636.7500\n",
      "Train on 12043 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 9878.1673 - val_loss: 656728.1875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10555.3642 - val_loss: 662645.3125\n",
      "Train on 12044 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 7542.8528 - val_loss: 675466.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8876.9170 - val_loss: 681132.6875\n",
      "Train on 12045 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 7267.2832 - val_loss: 580593.3750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12940.5744 - val_loss: 591588.5625\n",
      "Train on 12046 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 11021.5457 - val_loss: 648801.1250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8914.1063 - val_loss: 644560.8125\n",
      "Train on 12047 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8361.4483 - val_loss: 663898.7500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12036.5439 - val_loss: 656304.5000\n",
      "Train on 12048 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8803.1513 - val_loss: 700770.0625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8750.2386 - val_loss: 683170.8750\n",
      "Train on 12049 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8660.6135 - val_loss: 635699.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8002.4003 - val_loss: 640838.5625\n",
      "Train on 12050 samples, validate on 1 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 9111.8746 - val_loss: 630968.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 11736.9813 - val_loss: 636676.5625\n",
      "Train on 12051 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8710.9459 - val_loss: 664951.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12698.3957 - val_loss: 669682.1250\n",
      "Train on 12052 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 11809.9919 - val_loss: 669609.7500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9089.4839 - val_loss: 676263.6875\n",
      "Train on 12053 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 9455.5457 - val_loss: 688962.0000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 12587.7597 - val_loss: 694060.2500\n",
      "Train on 12054 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 11262.3426 - val_loss: 686432.5000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10340.1885 - val_loss: 690035.6250\n",
      "Train on 12055 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 6602.5993 - val_loss: 656956.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6852.7446 - val_loss: 640169.9375\n",
      "Train on 12056 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8526.2288 - val_loss: 649238.5625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7937.7795 - val_loss: 655612.0625\n",
      "Train on 12057 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8869.9499 - val_loss: 664208.6875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8465.8799 - val_loss: 651330.1875\n",
      "Train on 12058 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8213.5768 - val_loss: 639548.5000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7575.6198 - val_loss: 628706.1250\n",
      "Train on 12059 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 7921.9297 - val_loss: 595809.5000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9281.2276 - val_loss: 610036.5000\n",
      "Train on 12060 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 9216.8107 - val_loss: 574367.1250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10389.2036 - val_loss: 577159.6250\n",
      "Train on 12061 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8257.9751 - val_loss: 607621.0000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9713.2453 - val_loss: 603727.5000\n",
      "Train on 12062 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 11116.4782 - val_loss: 611308.6875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 10152.2453 - val_loss: 604829.7500\n",
      "Train on 12063 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8296.7168 - val_loss: 605600.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9397.4102 - val_loss: 601324.5000\n",
      "Train on 12064 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 8028.1534 - val_loss: 616471.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7224.1390 - val_loss: 611753.1250\n",
      "Train on 12065 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 6626.5971 - val_loss: 589424.3125\n",
      "Epoch 2/2\n",
      " - 1s - loss: 8597.0424 - val_loss: 584463.6250\n",
      "Train on 12066 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7447.6538 - val_loss: 609051.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7374.4568 - val_loss: 605779.8750\n",
      "Train on 12067 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 9118.0733 - val_loss: 608208.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6460.7238 - val_loss: 611199.1250\n",
      "Train on 12068 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 9231.5881 - val_loss: 587030.5625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7834.5528 - val_loss: 589473.8125\n",
      "Train on 12069 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8474.0262 - val_loss: 594345.7500\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7709.8803 - val_loss: 582784.6250\n",
      "Train on 12070 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 10388.3212 - val_loss: 620731.6250\n",
      "Epoch 2/2\n",
      " - 1s - loss: 7241.2842 - val_loss: 614371.2500\n",
      "Train on 12071 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9098.0323 - val_loss: 594779.5000\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9047.6268 - val_loss: 602050.5625\n",
      "Train on 12072 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 6852.7311 - val_loss: 594860.0625\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6015.8660 - val_loss: 604001.8125\n",
      "Train on 12073 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7808.3884 - val_loss: 638570.3125\n",
      "Epoch 2/2\n",
      " - 1s - loss: 9214.2055 - val_loss: 644883.5000\n",
      "Train on 12074 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9536.6571 - val_loss: 635798.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7951.1806 - val_loss: 642513.3750\n",
      "Train on 12075 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5853.5149 - val_loss: 612019.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6762.0795 - val_loss: 615950.5625\n",
      "Train on 12076 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7677.4134 - val_loss: 613513.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8217.6044 - val_loss: 604600.3750\n",
      "Train on 12077 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6899.4413 - val_loss: 603488.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7676.3624 - val_loss: 598321.1250\n",
      "Train on 12078 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9393.6441 - val_loss: 589253.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8525.2273 - val_loss: 588154.9375\n",
      "Train on 12079 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9403.2272 - val_loss: 610517.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7118.7779 - val_loss: 608831.5625\n",
      "Train on 12080 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 10617.3915 - val_loss: 610590.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6094.1702 - val_loss: 609206.9375\n",
      "Train on 12081 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8269.0878 - val_loss: 602712.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7900.0010 - val_loss: 598922.5625\n",
      "Train on 12082 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8382.3591 - val_loss: 615328.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5043.9825 - val_loss: 614567.1875\n",
      "Train on 12083 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7399.4467 - val_loss: 618703.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5787.2133 - val_loss: 613827.1250\n",
      "Train on 12084 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 15047.5869 - val_loss: 635225.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7457.8893 - val_loss: 635769.5000\n",
      "Train on 12085 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7263.2677 - val_loss: 624449.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6396.2844 - val_loss: 629230.8750\n",
      "Train on 12086 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5667.8833 - val_loss: 577036.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6932.2930 - val_loss: 579510.8750\n",
      "Train on 12087 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9710.7288 - val_loss: 688188.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8553.0439 - val_loss: 689533.1875\n",
      "Train on 12088 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7118.3401 - val_loss: 656405.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7557.9184 - val_loss: 654957.8750\n",
      "Train on 12089 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6974.1869 - val_loss: 654930.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7385.2408 - val_loss: 658043.3750\n",
      "Train on 12090 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9976.2805 - val_loss: 643621.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 13220.2426 - val_loss: 637359.7500\n",
      "Train on 12091 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7977.8917 - val_loss: 668461.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7737.5576 - val_loss: 666533.1250\n",
      "Train on 12092 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8350.9020 - val_loss: 665556.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9966.8079 - val_loss: 658401.1250\n",
      "Train on 12093 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6067.1921 - val_loss: 662148.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6615.7721 - val_loss: 661733.3750\n",
      "Train on 12094 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6766.1121 - val_loss: 667911.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6642.4329 - val_loss: 667211.7500\n",
      "Train on 12095 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 6550.0892 - val_loss: 641595.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8206.1958 - val_loss: 639664.1250\n",
      "Train on 12096 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9837.5043 - val_loss: 644917.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7713.6647 - val_loss: 640485.2500\n",
      "Train on 12097 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9707.7998 - val_loss: 655102.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9940.8914 - val_loss: 657911.8750\n",
      "Train on 12098 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 6882.5383 - val_loss: 684515.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8957.7022 - val_loss: 681445.8125\n",
      "Train on 12099 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8418.5256 - val_loss: 659665.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6108.7225 - val_loss: 665270.0000\n",
      "Train on 12100 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6612.3336 - val_loss: 659480.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6441.9333 - val_loss: 666655.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12101 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8430.0901 - val_loss: 677721.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7095.6211 - val_loss: 673794.0625\n",
      "Train on 12102 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8041.3129 - val_loss: 642150.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6700.0873 - val_loss: 645618.5000\n",
      "Train on 12103 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7242.7750 - val_loss: 615029.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6028.8861 - val_loss: 616543.5625\n",
      "Train on 12104 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 12561.0850 - val_loss: 645221.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7844.3285 - val_loss: 649826.5000\n",
      "Train on 12105 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8794.7828 - val_loss: 641165.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9782.4228 - val_loss: 633442.2500\n",
      "Train on 12106 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8140.8721 - val_loss: 663191.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6990.9125 - val_loss: 664588.0000\n",
      "Train on 12107 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7244.7236 - val_loss: 649647.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6632.3583 - val_loss: 650918.4375\n",
      "Train on 12108 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7121.1393 - val_loss: 634179.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5954.2673 - val_loss: 629523.3125\n",
      "Train on 12109 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5724.2873 - val_loss: 658259.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 12498.8886 - val_loss: 651871.3125\n",
      "Train on 12110 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8427.5718 - val_loss: 615618.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6366.3862 - val_loss: 605771.8750\n",
      "Train on 12111 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6188.0142 - val_loss: 615719.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8721.7704 - val_loss: 615896.9375\n",
      "Train on 12112 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6941.7407 - val_loss: 734987.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6142.0488 - val_loss: 722821.2500\n",
      "Train on 12113 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7535.2911 - val_loss: 750472.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7602.2448 - val_loss: 748235.1250\n",
      "Train on 12114 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8846.6930 - val_loss: 706184.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6111.1189 - val_loss: 708324.0000\n",
      "Train on 12115 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7262.3035 - val_loss: 713932.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5013.3985 - val_loss: 718393.2500\n",
      "Train on 12116 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7383.5272 - val_loss: 702539.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5096.0779 - val_loss: 710518.1250\n",
      "Train on 12117 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 9517.9165 - val_loss: 739177.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7939.3677 - val_loss: 748152.7500\n",
      "Train on 12118 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7027.5176 - val_loss: 703006.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5459.3222 - val_loss: 717268.8125\n",
      "Train on 12119 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 7751.3887 - val_loss: 720286.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6886.4087 - val_loss: 717908.2500\n",
      "Train on 12120 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7389.7041 - val_loss: 739897.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5992.0218 - val_loss: 737340.0000\n",
      "Train on 12121 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 6938.6093 - val_loss: 723393.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7278.3701 - val_loss: 731228.7500\n",
      "Train on 12122 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7094.7972 - val_loss: 671799.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8867.5776 - val_loss: 677572.9375\n",
      "Train on 12123 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5695.9612 - val_loss: 698176.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9721.9252 - val_loss: 696632.6875\n",
      "Train on 12124 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 8708.8707 - val_loss: 696719.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5628.3995 - val_loss: 698553.9375\n",
      "Train on 12125 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 5198.9075 - val_loss: 713277.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6041.5328 - val_loss: 697956.6250\n",
      "Train on 12126 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 7316.5258 - val_loss: 732386.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5004.7567 - val_loss: 740062.0000\n",
      "Train on 12127 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 6433.7561 - val_loss: 721565.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7592.7961 - val_loss: 722359.3125\n",
      "Train on 12128 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 11997.3474 - val_loss: 652568.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8402.8326 - val_loss: 654218.7500\n",
      "Train on 12129 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6584.9658 - val_loss: 701948.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5436.4907 - val_loss: 697202.5625\n",
      "Train on 12130 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7765.3102 - val_loss: 663319.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9379.1866 - val_loss: 675137.4375\n",
      "Train on 12131 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5890.6791 - val_loss: 654815.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5924.9280 - val_loss: 641808.6875\n",
      "Train on 12132 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9441.4873 - val_loss: 672973.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6377.9707 - val_loss: 670957.7500\n",
      "Train on 12133 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5511.3879 - val_loss: 675488.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5596.5467 - val_loss: 669509.8750\n",
      "Train on 12134 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7080.5667 - val_loss: 701515.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7272.6474 - val_loss: 700056.6250\n",
      "Train on 12135 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9883.1586 - val_loss: 691249.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6580.1517 - val_loss: 687086.3750\n",
      "Train on 12136 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8299.6435 - val_loss: 565200.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6725.0408 - val_loss: 556043.3125\n",
      "Train on 12137 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5133.2652 - val_loss: 594366.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5762.4370 - val_loss: 598607.0625\n",
      "Train on 12138 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4996.1521 - val_loss: 616651.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5526.9644 - val_loss: 613018.6250\n",
      "Train on 12139 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5244.2395 - val_loss: 569259.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10069.1882 - val_loss: 576171.0625\n",
      "Train on 12140 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9501.7658 - val_loss: 572627.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5917.5488 - val_loss: 581025.0625\n",
      "Train on 12141 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5842.5812 - val_loss: 600660.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6236.4216 - val_loss: 604608.3750\n",
      "Train on 12142 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4515.8436 - val_loss: 588149.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9653.8823 - val_loss: 583348.7500\n",
      "Train on 12143 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 12938.4433 - val_loss: 604692.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6938.7017 - val_loss: 600525.8750\n",
      "Train on 12144 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6192.6947 - val_loss: 575736.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6270.9558 - val_loss: 576084.3125\n",
      "Train on 12145 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9734.6644 - val_loss: 592320.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7173.5891 - val_loss: 593057.9375\n",
      "Train on 12146 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7365.2180 - val_loss: 588927.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4434.6062 - val_loss: 589063.3750\n",
      "Train on 12147 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6036.0456 - val_loss: 565286.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7084.3902 - val_loss: 571001.6250\n",
      "Train on 12148 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6762.7883 - val_loss: 589452.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5079.2636 - val_loss: 591976.9375\n",
      "Train on 12149 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5926.4620 - val_loss: 593618.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7245.6150 - val_loss: 592236.9375\n",
      "Train on 12150 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10436.5364 - val_loss: 584055.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6667.8427 - val_loss: 580117.2500\n",
      "Train on 12151 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7003.1079 - val_loss: 566348.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 2s - loss: 5921.4742 - val_loss: 565104.1875\n",
      "Train on 12152 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5476.1093 - val_loss: 590241.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5587.0652 - val_loss: 587082.1875\n",
      "Train on 12153 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4829.7184 - val_loss: 558927.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6760.3337 - val_loss: 555982.8750\n",
      "Train on 12154 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6025.3549 - val_loss: 572513.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4849.7966 - val_loss: 569725.3125\n",
      "Train on 12155 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7582.5732 - val_loss: 582896.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5642.4315 - val_loss: 576918.5000\n",
      "Train on 12156 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5170.9082 - val_loss: 599151.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4565.7571 - val_loss: 604950.8750\n",
      "Train on 12157 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5033.5959 - val_loss: 593644.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4581.5206 - val_loss: 590795.6250\n",
      "Train on 12158 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6543.0871 - val_loss: 606351.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6217.1906 - val_loss: 603000.8125\n",
      "Train on 12159 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5776.7320 - val_loss: 567083.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7224.0787 - val_loss: 566960.1250\n",
      "Train on 12160 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4531.0264 - val_loss: 589929.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5279.2921 - val_loss: 579464.7500\n",
      "Train on 12161 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5489.6569 - val_loss: 609033.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7651.7302 - val_loss: 604555.2500\n",
      "Train on 12162 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4824.8777 - val_loss: 607364.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6026.3227 - val_loss: 603251.0625\n",
      "Train on 12163 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10012.3684 - val_loss: 594514.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5349.5039 - val_loss: 605765.0000\n",
      "Train on 12164 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5706.6598 - val_loss: 588524.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6801.3369 - val_loss: 592103.1875\n",
      "Train on 12165 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5449.5985 - val_loss: 581332.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10232.5765 - val_loss: 610964.0000\n",
      "Train on 12166 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6945.1378 - val_loss: 596366.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8501.3882 - val_loss: 593894.8750\n",
      "Train on 12167 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4983.5567 - val_loss: 575474.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4466.5660 - val_loss: 573131.4375\n",
      "Train on 12168 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4834.8585 - val_loss: 566435.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4912.4214 - val_loss: 572228.3750\n",
      "Train on 12169 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7963.3584 - val_loss: 576074.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6981.5716 - val_loss: 574075.9375\n",
      "Train on 12170 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6551.4157 - val_loss: 569055.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4948.7300 - val_loss: 572591.8750\n",
      "Train on 12171 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4798.5936 - val_loss: 578442.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4055.4668 - val_loss: 575255.5625\n",
      "Train on 12172 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9088.3193 - val_loss: 576872.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4965.0561 - val_loss: 579171.5625\n",
      "Train on 12173 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5565.1505 - val_loss: 592920.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6556.2299 - val_loss: 583641.1875\n",
      "Train on 12174 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5250.3114 - val_loss: 547352.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7359.3230 - val_loss: 540549.5000\n",
      "Train on 12175 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6576.8908 - val_loss: 574260.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4911.7112 - val_loss: 559761.1250\n",
      "Train on 12176 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5711.0286 - val_loss: 576226.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6799.9370 - val_loss: 579219.5000\n",
      "Train on 12177 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5355.1728 - val_loss: 576379.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6100.6096 - val_loss: 578115.1875\n",
      "Train on 12178 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4564.3600 - val_loss: 577026.4375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 4990.8171 - val_loss: 571223.3750\n",
      "Train on 12179 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5299.6303 - val_loss: 601355.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7359.2371 - val_loss: 601941.5000\n",
      "Train on 12180 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5544.8463 - val_loss: 578901.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5269.8268 - val_loss: 577973.0000\n",
      "Train on 12181 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3733.1542 - val_loss: 568633.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3973.0661 - val_loss: 570835.1875\n",
      "Train on 12182 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5073.1657 - val_loss: 601562.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5896.4390 - val_loss: 601302.9375\n",
      "Train on 12183 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7172.5864 - val_loss: 591377.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6041.4956 - val_loss: 598272.8125\n",
      "Train on 12184 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5203.6757 - val_loss: 595446.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6043.6329 - val_loss: 593258.3750\n",
      "Train on 12185 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4576.5720 - val_loss: 587938.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4775.1364 - val_loss: 581789.4375\n",
      "Train on 12186 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7291.8724 - val_loss: 560504.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5358.1854 - val_loss: 562738.0625\n",
      "Train on 12187 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5178.7766 - val_loss: 582560.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5235.4120 - val_loss: 580698.6875\n",
      "Train on 12188 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4701.8838 - val_loss: 573958.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4031.5492 - val_loss: 578321.6250\n",
      "Train on 12189 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5882.4585 - val_loss: 557652.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4303.0390 - val_loss: 558396.0625\n",
      "Train on 12190 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5807.4641 - val_loss: 578453.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5950.1993 - val_loss: 587700.8125\n",
      "Train on 12191 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8361.5282 - val_loss: 577484.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5892.2894 - val_loss: 575989.8125\n",
      "Train on 12192 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5445.3587 - val_loss: 586220.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3979.4513 - val_loss: 579016.1875\n",
      "Train on 12193 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4414.3340 - val_loss: 575529.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5642.6218 - val_loss: 574797.1875\n",
      "Train on 12194 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6145.4086 - val_loss: 576069.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9653.4859 - val_loss: 562425.6875\n",
      "Train on 12195 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4860.8332 - val_loss: 561236.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5254.9495 - val_loss: 577844.1875\n",
      "Train on 12196 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4803.9204 - val_loss: 590196.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8777.3782 - val_loss: 588620.1250\n",
      "Train on 12197 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4422.6808 - val_loss: 596573.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7171.8931 - val_loss: 588520.5000\n",
      "Train on 12198 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3657.6092 - val_loss: 582010.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3861.7919 - val_loss: 577390.7500\n",
      "Train on 12199 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 5029.7583 - val_loss: 570056.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4937.4723 - val_loss: 565317.1250\n",
      "Train on 12200 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5802.3499 - val_loss: 589269.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 5703.1634 - val_loss: 583965.7500\n",
      "Train on 12201 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 5014.6806 - val_loss: 581739.8750\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6787.8935 - val_loss: 587512.5000\n",
      "Train on 12202 samples, validate on 1 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 3394.1024 - val_loss: 583840.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3532.8415 - val_loss: 585466.3125\n",
      "Train on 12203 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4161.5895 - val_loss: 510836.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5456.8705 - val_loss: 515031.9062\n",
      "Train on 12204 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5903.6556 - val_loss: 527224.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6479.7985 - val_loss: 529167.8125\n",
      "Train on 12205 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8655.3993 - val_loss: 536482.9375\n",
      "Epoch 2/2\n",
      " - 1s - loss: 6877.5093 - val_loss: 538177.6875\n",
      "Train on 12206 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4109.6864 - val_loss: 532387.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5517.4409 - val_loss: 530857.7500\n",
      "Train on 12207 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4323.5875 - val_loss: 532531.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 11880.0852 - val_loss: 532538.2500\n",
      "Train on 12208 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7099.8820 - val_loss: 547278.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6554.4508 - val_loss: 545611.2500\n",
      "Train on 12209 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4283.8772 - val_loss: 537951.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5245.5647 - val_loss: 537013.8125\n",
      "Train on 12210 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4255.1882 - val_loss: 538187.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5123.7038 - val_loss: 540557.7500\n",
      "Train on 12211 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3972.2694 - val_loss: 537271.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6115.8752 - val_loss: 542406.0000\n",
      "Train on 12212 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4830.7492 - val_loss: 535086.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5414.5928 - val_loss: 528343.0000\n",
      "Train on 12213 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5015.1091 - val_loss: 533733.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5463.5379 - val_loss: 535129.7500\n",
      "Train on 12214 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4098.7088 - val_loss: 521962.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5203.4291 - val_loss: 523659.2812\n",
      "Train on 12215 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3740.4431 - val_loss: 538843.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6345.3642 - val_loss: 535874.3750\n",
      "Train on 12216 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6055.4564 - val_loss: 541384.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5190.3940 - val_loss: 532952.7500\n",
      "Train on 12217 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6197.6439 - val_loss: 546997.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5172.4196 - val_loss: 540371.8125\n",
      "Train on 12218 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9026.2264 - val_loss: 537750.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4444.8258 - val_loss: 536506.5625\n",
      "Train on 12219 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4576.7431 - val_loss: 546602.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6370.6741 - val_loss: 545640.1250\n",
      "Train on 12220 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5558.9677 - val_loss: 535889.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5775.7874 - val_loss: 537246.4375\n",
      "Train on 12221 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6814.0945 - val_loss: 523167.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8954.3537 - val_loss: 530242.4375\n",
      "Train on 12222 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4033.0255 - val_loss: 521000.5938\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9174.0040 - val_loss: 522442.3750\n",
      "Train on 12223 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7196.3792 - val_loss: 600727.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4202.8788 - val_loss: 602380.2500\n",
      "Train on 12224 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4754.2010 - val_loss: 649098.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4788.8670 - val_loss: 652058.2500\n",
      "Train on 12225 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4136.5561 - val_loss: 602899.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4893.6145 - val_loss: 604585.6250\n",
      "Train on 12226 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4582.5322 - val_loss: 616798.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6954.5624 - val_loss: 617594.9375\n",
      "Train on 12227 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6924.4416 - val_loss: 639766.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4026.2299 - val_loss: 633361.8125\n",
      "Train on 12228 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5574.6581 - val_loss: 609722.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5994.3737 - val_loss: 612624.5625\n",
      "Train on 12229 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 4888.5180 - val_loss: 627694.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5003.7340 - val_loss: 628184.7500\n",
      "Train on 12230 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5348.4866 - val_loss: 615362.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5629.4147 - val_loss: 610698.3750\n",
      "Train on 12231 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3998.5813 - val_loss: 608807.1875\n",
      "Epoch 2/2\n",
      " - 1s - loss: 5443.4327 - val_loss: 614589.0000\n",
      "Train on 12232 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6017.5788 - val_loss: 630079.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5697.1066 - val_loss: 631633.0000\n",
      "Train on 12233 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 4578.9198 - val_loss: 621714.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4197.5489 - val_loss: 626831.3125\n",
      "Train on 12234 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 10143.8581 - val_loss: 617496.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4222.8195 - val_loss: 617861.2500\n",
      "Train on 12235 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4921.8003 - val_loss: 623836.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6149.2474 - val_loss: 626601.3125\n",
      "Train on 12236 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5920.6577 - val_loss: 614347.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4039.1151 - val_loss: 618437.1250\n",
      "Train on 12237 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3642.8152 - val_loss: 618006.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6631.2156 - val_loss: 618788.5000\n",
      "Train on 12238 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4698.4691 - val_loss: 621768.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6494.2508 - val_loss: 623256.3125\n",
      "Train on 12239 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4783.1367 - val_loss: 624028.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6917.8323 - val_loss: 624240.8125\n",
      "Train on 12240 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5082.4353 - val_loss: 625089.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4927.2726 - val_loss: 626477.2500\n",
      "Train on 12241 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4317.9247 - val_loss: 647903.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5190.2299 - val_loss: 648740.5625\n",
      "Train on 12242 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4584.9507 - val_loss: 591299.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5031.1701 - val_loss: 593214.3750\n",
      "Train on 12243 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3603.7774 - val_loss: 614285.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5599.1834 - val_loss: 615104.0000\n",
      "Train on 12244 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7604.8696 - val_loss: 626271.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4489.6474 - val_loss: 621513.1875\n",
      "Train on 12245 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 12885.1667 - val_loss: 611169.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4273.4761 - val_loss: 622620.8125\n",
      "Train on 12246 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5161.5618 - val_loss: 613153.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4675.9231 - val_loss: 621054.8125\n",
      "Train on 12247 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7218.6783 - val_loss: 625676.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4395.4463 - val_loss: 619337.5000\n",
      "Train on 12248 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4609.3511 - val_loss: 590267.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7877.8475 - val_loss: 589549.5625\n",
      "Train on 12249 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4220.3154 - val_loss: 606103.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5082.6747 - val_loss: 603282.1250\n",
      "Train on 12250 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5908.4401 - val_loss: 602287.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5345.1340 - val_loss: 602724.0000\n",
      "Train on 12251 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3608.7454 - val_loss: 596249.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4423.5489 - val_loss: 602550.4375\n",
      "Train on 12252 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5258.7226 - val_loss: 614281.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8201.9658 - val_loss: 612208.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12253 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4746.0823 - val_loss: 645774.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5382.7379 - val_loss: 650422.9375\n",
      "Train on 12254 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4831.0989 - val_loss: 642438.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4909.0163 - val_loss: 638259.7500\n",
      "Train on 12255 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5070.8992 - val_loss: 585379.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5999.8466 - val_loss: 579213.1250\n",
      "Train on 12256 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5970.2545 - val_loss: 550750.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7418.3822 - val_loss: 545723.4375\n",
      "Train on 12257 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4721.9457 - val_loss: 572042.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4466.3986 - val_loss: 576915.1875\n",
      "Train on 12258 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5571.7647 - val_loss: 575333.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 13237.5380 - val_loss: 582039.0000\n",
      "Train on 12259 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6299.7619 - val_loss: 574907.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4369.2990 - val_loss: 574240.1875\n",
      "Train on 12260 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4098.2895 - val_loss: 578927.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6248.7031 - val_loss: 576923.3125\n",
      "Train on 12261 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9161.2164 - val_loss: 582265.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5723.6058 - val_loss: 580734.0625\n",
      "Train on 12262 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5242.5888 - val_loss: 581294.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4678.8950 - val_loss: 584615.9375\n",
      "Train on 12263 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5428.8373 - val_loss: 578621.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5404.5131 - val_loss: 577980.4375\n",
      "Train on 12264 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8127.6574 - val_loss: 587115.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5233.1577 - val_loss: 579843.1875\n",
      "Train on 12265 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4726.9060 - val_loss: 617896.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5192.8803 - val_loss: 614413.6875\n",
      "Train on 12266 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4328.1027 - val_loss: 605399.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6703.9000 - val_loss: 606577.8125\n",
      "Train on 12267 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5152.7436 - val_loss: 606524.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5287.3982 - val_loss: 605655.1875\n",
      "Train on 12268 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5425.9955 - val_loss: 583172.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3532.9201 - val_loss: 584680.8750\n",
      "Train on 12269 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4939.2579 - val_loss: 600613.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4690.3010 - val_loss: 597000.3125\n",
      "Train on 12270 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4586.6697 - val_loss: 594125.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5699.3424 - val_loss: 595769.5625\n",
      "Train on 12271 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6491.9380 - val_loss: 592128.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3373.4591 - val_loss: 601432.4375\n",
      "Train on 12272 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5531.9398 - val_loss: 593818.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7088.5366 - val_loss: 592263.2500\n",
      "Train on 12273 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4346.2886 - val_loss: 600914.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6332.8725 - val_loss: 608722.2500\n",
      "Train on 12274 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6818.2393 - val_loss: 600487.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4691.8741 - val_loss: 595140.3125\n",
      "Train on 12275 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5145.1732 - val_loss: 587567.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5646.0234 - val_loss: 592856.0000\n",
      "Train on 12276 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6421.2853 - val_loss: 597647.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4135.1464 - val_loss: 600378.6875\n",
      "Train on 12277 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5696.6057 - val_loss: 600042.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4456.5467 - val_loss: 600467.1875\n",
      "Train on 12278 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4493.0022 - val_loss: 598068.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4689.8271 - val_loss: 594307.7500\n",
      "Train on 12279 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5006.1494 - val_loss: 606590.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4987.7233 - val_loss: 603406.9375\n",
      "Train on 12280 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7924.5604 - val_loss: 605145.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5693.1406 - val_loss: 601977.0625\n",
      "Train on 12281 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4737.4050 - val_loss: 587977.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4323.0835 - val_loss: 597247.8125\n",
      "Train on 12282 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4168.4844 - val_loss: 581312.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10035.5254 - val_loss: 580375.3750\n",
      "Train on 12283 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5600.3762 - val_loss: 589173.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8570.5352 - val_loss: 586793.7500\n",
      "Train on 12284 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4305.1024 - val_loss: 587949.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6484.4679 - val_loss: 593577.6875\n",
      "Train on 12285 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4317.4137 - val_loss: 587174.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 8274.5491 - val_loss: 588149.6875\n",
      "Train on 12286 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4702.2961 - val_loss: 591319.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5915.4322 - val_loss: 585316.1250\n",
      "Train on 12287 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 9347.8079 - val_loss: 592463.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4925.7086 - val_loss: 587603.8125\n",
      "Train on 12288 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4727.6188 - val_loss: 585849.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4198.0290 - val_loss: 579363.3125\n",
      "Train on 12289 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4808.2316 - val_loss: 600248.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3675.3157 - val_loss: 603977.1250\n",
      "Train on 12290 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5349.8594 - val_loss: 603587.8750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5444.0845 - val_loss: 605319.6875\n",
      "Train on 12291 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5907.5960 - val_loss: 558019.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5593.0235 - val_loss: 557039.1875\n",
      "Train on 12292 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4891.4835 - val_loss: 570408.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4674.2311 - val_loss: 572428.1875\n",
      "Train on 12293 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5411.1165 - val_loss: 580697.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6011.2313 - val_loss: 585689.3750\n",
      "Train on 12294 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4280.8806 - val_loss: 586384.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4092.2057 - val_loss: 583685.5625\n",
      "Train on 12295 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7982.2187 - val_loss: 577139.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5366.8831 - val_loss: 583894.8750\n",
      "Train on 12296 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4688.9332 - val_loss: 581633.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 10514.8162 - val_loss: 588674.8125\n",
      "Train on 12297 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5238.2799 - val_loss: 579844.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6819.5685 - val_loss: 583192.1250\n",
      "Train on 12298 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4767.9852 - val_loss: 581879.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5825.7915 - val_loss: 581303.1250\n",
      "Train on 12299 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5385.0655 - val_loss: 544488.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4307.7434 - val_loss: 544667.8125\n",
      "Train on 12300 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3990.5316 - val_loss: 552720.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 9239.2662 - val_loss: 553658.4375\n",
      "Train on 12301 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4520.7546 - val_loss: 556765.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4609.8049 - val_loss: 550084.4375\n",
      "Train on 12302 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4936.5191 - val_loss: 547984.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5830.3823 - val_loss: 545703.9375\n",
      "Train on 12303 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 8714.7335 - val_loss: 560954.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 2s - loss: 8864.5915 - val_loss: 560512.1250\n",
      "Train on 12304 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4382.1455 - val_loss: 564270.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5034.8439 - val_loss: 563679.0625\n",
      "Train on 12305 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5093.8068 - val_loss: 556230.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4440.3170 - val_loss: 554751.5000\n",
      "Train on 12306 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4591.6831 - val_loss: 543753.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4493.7194 - val_loss: 549344.8125\n",
      "Train on 12307 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4973.5504 - val_loss: 558188.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6093.8625 - val_loss: 555227.2500\n",
      "Train on 12308 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4281.0606 - val_loss: 558090.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 7760.5683 - val_loss: 551395.0625\n",
      "Train on 12309 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6413.2533 - val_loss: 559517.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4853.2464 - val_loss: 554095.9375\n",
      "Train on 12310 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4444.2225 - val_loss: 556673.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5409.9376 - val_loss: 560549.4375\n",
      "Train on 12311 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6303.3627 - val_loss: 560349.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5203.3981 - val_loss: 560467.1875\n",
      "Train on 12312 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5551.6657 - val_loss: 562474.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4796.7366 - val_loss: 566170.2500\n",
      "Train on 12313 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5220.4940 - val_loss: 565723.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4980.4583 - val_loss: 570445.3125\n",
      "Train on 12314 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6668.0386 - val_loss: 557048.3125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4845.3705 - val_loss: 558287.3125\n",
      "Train on 12315 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4151.9640 - val_loss: 565921.1875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5025.3174 - val_loss: 565317.1250\n",
      "Train on 12316 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4644.2196 - val_loss: 558372.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4894.5055 - val_loss: 563034.0625\n",
      "Train on 12317 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5007.5400 - val_loss: 573868.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4846.2139 - val_loss: 577276.0625\n",
      "Train on 12318 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5260.2609 - val_loss: 553983.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4014.9851 - val_loss: 551758.8125\n",
      "Train on 12319 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5067.6308 - val_loss: 552728.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4568.4369 - val_loss: 546418.0000\n",
      "Train on 12320 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6206.1550 - val_loss: 560732.5625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4066.5570 - val_loss: 558148.3125\n",
      "Train on 12321 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4874.6473 - val_loss: 553580.6875\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5071.4427 - val_loss: 550576.3125\n",
      "Train on 12322 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4889.0056 - val_loss: 532825.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4653.3794 - val_loss: 535954.4375\n",
      "Train on 12323 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5111.2452 - val_loss: 552202.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5034.9327 - val_loss: 557198.8125\n",
      "Train on 12324 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3621.4173 - val_loss: 579437.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3790.5862 - val_loss: 575383.3750\n",
      "Train on 12325 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 11774.6742 - val_loss: 572817.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4382.8410 - val_loss: 565311.2500\n",
      "Train on 12326 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5335.4687 - val_loss: 567634.2500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4663.3437 - val_loss: 571991.2500\n",
      "Train on 12327 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5473.4093 - val_loss: 628168.5000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4040.6202 - val_loss: 627320.8750\n",
      "Train on 12328 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4137.2918 - val_loss: 483845.9062\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4886.3915 - val_loss: 489272.2500\n",
      "Train on 12329 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3725.0180 - val_loss: 528188.6250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 5081.8820 - val_loss: 530704.0625\n",
      "Train on 12330 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 3914.1993 - val_loss: 533490.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3823.4477 - val_loss: 528245.7500\n",
      "Train on 12331 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4971.8965 - val_loss: 543151.7500\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4919.9964 - val_loss: 537140.1250\n",
      "Train on 12332 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5809.7327 - val_loss: 539876.9375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4689.8049 - val_loss: 536484.7500\n",
      "Train on 12333 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 7909.0094 - val_loss: 533184.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4406.8657 - val_loss: 532475.1875\n",
      "Train on 12334 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4982.1504 - val_loss: 529026.4375\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6458.8262 - val_loss: 534848.6875\n",
      "Train on 12335 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4364.5963 - val_loss: 528129.0000\n",
      "Epoch 2/2\n",
      " - 2s - loss: 3454.9355 - val_loss: 532421.0625\n",
      "Train on 12336 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 5334.7345 - val_loss: 532069.0625\n",
      "Epoch 2/2\n",
      " - 2s - loss: 6555.4160 - val_loss: 528454.4375\n",
      "Train on 12337 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4207.9980 - val_loss: 533516.1250\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4158.6709 - val_loss: 530800.8125\n",
      "Train on 12338 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 6845.9709 - val_loss: 530900.8125\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4429.4697 - val_loss: 533153.1250\n",
      "Train on 12339 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 4487.7587 - val_loss: 535982.3750\n",
      "Epoch 2/2\n",
      " - 2s - loss: 4519.7130 - val_loss: 534688.0000\n"
     ]
    }
   ],
   "source": [
    "res_3 = make_rolling_window(LSTM_model_3, train_X, train_y, val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "sns.lineplot(data=pd.DataFrame({'y' : res_3[1]}))\n",
    "sns.lineplot(data=pd.DataFrame({'yhat' : res_3[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_22: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-e7d1ed1c23c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLSTM_model_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mLSTM_model_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mLSTM_model_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mLSTM_model_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# LSTM_model_4.add(LSTM(16, activation='relu'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_22: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "LSTM_model_4 = Sequential()\n",
    "LSTM_model_4.add(LSTM(256, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]), dropout=0.20,recurrent_dropout=0.20))\n",
    "LSTM_model_4.add(LSTM(128, dropout=0.20,recurrent_dropout=0.20))\n",
    "LSTM_model_4.add(Dense(128))\n",
    "# LSTM_model_4.add(LSTM(16, activation='relu'))\n",
    "LSTM_model_4.add(Dense(1))\n",
    "LSTM_model_4.compile(optimizer='adam', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4 = LSTM_model_4.fit(train_X, train_y, \n",
    "                    epochs= 200, \n",
    "                    batch_size = 32, \n",
    "                    validation_data=(val_X, val_y),\n",
    "                    verbose=2,\n",
    "#                     callbacks=[earlystopper],\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_4 = make_rolling_window(LSTM_model_4, train_X, train_y, val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.447"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_3.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3619.13, 3615.49, 3610.75, 3533.19, 3511.1 , 3510.73, 3508.06,\n",
       "       3502.81, 3505.02, 3511.26, 3505.64, 3511.54, 3519.49, 3522.14,\n",
       "       3520.47, 3523.76, 3535.24, 3542.7 , 3542.85, 3536.03, 3536.21,\n",
       "       3552.35, 3528.39, 3535.43, 3545.13, 3529.71, 3629.22, 3672.35,\n",
       "       3668.39, 3679.14, 3677.33, 3682.41, 3659.27, 3646.98, 3667.75,\n",
       "       3667.85, 3677.49, 3671.05, 3670.68, 3668.54, 3666.52, 3660.3 ,\n",
       "       3663.22, 3663.85, 3642.64, 3643.13, 3647.35, 3644.1 , 3652.92,\n",
       "       3655.09, 3635.65, 3633.09, 3632.91, 3632.34, 3626.85, 3591.41,\n",
       "       3569.68, 3575.48, 3579.53, 3580.64, 3587.45, 3583.9 , 3591.87,\n",
       "       3603.42, 3601.87, 3594.71, 3582.95, 3597.23, 3614.08, 3616.31,\n",
       "       3618.45, 3646.02, 3624.12, 3621.98, 3614.57, 3600.34, 3605.89,\n",
       "       3612.97, 3592.74, 3589.17, 3606.62, 3598.87, 3605.11, 3606.18,\n",
       "       3601.94, 3595.04, 3580.3 , 3587.25, 3583.97, 3588.15, 3587.97,\n",
       "       3592.79, 3588.36, 3580.96, 3593.58, 3589.22, 3585.66, 3587.82,\n",
       "       3602.7 , 3618.3 , 3610.16, 3630.46, 3628.71, 3624.15, 3636.16,\n",
       "       3624.28, 3639.58, 3631.61, 3628.42, 3630.11, 3624.93, 3621.1 ,\n",
       "       3616.97, 3623.97, 3623.4 , 3624.65, 3627.66, 3621.64, 3609.99,\n",
       "       3601.36, 3602.29, 3604.21, 3616.31, 3610.92, 3598.54, 3601.03,\n",
       "       3593.05, 3604.34, 3611.8 , 3612.55, 3608.93, 3609.6 , 3612.64,\n",
       "       3621.9 , 3620.76, 3621.88, 3621.22, 3618.37, 3617.81, 3622.36,\n",
       "       3624.71, 3725.14, 3723.71, 3718.69, 3712.73, 3710.34, 3709.86,\n",
       "       3711.08, 3711.84, 3695.19, 3702.17, 3701.2 , 3699.66, 3700.37,\n",
       "       3687.5 , 3682.38, 3693.96, 3696.12, 3696.45, 3696.24, 3690.49,\n",
       "       3686.27, 3688.3 , 3688.48, 3692.17, 3691.  , 3619.19, 3518.15,\n",
       "       3514.71, 3526.31, 3520.7 , 3519.49, 3518.49, 3520.03, 3518.37,\n",
       "       3525.16, 3538.21, 3549.85, 3538.22, 3542.05, 3537.23, 3538.7 ,\n",
       "       3527.89, 3522.45, 3526.51, 3532.53, 3529.49, 3527.88, 3528.13,\n",
       "       3536.7 , 3543.69, 3543.23, 3548.52, 3538.14, 3535.34, 3542.1 ,\n",
       "       3545.15, 3539.9 , 3544.37, 3539.14, 3527.82, 3521.31, 3538.45,\n",
       "       3413.16, 3390.14, 3386.9 , 3392.32, 3391.11, 3391.56, 3389.4 ,\n",
       "       3381.21, 3391.24, 3396.24, 3396.76, 3421.83, 3430.63, 3431.97,\n",
       "       3436.04, 3429.07, 3424.63, 3429.49, 3435.5 , 3446.06, 3445.79,\n",
       "       3443.81, 3443.55, 3444.77, 3797.64, 3797.43, 3800.47, 3803.65,\n",
       "       3801.01, 3800.47, 3800.25, 3797.23, 3808.4 , 3817.2 , 3812.83,\n",
       "       3812.67, 3808.84, 3810.45, 3815.98, 3817.07, 3825.51, 3837.67,\n",
       "       3832.31, 3831.71, 3829.01, 3829.27, 3819.35, 3811.35, 4093.05,\n",
       "       4121.13, 4119.97, 4121.55, 4124.54, 4118.76, 4123.4 , 4121.23,\n",
       "       4117.89, 4120.75, 4117.36, 4113.23, 4122.65, 4126.42, 4139.54,\n",
       "       4132.65, 4141.09, 4134.3 , 4131.4 , 4131.35, 4128.65, 4128.7 ,\n",
       "       4137.3 , 4139.19, 5300.21, 5303.23, 5324.82, 5314.34, 5316.01,\n",
       "       5320.36, 5316.16, 5312.49, 5291.64, 5294.44, 5300.96, 5311.13,\n",
       "       5288.68, 5282.93, 5292.16, 5292.43, 5296.37, 5326.45, 5309.8 ,\n",
       "       5299.27, 5307.11, 5299.59, 5296.83, 5319.61, 8530.27, 8554.68,\n",
       "       8532.34, 8546.66, 8551.72, 8513.92, 8501.7 , 8529.27, 8544.62,\n",
       "       8584.73, 8580.07, 8550.52, 8558.99, 8531.44, 8510.38, 8516.63,\n",
       "       8558.23, 8534.86, 8513.3 , 8510.17, 8548.55], dtype=float32)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>vix</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12030</th>\n",
       "      <td>2018-12-20 10:00:00</td>\n",
       "      <td>4051.15</td>\n",
       "      <td>44.738</td>\n",
       "      <td>4124.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12031</th>\n",
       "      <td>2018-12-20 11:00:00</td>\n",
       "      <td>4039.42</td>\n",
       "      <td>44.738</td>\n",
       "      <td>4100.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12032</th>\n",
       "      <td>2018-12-20 12:00:00</td>\n",
       "      <td>4051.51</td>\n",
       "      <td>44.738</td>\n",
       "      <td>4076.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12033</th>\n",
       "      <td>2018-12-20 13:00:00</td>\n",
       "      <td>4009.81</td>\n",
       "      <td>44.738</td>\n",
       "      <td>4131.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12034</th>\n",
       "      <td>2018-12-20 14:00:00</td>\n",
       "      <td>4019.83</td>\n",
       "      <td>44.738</td>\n",
       "      <td>4076.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ds        y     vix     gold\n",
       "12030 2018-12-20 10:00:00  4051.15  44.738  4124.56\n",
       "12031 2018-12-20 11:00:00  4039.42  44.738  4100.84\n",
       "12032 2018-12-20 12:00:00  4051.51  44.738  4076.27\n",
       "12033 2018-12-20 13:00:00  4009.81  44.738  4131.06\n",
       "12034 2018-12-20 14:00:00  4019.83  44.738  4076.56"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12007    3805.709961\n",
       "12008    3813.189941\n",
       "12009    3883.330078\n",
       "12010    3818.000000\n",
       "12011    3782.540039\n",
       "12012    3782.209961\n",
       "12013    3796.199951\n",
       "12014    3789.110107\n",
       "12015    3792.659912\n",
       "12016    3730.290039\n",
       "12017    3683.780029\n",
       "12018    3693.860107\n",
       "12019    3702.300049\n",
       "12020    3697.129883\n",
       "12021    3727.699951\n",
       "12022    3737.750000\n",
       "12023    3719.699951\n",
       "12024    3730.110107\n",
       "12025    3710.159912\n",
       "12026    3699.469971\n",
       "12027    3706.750000\n",
       "12028    3928.399902\n",
       "12029    4031.699951\n",
       "12030    4051.149902\n",
       "12031    4039.419922\n",
       "12032    4051.510010\n",
       "12033    4009.810059\n",
       "12034    4019.830078\n",
       "12035    4032.439941\n",
       "12036    4074.370117\n",
       "            ...     \n",
       "12277    3814.590088\n",
       "12278    3810.479980\n",
       "12279    3799.679932\n",
       "12280    3813.479980\n",
       "12281    3822.229980\n",
       "12282    3816.459961\n",
       "12283    3823.070068\n",
       "12284    3823.669922\n",
       "12285    3800.840088\n",
       "12286    3778.780029\n",
       "12287    3777.780029\n",
       "12288    3785.790039\n",
       "12289    3778.320068\n",
       "12290    3784.540039\n",
       "12291    3784.580078\n",
       "12292    3774.679932\n",
       "12293    3790.850098\n",
       "12294    3797.050049\n",
       "12295    3740.310059\n",
       "12296    3737.530029\n",
       "12297    3755.939941\n",
       "12298    3763.600098\n",
       "12299    3763.610107\n",
       "12300    3758.689941\n",
       "12301    3749.879883\n",
       "12302    3749.129883\n",
       "12303    3691.780029\n",
       "12304    3676.899902\n",
       "12305    3673.360107\n",
       "12306    3668.260010\n",
       "Name: var1(t), Length: 300, dtype: float32"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed_2['var1(t)'][12000:12300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
