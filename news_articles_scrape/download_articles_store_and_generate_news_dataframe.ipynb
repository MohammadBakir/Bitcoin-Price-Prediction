{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Packages\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import newspaper\n",
    "from newspaper import fulltext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set chromedriver executable path. \n",
    "chromedriver = \"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open pickled list of article news links\n",
    "with open('./data_frames/news_article_links_15000_30000.pkl', 'rb') as file:\n",
    "     news_article_links = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_article_links = [item for sublist in news_article_links for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From individual API files, download news source link and extract text using newspaper python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_json(urls, file_path_text_folder, file_path_dates_folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    The following function utilizes the newspaper api to scrape text and dates from a news article. The text and dates are\n",
    "    then stored locally in their designated folder. \n",
    "    \"\"\"\n",
    "    num = len(urls)\n",
    "    print('saving ...')\n",
    "    \n",
    "    #Loop through Urls list and download article text utilizing newspaper API\n",
    "    for url in urls:\n",
    "        try:\n",
    "            #print(url)\n",
    "            url = url.strip()\n",
    "            link = newspaper.Article(url)\n",
    "            link.download()\n",
    "            html = link.html\n",
    "            \n",
    "            #Disregard any urls with the word 'video' as they can't be scraped via newspaper api\n",
    "            if 'video' in url:\n",
    "                pass\n",
    "\n",
    "            elif link: \n",
    "                try:\n",
    "                    #Parse article text from url\n",
    "                    link.parse()\n",
    "                    text = fulltext(html)\n",
    "                    date = link.publish_date\n",
    "\n",
    "                    #Save Article text and Dates locally on device\n",
    "                    filename = file_path_text_folder+'article_{0}.txt'.format(num)\n",
    "                    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "                    with open(filename, 'w',encoding=\"utf8\",newline='') as file:\n",
    "                        json.dump(text,file)\n",
    "                    \n",
    "                    filename = file_path_dates_folder+'article_{0}_date.txt'.format(num)\n",
    "                    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "                    with open(filename, 'w',encoding=\"utf8\",newline='') as file:\n",
    "                        json.dump(str(date),file)\n",
    "                        \n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        num -=1\n",
    "                \n",
    "    print('Finished')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Run Cell to Collect Articles\n",
    "saving_json(news_article_links,'./article_data/text/article_text_15000_30000/','./article_data/dates/article_dates_15000_30000/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Initial Dataframes, Only Run the Following cell once then comment out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create initial modeling DataFrame - Only Ran Once then commented out\n",
    "# modeling_text = pd.DataFrame(columns=['text'])\n",
    "\n",
    "# # Save initial DataFrame - Only Ran Once - Only Ran Once then commented out\n",
    "# with open('./data_frames/bitcoin_news_raw_text_df.pickle', 'wb') as file:\n",
    "#            pickle.dump(modeling_text, file)\n",
    "\n",
    "# # Create initial modeling DataFrame - Only Ran Once then commented out\n",
    "# modeling_dates = pd.DataFrame(columns=['date'])\n",
    "\n",
    "# # Save initial DataFrame - Only Ran Once - Only Ran Once then commented out\n",
    "# with open('./data_frames/bitcoin_news_raw_dates_df.pickle', 'wb') as file:\n",
    "#            pickle.dump(modeling_dates, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Corpus of Bitcoin News Article Text\n",
    "with open('./data_frames/bitcoin_news_raw_text_df.pickle', 'rb') as file:\n",
    "    bitcoin_news_text = pickle.load(file)\n",
    "\n",
    "with open('./data_frames/bitcoin_news_raw_dates_df.pickle', 'rb') as file:\n",
    "    bitcoin_news_dates = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_data_to_dateframe(df, file_directory):\n",
    "    \"\"\"\n",
    "    This function takes in an empty dataframe. Opens text files avaialble on host machine, and adds the text within\n",
    "    the files to the dataframe.\n",
    "    \"\"\"\n",
    "    i = df.shape[0]  #Will start adding at the last row of the dataframe\n",
    "    for source in os.listdir(file_directory):\n",
    "        for file in os.listdir(file_directory+source):\n",
    "             if file.endswith(\".txt\"):\n",
    "                    curr_file = os.path.join(file_directory+source, file)\n",
    "                    with open(curr_file) as json_file:\n",
    "                        try:\n",
    "                            data = json.load(json_file)\n",
    "                            df.loc[i] = data \n",
    "                            i = i + 1\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_news_text  = add_text_data_to_dateframe(bitcoin_news_text,'./article_data/text/' )\n",
    "bitcoin_news_dates = add_text_data_to_dateframe(bitcoin_news_dates,'./article_data/dates/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Bitcoin Article Text Dataframe\n",
    "with open('./data_frames/bitcoin_news_raw_text_df.pickle', 'wb') as file:\n",
    "    pickle.dump(bitcoin_news_text, file)\n",
    "\n",
    "#Save Bitcoin Article Dates Dataframe\n",
    "with open('./data_frames/bitcoin_news_raw_dates_df.pickle', 'wb') as file:\n",
    "    pickle.dump(bitcoin_news_dates, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Saved Dataframes\n",
    "with open('./data_frames/bitcoin_news_raw_text_df.pickle', 'rb') as file:\n",
    "    bitcoin_news_raw_text_df = pickle.load(file)\n",
    "    \n",
    "#Combine Dataframes\n",
    "with open('./data_frames/bitcoin_news_raw_dates_df.pickle', 'rb') as file:\n",
    "    bitcoin_news_raw_dates_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Dataframes at the index\n",
    "bitcoin_news_text_dates_combined_df = pd.merge(bitcoin_news_raw_text_df, bitcoin_news_raw_dates_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20240</th>\n",
       "      <td>We’ve been a little ‘crypto crazy’ the last fe...</td>\n",
       "      <td>2017-06-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>Top influential organizations: Blockchain, Coi...</td>\n",
       "      <td>2016-06-06 13:43:55+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8666</th>\n",
       "      <td>Bitcoin Europe Lowers Card Interchange Fees – ...</td>\n",
       "      <td>2015-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13427</th>\n",
       "      <td>Can Blockchain break Facebook, Uber, Airbnb, e...</td>\n",
       "      <td>2016-05-11 16:12:24+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9074</th>\n",
       "      <td>Bitcoin: The End of Money As We Know It is a 2...</td>\n",
       "      <td>2015-12-26 01:02:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13023</th>\n",
       "      <td>With a new wave of volatility hitting the cryp...</td>\n",
       "      <td>2016-05-01 15:59:38+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>Mar 08, 2018 at 12:29 // News\\n\\nCoin Idol Aut...</td>\n",
       "      <td>2018-03-12 21:55:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>Bitcoin enthusiasts look for new ways to safeg...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11556</th>\n",
       "      <td>Bitcoin is collapsing. Martin Hunter/Getty Ima...</td>\n",
       "      <td>2016-03-04 15:13:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>Cybercriminal group DD4BC, which stands for “D...</td>\n",
       "      <td>2015-09-09 16:19:58+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "20240  We’ve been a little ‘crypto crazy’ the last fe...   \n",
       "4726   Top influential organizations: Blockchain, Coi...   \n",
       "8666   Bitcoin Europe Lowers Card Interchange Fees – ...   \n",
       "13427  Can Blockchain break Facebook, Uber, Airbnb, e...   \n",
       "9074   Bitcoin: The End of Money As We Know It is a 2...   \n",
       "13023  With a new wave of volatility hitting the cryp...   \n",
       "14582  Mar 08, 2018 at 12:29 // News\\n\\nCoin Idol Aut...   \n",
       "7614   Bitcoin enthusiasts look for new ways to safeg...   \n",
       "11556  Bitcoin is collapsing. Martin Hunter/Getty Ima...   \n",
       "6060   Cybercriminal group DD4BC, which stands for “D...   \n",
       "\n",
       "                            date  \n",
       "20240        2017-06-09 00:00:00  \n",
       "4726   2016-06-06 13:43:55+00:00  \n",
       "8666         2015-12-15 00:00:00  \n",
       "13427  2016-05-11 16:12:24+00:00  \n",
       "9074   2015-12-26 01:02:10+00:00  \n",
       "13023  2016-05-01 15:59:38+00:00  \n",
       "14582  2018-03-12 21:55:10+00:00  \n",
       "7614                        None  \n",
       "11556  2016-03-04 15:13:08+00:00  \n",
       "6060   2015-09-09 16:19:58+00:00  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample the dataframe\n",
    "bitcoin_news_text_dates_combined.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Joined Article Text and Dates Dataframe\n",
    "with open('./data_frames/bitcoin_news_text_dates_combined_df.pickle', 'wb') as file:\n",
    "    pickle.dump(bitcoin_news_text_dates_combined_df, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
